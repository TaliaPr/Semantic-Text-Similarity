{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Run this cell to install compatible versions of package\\n\\n!pip uninstall -y numpy tensorflow tensorflow-gpu ml_dtypes gensim\\n\\n!pip install numpy==1.23.5  \\n!pip install gensim==4.3.0\\n!pip install tensorflow==2.19.0\\n\\n# Force restart the kernel after installing packages\\nprint(\"Please restart the kernel after running this cell.\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Run this cell to install compatible versions of package\n",
    "\n",
    "!pip uninstall -y numpy tensorflow tensorflow-gpu ml_dtypes gensim\n",
    "\n",
    "!pip install numpy==1.23.5  \n",
    "!pip install gensim==4.3.0\n",
    "!pip install tensorflow==2.19.0\n",
    "\n",
    "# Force restart the kernel after installing packages\n",
    "print(\"Please restart the kernel after running this cell.\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Semantic Text Similarity\n",
    "Este modelo utiliza gensim para convertir pares de vectores + puntuacions en vectores (word embeddings).\n",
    "Dado un dataset, infere la puntuaciÃ³ de similitud entre ambdues frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T13:56:38.187276Z",
     "start_time": "2025-05-23T13:56:35.576516Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:160: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 2.1.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Temp\\ipykernel_11692\\121210878.py\", line 3, in <module>\n",
      "    from gensim.utils import simple_preprocess\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\__init__.py\", line 11, in <module>\n",
      "    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\__init__.py\", line 4, in <module>\n",
      "    from .preprocessing import (  # noqa:F401\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\preprocessing.py\", line 26, in <module>\n",
      "    from gensim import utils\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\utils.py\", line 36, in <module>\n",
      "    import scipy.sparse\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\__init__.py\", line 267, in <module>\n",
      "    from ._csr import *\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Temp\\ipykernel_11692\\121210878.py\", line 3, in <module>\n",
      "    from gensim.utils import simple_preprocess\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\__init__.py\", line 11, in <module>\n",
      "    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\__init__.py\", line 4, in <module>\n",
      "    from .preprocessing import (  # noqa:F401\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\preprocessing.py\", line 26, in <module>\n",
      "    from gensim import utils\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\utils.py\", line 36, in <module>\n",
      "    import scipy.sparse\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\__init__.py\", line 267, in <module>\n",
      "    from ._csr import *\n",
      "  File \"C:\\Users\\jiawe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Requisits\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m simple_preprocess\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpora\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"This package contains functions to preprocess raw text\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      5\u001b[39m     preprocess_documents,\n\u001b[32m      6\u001b[39m     preprocess_string,\n\u001b[32m      7\u001b[39m     read_file,\n\u001b[32m      8\u001b[39m     read_files,\n\u001b[32m      9\u001b[39m     remove_stopwords,\n\u001b[32m     10\u001b[39m     split_alphanum,\n\u001b[32m     11\u001b[39m     stem_text,\n\u001b[32m     12\u001b[39m     strip_multiple_whitespaces,\n\u001b[32m     13\u001b[39m     strip_non_alphanum,\n\u001b[32m     14\u001b[39m     strip_numeric,\n\u001b[32m     15\u001b[39m     strip_punctuation,\n\u001b[32m     16\u001b[39m     strip_short,\n\u001b[32m     17\u001b[39m     strip_tags,\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\parsing\\preprocessing.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstring\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[32m     30\u001b[39m STOPWORDS = \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msix\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjust\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mless\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbeing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mindeed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mover\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmove\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33manyway\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfour\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnot\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mown\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mthrough\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33musing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfifty\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwhere\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmill\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33monly\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfind\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbefore\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwhose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhow\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msomewhere\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmake\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33monce\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     59\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\utils.py:36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmart_open\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mopen\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m gensim_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\__init__.py:267\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_warnings\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_csr.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sparsetools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[32m     11\u001b[39m                            get_csr_submatrix)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m upcast, get_index_dtype\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compressed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Requisits\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T13:56:38.193657Z",
     "start_time": "2025-05-23T13:56:38.191213Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tipat\n",
    "from typing import Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:00:32.430490Z",
     "start_time": "2025-05-23T13:58:11.606736Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WV_MODEL_PATH = '/Users/salva/Downloads/cc.ca.300.vec.gz'\\nimport gensim\\nwv_model =  gensim.models.KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\\nwv_model\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models pre-entrenats\n",
    "# WV_MODEL_PATH = \"/Users/salva/Downloads/cc.ca.300.bin.gz\"\n",
    "\n",
    "\n",
    "'''WV_MODEL_PATH = '/Users/salva/Downloads/cc.ca.300.vec.gz'\n",
    "import gensim\n",
    "wv_model =  gensim.models.KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\n",
    "wv_model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llavors podeu carregar el model com a mmap\n",
    "from gensim.models.fasttext import FastTextKeyedVectors\n",
    "wv_model = FastTextKeyedVectors.load('../cc.ca.gensim.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:01:38.200978Z",
     "start_time": "2025-05-23T14:01:38.197829Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REMAP_EMBEDDINGS: bool = True\n",
    "USE_PRETRAINED: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:11:24.097338Z",
     "start_time": "2025-05-23T14:11:20.085380Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2073 samples, Validation: 500 samples, Test: 500 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentence_1', 'sentence_2', 'label'],\n",
       "    num_rows: 3073\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Text Similarity (STS) dataset (principal per la PrÃ ctica 4)\n",
    "train = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test = load_dataset(\"projecte-aina/sts-ca\", split=\"test\")\n",
    "val = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "\n",
    "all_data = load_dataset(\"projecte-aina/sts-ca\", split=\"all\")\n",
    "print(f\"Train: {len(train)} samples, Validation: {len(val)} samples, Test: {len(test)} samples\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Preprocesses a dataset corpus by extracting sentence pairs and their similarity scores.\n",
    "    \n",
    "    Args:\n",
    "        corpus: A dataset containing 'sentence_1', 'sentence_2', and 'label' fields\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples containing (preprocessed_sentence_1, preprocessed_sentence_2, score)\n",
    "    \"\"\"\n",
    "    sentences_1_preproc = [simple_preprocess(d[\"sentence_1\"]) for d in corpus] #lista de listas que son oraciones lematizadas\n",
    "    sentences_2_preproc = [simple_preprocess(d[\"sentence_2\"]) for d in corpus]\n",
    "    scores = [d[\"label\"] for d in corpus]\n",
    "    sentence_pairs = list(zip(sentences_1_preproc, sentences_2_preproc, scores))\n",
    "    return sentences_1_preproc, sentences_2_preproc, scores, sentence_pairs\n",
    "\n",
    "# Process each dataset\n",
    "sentences_1_preproc, sentences_2_preproc, scores, sentence_pairs = map_corpus(all_data)\n",
    "\n",
    "# Optionally process train/test/val sets separately\n",
    "train_s1, train_s2, train_scores, train_pairs = map_corpus(train)\n",
    "test_s1, test_s2, test_scores, test_pairs = map_corpus(test)\n",
    "val_s1, val_s2, val_scores, val_pairs = map_corpus(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generacion del diccionario de todo el corpus existente para este problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:28:24.986973Z",
     "start_time": "2025-05-23T14:28:24.737384Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1dd55edca10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences_pairs_flattened = sentences_1_preproc + sentences_2_preproc\n",
    "diccionario = Dictionary(sentences_pairs_flattened)\n",
    "diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Baseline : One-Hot Encoding\n",
    "\n",
    "Una altra alternativa Ã©s utilitzar One-Hot Encoding per representar les frases. AixÃ² pot ser Ãºtil per comparar la similitud entre frases de manera mÃ©s directa, encara que no captura la semÃ ntica de les paraules com ho fan els word embeddings. La similitud es pot calcular fent servir la distÃ ncia de Jaccard (nÃºmero de paraules en comÃº dividit entre nÃºmero de paraules totals entre les dues frases) o el coseno entre els vectors resultants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usant la distÃ ncia Jaccard per avaluar la similitud entre oracions\n",
    "from typing import List, Set, Union\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_evaluation(sent1: List[Union[str, Set[str]]], sent2: List[Union[str, Set[str]]]) -> float:\n",
    "    \"\"\"\n",
    "    Calcular la similitud de Jaccard entre dues oracions\n",
    "    \n",
    "    Args:\n",
    "        sent1: Primera oraciÃ³ tokenitzada com una llista de paraules o conjunts de paraules\n",
    "        sent2: Segona oraciÃ³ tokenitzada com una llista de paraules o conjunts de paraules\n",
    "        \n",
    "    Returns:\n",
    "        float: PuntuaciÃ³ de similitud basada en la distÃ ncia de Jaccard\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(sent1)):\n",
    "        # Convertir a conjunts si no ho sÃ³n ja\n",
    "        set1 = set(sent1[i]) if not isinstance(sent1[i], set) else sent1[i]\n",
    "        set2 = set(sent2[i]) if not isinstance(sent2[i], set) else sent2[i]\n",
    "        \n",
    "        # Calcular la similitud de Jaccard\n",
    "        score = len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Retornar la puntuaciÃ³ mitjana si tenim puntuacions vÃ lides\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando la distancia coseno para calcular la similitud entre dos oraciones\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from typing import List, Union, Optional, Set, Dict, Tuple, Any\n",
    "\n",
    "def one_hot_cosine_similarity(sent1: List[Union[str, Set[str]]], sent2: List[Union[str, Set[str]]], vocabulary: Optional[Dict] = None) -> List[float]:\n",
    "    \"\"\"\n",
    "    Calcula la similitud del coseno entre pares de oracions utilizando representaciÃ³n one-hot encoding\n",
    "    \n",
    "    Args:\n",
    "        sent1: Lista de oraciones tokenizadas (primera oraciÃ³n de cada par)\n",
    "        sent2: Lista de oraciones tokenizadas (segona oraciÃ³n de cada par)\n",
    "        vocabulary: Diccionario opcional para mapear palabras a Ã­ndices\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Lista de puntuaciones de similitud basadas en el coseno\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(sent1)):\n",
    "        # Convertir a conjuntos para facilitar el manejo\n",
    "        set1 = set(sent1[i]) if not isinstance(sent1[i], set) else sent1[i]\n",
    "        set2 = set(sent2[i]) if not isinstance(sent2[i], set) else sent2[i]\n",
    "        \n",
    "        if vocabulary:\n",
    "            # Usar el vocabulario proporcionado\n",
    "            vocab_size = len(vocabulary.token2id)\n",
    "            vec1 = np.zeros(vocab_size)\n",
    "            vec2 = np.zeros(vocab_size)\n",
    "            \n",
    "            for word in set1:\n",
    "                if word in vocabulary.token2id:\n",
    "                    vec1[vocabulary.token2id[word]] = 1\n",
    "                    \n",
    "            for word in set2:\n",
    "                if word in vocabulary.token2id:\n",
    "                    vec2[vocabulary.token2id[word]] = 1\n",
    "        else:\n",
    "            # Crear un vocabulario ad-hoc para este par\n",
    "            all_words = set1.union(set2)\n",
    "            word_to_idx = {word: idx for idx, word in enumerate(all_words)}\n",
    "            \n",
    "            vec1 = np.zeros(len(all_words))\n",
    "            vec2 = np.zeros(len(all_words))\n",
    "            \n",
    "            for word in set1:\n",
    "                vec1[word_to_idx[word]] = 1\n",
    "                \n",
    "            for word in set2:\n",
    "                vec2[word_to_idx[word]] = 1\n",
    "        \n",
    "        # Calcular similitud del coseno\n",
    "        # Si los vectores son cero, asignamos una similitud de 0\n",
    "        norm1 = np.linalg.norm(vec1)\n",
    "        norm2 = np.linalg.norm(vec2)\n",
    "        \n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            cos_sim = np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "            scores.append(cos_sim)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Ejemplo de uso\n",
    "# similitudes = one_hot_cosine_similarity(sentences_1_preproc[:5], sentences_2_preproc[:5], diccionario)\n",
    "# print(similitudes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo regressiÃ³ amb atenciÃ³\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:28:26.049512Z",
     "start_time": "2025-05-23T14:28:26.044611Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Len: 30 30\n",
      "[0, 11, 13, 1, 9, 10, 5, 14, 8, 7, 2, 8, 12, 2, 6, 4, 3, 15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Len:\", max([len(s) for s in sentences_1_preproc]), max([len(s) for s in sentences_2_preproc]))\n",
    "print(list(diccionario.doc2idx(sentences_1_preproc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:30:40.096782Z",
     "start_time": "2025-05-23T14:30:40.079341Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def map_word_embeddings(\n",
    "        sentence: Union[str, List[str]],\n",
    "        sequence_len: int = 32,\n",
    "        fixed_dictionary: Optional[Dictionary] = None\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map to word-embedding indices\n",
    "    :param sentence:\n",
    "    :param sequence_len:\n",
    "    :param fixed_dictionary:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(sentence, list):\n",
    "        sentence_preproc = simple_preprocess(sentence)\n",
    "    else:\n",
    "        sentence_preproc = sentence\n",
    "    _vectors = np.zeros(sequence_len, dtype=np.int32)\n",
    "    index = 0\n",
    "    for word in sentence_preproc:\n",
    "        if fixed_dictionary is not None:\n",
    "            if word in fixed_dictionary.token2id:\n",
    "                # Sumo 1 perquÃ¨ el valor 0 estÃ  reservat a padding\n",
    "                _vectors[index] = fixed_dictionary.token2id[word] + 1\n",
    "                index += 1\n",
    "        else:\n",
    "            if word in wv_model.key_to_index:\n",
    "                _vectors[index] = wv_model.key_to_index[word] + 1\n",
    "                index += 1\n",
    "    return _vectors\n",
    "\n",
    "\n",
    "def map_pairs(\n",
    "        sentence_pairs: List[Tuple[str, str, float]],\n",
    "        sequence_len: int = 32,\n",
    "        fixed_dictionary: Optional[Dictionary] = None\n",
    ") -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    \"\"\"\n",
    "    Mapea els triplets d'oracions a llistes de (x, y), (pares de vectors, score)\n",
    "    :param sentence_pairs:\n",
    "    :param sequence_len:\n",
    "    :param fixed_dictionary:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Mapeig dels paquets d'oracions a paquets de vectors\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        vector1 = map_word_embeddings(sentence_1, sequence_len, fixed_dictionary)\n",
    "        vector2 = map_word_embeddings(sentence_2, sequence_len, fixed_dictionary)\n",
    "        # Afegir a la llista\n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:30:41.100414Z",
     "start_time": "2025-05-23T14:30:41.067881Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([ 1, 12, 14,  2, 10, 11,  6, 15,  9,  8,  3,  9, 13,  3,  7,  5,  4,\n",
      "       16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]), array([10010,     9,  2784,     6,    15,     9,     8,     3,     9,\n",
      "          13,     3,     7,     5,     4,    16,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0])), 3.5)\n"
     ]
    }
   ],
   "source": [
    "# Imprimir els paquets de vectors i la puntuaciÃ³ de similitud associada\n",
    "mapped = map_pairs(sentence_pairs, fixed_dictionary=diccionario if REMAP_EMBEDDINGS else None)\n",
    "# for vectors, similitud in mapped:\n",
    "#     print(f\"Pares de vectores: {vectors[0].shape}, {vectors[1].shape}\")\n",
    "#     print(f\"PuntuaciÃ³ de similitud: {similitud}\")\n",
    "print(mapped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:29:33.314851Z",
     "start_time": "2025-05-23T21:29:33.309646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir constants d'entrenament\n",
    "batch_size: int = 64\n",
    "num_epochs: int = 128\n",
    "# train_val_split variable is no longer needed since we're using the predefined splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:42.790296Z",
     "start_time": "2025-05-23T21:23:42.786818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3073"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:43.042943Z",
     "start_time": "2025-05-23T21:23:43.031829Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (2073, 32), (2073, 32), (2073,)\n",
      "Validation shapes: (500, 32), (500, 32), (500,)\n",
      "Test shapes: (500, 32), (500, 32), (500,)\n",
      "\n",
      "Validation shapes: (500, 32), (500, 32), (500,)\n",
      "Test shapes: (500, 32), (500, 32), (500,)\n"
     ]
    }
   ],
   "source": [
    "# Process each dataset separately\n",
    "# Map train, val, and test sets to word embeddings\n",
    "train_mapped = map_pairs(train_pairs, fixed_dictionary=diccionario if REMAP_EMBEDDINGS else None)\n",
    "val_mapped = map_pairs(val_pairs, fixed_dictionary=diccionario if REMAP_EMBEDDINGS else None)\n",
    "test_mapped = map_pairs(test_pairs, fixed_dictionary=diccionario if REMAP_EMBEDDINGS else None)\n",
    "\n",
    "def pair_list_to_x_y(pair_list: List[Tuple[Tuple[np.ndarray, np.ndarray], int]]) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Otiene las matrices X_1 (N x d) , X_2 (N x d), e Y (n) a partir de listas de parelles de vectors d'oracions - Llistes de (d, d, 1)\n",
    "    :param pair_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    _x, _y = zip(*pair_list)\n",
    "    _x_1, _x_2 = zip(*_x)\n",
    "    return (np.row_stack(_x_1), np.row_stack(_x_2)), np.array(_y) / 5.0\n",
    "\n",
    "# Obtener las listas de train, val i test\n",
    "x_train, y_train = pair_list_to_x_y(train_mapped)\n",
    "x_val, y_val = pair_list_to_x_y(val_mapped)\n",
    "x_test, y_test = pair_list_to_x_y(test_mapped)\n",
    "\n",
    "print(f\"Train shapes: {x_train[0].shape}, {x_train[1].shape}, {y_train.shape}\")\n",
    "print(f\"Validation shapes: {x_val[0].shape}, {x_val[1].shape}, {y_val.shape}\")\n",
    "print(f\"Test shapes: {x_test[0].shape}, {x_test[1].shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:43.233872Z",
     "start_time": "2025-05-23T21:23:43.221808Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\jiawe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe\"\n  * The NumPy version is: \"1.23.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: æ¾ä¸å°æå®çæ¨¡åã\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\__init__.py:23\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\multiarray.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\overrides.py:8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_multiarray_umath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[32m     12\u001b[39m ARRAY_FUNCTIONS = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _multiarray_umath: æ¾ä¸å°æå®çæ¨¡åã",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\__init__.py:49\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     26\u001b[39m     msg = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \u001b[33m\"\"\"\u001b[39m % (sys.version_info[\u001b[32m0\u001b[39m], sys.version_info[\u001b[32m1\u001b[39m], sys.executable,\n\u001b[32m     48\u001b[39m         __version__, exc)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m envkey \u001b[38;5;129;01min\u001b[39;00m env_added:\n",
      "\u001b[31mImportError\u001b[39m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\jiawe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe\"\n  * The NumPy version is: \"1.23.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: æ¾ä¸å°æå®çæ¨¡åã\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "_multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[31mImportError\u001b[39m: _multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check if TensorFlow is properly installed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Preparar els conjunts de dades d'entrenament, validaciÃ³ i test\u001b[39;00m\n\u001b[32m      6\u001b[39m train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m executor\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion_registry\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\framework\\dtypes.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type, Sequence, Optional\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ml_dtypes\\__init__.py:40\u001b[39m\n\u001b[32m     16\u001b[39m __all__ = [\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbfloat16\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muint4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m ]\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_finfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m finfo\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_iinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iinfo\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ml_dtypes\\_finfo.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2023 The ml_dtypes Authors.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float4_e2m1fn\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float6_e2m3fn\n",
      "\u001b[31mImportError\u001b[39m: numpy._core.umath failed to import"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is properly installed and handle compatibility issues with NumPy\n",
    "import tensorflow as tf\n",
    "\n",
    "# Now prepare the datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train[0])).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "print(f\"Batches in train_dataset: {len(list(train_dataset))}\")\n",
    "print(f\"Batches in val_dataset: {len(list(val_dataset))}\")\n",
    "print(f\"Batches in test_dataset: {len(list(test_dataset))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "['AggregationMethod', 'Assert', 'CriticalSection', 'DType', 'DeviceSpec', 'GradientTape', 'Graph', 'IndexedSlices', 'IndexedSlicesSpec', 'Module', 'Operation', 'OptionalSpec', 'RaggedTensor', 'RaggedTensorSpec', 'RegisterGradient', 'SparseTensor', 'SparseTensorSpec', 'Tensor', 'TensorArray', 'TensorArraySpec', 'TensorShape', 'TensorSpec', 'TypeSpec', 'UnconnectedGradients', 'Variable', 'VariableAggregation', 'VariableSynchronization', '_API_MODULE', '_KerasLazyLoader', '__all__', '__builtins__', '__cached__', '__compiler_version__', '__cxx11_abi_flag__', '__cxx_version__', '__doc__', '__file__', '__git_version__', '__internal__', '__loader__', '__monolithic_build__', '__name__', '__operators__', '__package__', '__path__', '__spec__', '__version__', '_api', '_compat', '_current_file_location', '_current_module', '_fi', '_initializers', '_inspect', '_kernel_dir', '_ll', '_losses', '_major_api_version', '_metrics', '_module_dir', '_module_util', '_name', '_names_with_underscore', '_optimizers', '_os', '_plugin_dir', '_pywrap_tensorflow', '_running_from_pip_package', '_s', '_scheme', '_site', '_site_packages_dirs', '_sys', '_sysconfig', '_tf2', '_tf_api_dir', '_tf_dir', '_tf_uses_legacy_keras', 'abs', 'acos', 'acosh', 'add', 'add_n', 'approx_top_k', 'argmax', 'argmin', 'argsort', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_less', 'assert_rank', 'atan', 'atan2', 'atanh', 'audio', 'autodiff', 'autograph', 'batch_to_space', 'bfloat16', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'broadcast_to', 'case', 'cast', 'check_pinned', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'config', 'constant', 'constant_initializer', 'control_dependencies', 'conv', 'conv2d_backprop_filter_v2', 'conv2d_backprop_input_v2', 'convert_to_tensor', 'cos', 'cosh', 'cumsum', 'custom_gradient', 'data', 'debugging', 'device', 'distribute', 'divide', 'double', 'dtensor', 'dtypes', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'eig', 'eigvals', 'einsum', 'ensure_shape', 'equal', 'errors', 'executing_eagerly', 'exp', 'expand_dims', 'experimental', 'extract_volume_patches', 'eye', 'feature_column', 'fftnd', 'fill', 'fingerprint', 'float16', 'float32', 'float64', 'floor', 'foldl', 'foldr', 'function', 'gather', 'gather_nd', 'get_current_name_scope', 'get_logger', 'get_static_value', 'grad_pass_through', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'guarantee_const', 'half', 'hessians', 'histogram_fixed_width', 'histogram_fixed_width_bins', 'identity', 'identity_n', 'ifftnd', 'image', 'import_graph_def', 'init_scope', 'initializers', 'inside_function', 'int16', 'int32', 'int64', 'int8', 'io', 'irfftnd', 'is_symbolic_tensor', 'is_tensor', 'keras', 'less', 'less_equal', 'linalg', 'linspace', 'lite', 'load_library', 'load_op_library', 'logical_and', 'logical_not', 'logical_or', 'lookup', 'losses', 'make_ndarray', 'make_tensor_proto', 'map_fn', 'math', 'matmul', 'matrix_square_root', 'maximum', 'meshgrid', 'metrics', 'minimum', 'mlir', 'multiply', 'name_scope', 'negative', 'nest', 'newaxis', 'nn', 'no_gradient', 'no_op', 'nondifferentiable_batch_function', 'norm', 'not_equal', 'numpy_function', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'optimizers', 'pad', 'parallel_stack', 'pow', 'print', 'profiler', 'py_function', 'qint16', 'qint32', 'qint8', 'quantization', 'queue', 'quint16', 'quint8', 'ragged', 'ragged_fill_empty_rows', 'ragged_fill_empty_rows_grad', 'random', 'random_index_shuffle', 'random_normal_initializer', 'random_uniform_initializer', 'range', 'rank', 'raw_ops', 'realdiv', 'recompute_grad', 'reduce_all', 'reduce_any', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'register_tensor_conversion_function', 'repeat', 'required_space_to_batch_paddings', 'reshape', 'resource', 'reverse', 'reverse_sequence', 'rfftnd', 'roll', 'round', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_nd', 'searchsorted', 'security', 'sequence_mask', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'signal', 'sin', 'sinh', 'size', 'slice', 'sort', 'space_to_batch', 'space_to_batch_nd', 'sparse', 'split', 'sqrt', 'square', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'strings', 'subtract', 'summary', 'switch_case', 'sysconfig', 'tan', 'tanh', 'tensor_scatter_nd_add', 'tensor_scatter_nd_max', 'tensor_scatter_nd_min', 'tensor_scatter_nd_sub', 'tensor_scatter_nd_update', 'tensordot', 'test', 'tile', 'timestamp', 'tools', 'tpu', 'train', 'transpose', 'truediv', 'truncatediv', 'truncatemod', 'tuple', 'type_spec_from_value', 'types', 'uint16', 'uint32', 'uint64', 'uint8', 'unique', 'unique_with_counts', 'unravel_index', 'unstack', 'variable_creator_scope', 'variant', 'vectorized_map', 'version', 'where', 'while_loop', 'xla', 'zeros', 'zeros_initializer', 'zeros_like']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(dir(tf))  # Â¿\"data\" aparece en esta lista?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:43.620561Z",
     "start_time": "2025-05-23T21:23:43.432209Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretrained_weights: Optional[np.ndarray] = None\n",
    "if USE_PRETRAINED:\n",
    "    if REMAP_EMBEDDINGS:\n",
    "        pretrained_weights = np.zeros(\n",
    "            (len(diccionario.token2id) + 1, wv_model.vector_size),  dtype=np.float32)\n",
    "        for token, _id in diccionario.token2id.items():\n",
    "            if token in wv_model:\n",
    "                pretrained_weights[_id + 1] = wv_model[token]\n",
    "            else:\n",
    "                # In W2V, OOV will not have a representation. We will use 0.\n",
    "                pass\n",
    "    else:\n",
    "        # Not recommended (this will consume A LOT of RAM) PORQUE CARGA TODOS LOS VECTORES DEL MODELO.\n",
    "        pretrained_weights = np.zeros((wv_model.vectors.shape[0] + 1, wv_model.vector_size,),  dtype=np.float32)\n",
    "        pretrained_weights[1:, :] = wv_model.vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:43.628885Z",
     "start_time": "2025-05-23T21:23:43.626056Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [-0.0307,  0.0032,  0.0128, ..., -0.0154,  0.0374,  0.0234],\n",
       "       [ 0.0519, -0.0079, -0.0013, ..., -0.0154, -0.0353, -0.0235],\n",
       "       [ 0.0058, -0.0161,  0.062 , ...,  0.0129,  0.019 ,  0.0177],\n",
       "       [-0.042 , -0.0113,  0.0837, ..., -0.0396, -0.0253, -0.0045]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:43.906826Z",
     "start_time": "2025-05-23T21:23:43.899264Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "class SimpleAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: int, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout_s1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.dropout_s2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.W_s1 = tf.keras.layers.Dense(units, activation='tanh', use_bias=True, name=\"attention_transform\")\n",
    "        # Dense layer to compute attention scores (context vector)\n",
    "        self.W_s2 = tf.keras.layers.Dense(1, use_bias=False, name=\"attention_scorer\")\n",
    "        self.supports_masking = True  # Declare that this layer supports masking\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        # inputs shape: (batch_size, sequence_length, embedding_dim)\n",
    "        # mask shape: (batch_size, sequence_length) boolean tensor\n",
    "\n",
    "        # Attention hidden states\n",
    "        hidden_states = self.dropout_s1(self.W_s1(inputs))\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = self.dropout_s2(self.W_s2(hidden_states))\n",
    "\n",
    "        if mask is not None:\n",
    "            # Apply the mask to the scores before softmax\n",
    "            expanded_mask = tf.expand_dims(tf.cast(mask, dtype=tf.float32), axis=-1)\n",
    "            # Add a large negative number to masked (padded) scores\n",
    "            scores += (1.0 - expanded_mask) * -1e9\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = tf.nn.softmax(scores, axis=1)\n",
    "\n",
    "        # Compute the context vector (weighted sum of input embeddings)\n",
    "        context_vector = tf.reduce_sum(inputs * attention_weights, axis=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "    def compute_mask(self, inputs: tf.Tensor, mask: Optional[tf.Tensor] = None) -> Optional[tf.Tensor]:\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_and_compile_model_2(\n",
    "        input_length: int = 32,\n",
    "        dictionary_size: int = 1000,\n",
    "        embedding_size: int = 300,\n",
    "        learning_rate: float = 0.001,\n",
    "        trainable_embedding: bool = False,\n",
    "        pretrained_weights: Optional[np.ndarray] = None,\n",
    "        attention_units: int = 4,\n",
    ") -> tf.keras.Model:\n",
    "    input_1 = tf.keras.Input((input_length,), dtype=tf.int32, name=\"input_1\")\n",
    "    input_2 = tf.keras.Input((input_length,), dtype=tf.int32, name=\"input_2\")\n",
    "\n",
    "    # Determine effective embedding parameters\n",
    "    if pretrained_weights is not None:\n",
    "        effective_dictionary_size = pretrained_weights.shape[0]\n",
    "        effective_embedding_size = pretrained_weights.shape[1]\n",
    "        embedding_initializer = tf.keras.initializers.Constant(pretrained_weights)\n",
    "        is_embedding_trainable = trainable_embedding\n",
    "        embedding_layer_name = \"embedding_pretrained\"\n",
    "    else:\n",
    "        effective_dictionary_size = dictionary_size\n",
    "        effective_embedding_size = embedding_size\n",
    "        embedding_initializer = 'uniform'\n",
    "        is_embedding_trainable = True\n",
    "        embedding_layer_name = \"embedding\"\n",
    "\n",
    "    # Shared Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=effective_dictionary_size,\n",
    "        output_dim=effective_embedding_size,\n",
    "        input_length=input_length,\n",
    "        mask_zero=True,\n",
    "        embeddings_initializer=embedding_initializer,\n",
    "        trainable=is_embedding_trainable,\n",
    "        name=embedding_layer_name\n",
    "    )\n",
    "\n",
    "    # Apply embedding layer to both inputs\n",
    "    embedded_1 = embedding_layer(input_1)  # Shape: (batch_size, input_length, effective_embedding_size)\n",
    "    embedded_2 = embedding_layer(input_2)  # Shape: (batch_size, input_length, effective_embedding_size)\n",
    "\n",
    "    # Shared Attention Layer\n",
    "    # Input: (batch_size, input_length, effective_embedding_size) with a mask\n",
    "    # Output: (batch_size, effective_embedding_size)\n",
    "    sentence_attention_layer = SimpleAttention(units=attention_units, name=\"sentence_attention\")\n",
    "    # sentence_attention_layer = tf.keras.layers.GlobalAveragePooling1D(name=\"sentence_attention_layer\")\n",
    "\n",
    "    sentence_vector_1 = sentence_attention_layer(embedded_1)\n",
    "    sentence_vector_2 = sentence_attention_layer(embedded_2)\n",
    "\n",
    "    # Projection layer\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        effective_embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.2, name=\"projection_dropout\")\n",
    "    projected_1 = dropout(first_projection_layer(sentence_vector_1))\n",
    "    projected_2 = dropout(first_projection_layer(sentence_vector_2))\n",
    "\n",
    "    # Normalize the projected vectors (L2 normalization)\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2)\n",
    "\n",
    "    # Compute Cosine Similarity = X * Y / (||X|| * ||Y||) \n",
    "    similarity_score = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"cosine_similarity\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    # Scale similarity from [-1, 1] to [0, 1]\n",
    "    output_layer = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\"\n",
    "    )(similarity_score)\n",
    "\n",
    "    # Define the Keras Model\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_1, input_2],\n",
    "        outputs=output_layer,\n",
    "        name=\"sequence_similarity_attention_model\"\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=['mae'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:30:21.742746Z",
     "start_time": "2025-05-23T21:29:56.965332Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiahu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.1273 - mae: 0.3187 - val_loss: 0.1514 - val_mae: 0.3556\n",
      "Epoch 2/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.1273 - mae: 0.3187 - val_loss: 0.1514 - val_mae: 0.3556\n",
      "Epoch 2/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0828 - mae: 0.2488 - val_loss: 0.1408 - val_mae: 0.3429\n",
      "Epoch 3/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0828 - mae: 0.2488 - val_loss: 0.1408 - val_mae: 0.3429\n",
      "Epoch 3/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0654 - mae: 0.2159 - val_loss: 0.1345 - val_mae: 0.3357\n",
      "Epoch 4/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0654 - mae: 0.2159 - val_loss: 0.1345 - val_mae: 0.3357\n",
      "Epoch 4/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0621 - mae: 0.2078 - val_loss: 0.1314 - val_mae: 0.3323\n",
      "Epoch 5/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0621 - mae: 0.2078 - val_loss: 0.1314 - val_mae: 0.3323\n",
      "Epoch 5/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0583 - mae: 0.1985 - val_loss: 0.1300 - val_mae: 0.3306\n",
      "Epoch 6/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0583 - mae: 0.1985 - val_loss: 0.1300 - val_mae: 0.3306\n",
      "Epoch 6/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0486 - mae: 0.1782 - val_loss: 0.1272 - val_mae: 0.3267\n",
      "Epoch 7/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0486 - mae: 0.1782 - val_loss: 0.1272 - val_mae: 0.3267\n",
      "Epoch 7/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0493 - mae: 0.1803 - val_loss: 0.1269 - val_mae: 0.3259\n",
      "Epoch 8/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0493 - mae: 0.1803 - val_loss: 0.1269 - val_mae: 0.3259\n",
      "Epoch 8/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0445 - mae: 0.1697 - val_loss: 0.1260 - val_mae: 0.3248\n",
      "Epoch 9/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0445 - mae: 0.1697 - val_loss: 0.1260 - val_mae: 0.3248\n",
      "Epoch 9/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0429 - mae: 0.1653 - val_loss: 0.1254 - val_mae: 0.3238\n",
      "Epoch 10/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0429 - mae: 0.1653 - val_loss: 0.1254 - val_mae: 0.3238\n",
      "Epoch 10/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0435 - mae: 0.1651 - val_loss: 0.1269 - val_mae: 0.3264\n",
      "Epoch 11/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0435 - mae: 0.1651 - val_loss: 0.1269 - val_mae: 0.3264\n",
      "Epoch 11/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0421 - mae: 0.1640 - val_loss: 0.1240 - val_mae: 0.3216\n",
      "Epoch 12/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0421 - mae: 0.1640 - val_loss: 0.1240 - val_mae: 0.3216\n",
      "Epoch 12/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0414 - mae: 0.1624 - val_loss: 0.1267 - val_mae: 0.3260\n",
      "Epoch 13/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0414 - mae: 0.1624 - val_loss: 0.1267 - val_mae: 0.3260\n",
      "Epoch 13/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0391 - mae: 0.1581 - val_loss: 0.1233 - val_mae: 0.3210\n",
      "Epoch 14/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0391 - mae: 0.1581 - val_loss: 0.1233 - val_mae: 0.3210\n",
      "Epoch 14/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0393 - mae: 0.1572 - val_loss: 0.1250 - val_mae: 0.3241\n",
      "Epoch 15/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0393 - mae: 0.1572 - val_loss: 0.1250 - val_mae: 0.3241\n",
      "Epoch 15/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0372 - mae: 0.1558 - val_loss: 0.1235 - val_mae: 0.3215\n",
      "Epoch 16/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0372 - mae: 0.1558 - val_loss: 0.1235 - val_mae: 0.3215\n",
      "Epoch 16/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0392 - mae: 0.1570 - val_loss: 0.1221 - val_mae: 0.3195\n",
      "Epoch 17/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0392 - mae: 0.1570 - val_loss: 0.1221 - val_mae: 0.3195\n",
      "Epoch 17/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0378 - mae: 0.1544 - val_loss: 0.1214 - val_mae: 0.3180\n",
      "Epoch 18/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0378 - mae: 0.1544 - val_loss: 0.1214 - val_mae: 0.3180\n",
      "Epoch 18/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0398 - mae: 0.1592 - val_loss: 0.1220 - val_mae: 0.3188\n",
      "Epoch 19/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0398 - mae: 0.1592 - val_loss: 0.1220 - val_mae: 0.3188\n",
      "Epoch 19/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0385 - mae: 0.1552 - val_loss: 0.1223 - val_mae: 0.3192\n",
      "Epoch 20/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0385 - mae: 0.1552 - val_loss: 0.1223 - val_mae: 0.3192\n",
      "Epoch 20/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0367 - mae: 0.1535 - val_loss: 0.1218 - val_mae: 0.3186\n",
      "Epoch 21/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0367 - mae: 0.1535 - val_loss: 0.1218 - val_mae: 0.3186\n",
      "Epoch 21/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0401 - mae: 0.1571 - val_loss: 0.1222 - val_mae: 0.3190\n",
      "Epoch 22/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0401 - mae: 0.1571 - val_loss: 0.1222 - val_mae: 0.3190\n",
      "Epoch 22/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0369 - mae: 0.1532 - val_loss: 0.1209 - val_mae: 0.3168\n",
      "Epoch 23/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0369 - mae: 0.1532 - val_loss: 0.1209 - val_mae: 0.3168\n",
      "Epoch 23/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0377 - mae: 0.1533 - val_loss: 0.1220 - val_mae: 0.3189\n",
      "Epoch 24/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0377 - mae: 0.1533 - val_loss: 0.1220 - val_mae: 0.3189\n",
      "Epoch 24/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0385 - mae: 0.1552 - val_loss: 0.1235 - val_mae: 0.3209\n",
      "Epoch 25/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0385 - mae: 0.1552 - val_loss: 0.1235 - val_mae: 0.3209\n",
      "Epoch 25/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0379 - mae: 0.1547 - val_loss: 0.1227 - val_mae: 0.3197\n",
      "Epoch 26/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0379 - mae: 0.1547 - val_loss: 0.1227 - val_mae: 0.3197\n",
      "Epoch 26/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0365 - mae: 0.1505 - val_loss: 0.1216 - val_mae: 0.3178\n",
      "Epoch 27/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0365 - mae: 0.1505 - val_loss: 0.1216 - val_mae: 0.3178\n",
      "Epoch 27/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0350 - mae: 0.1479 - val_loss: 0.1225 - val_mae: 0.3188\n",
      "Epoch 28/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0350 - mae: 0.1479 - val_loss: 0.1225 - val_mae: 0.3188\n",
      "Epoch 28/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0340 - mae: 0.1440 - val_loss: 0.1208 - val_mae: 0.3166\n",
      "Epoch 29/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0340 - mae: 0.1440 - val_loss: 0.1208 - val_mae: 0.3166\n",
      "Epoch 29/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1474 - val_loss: 0.1220 - val_mae: 0.3184\n",
      "Epoch 30/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1474 - val_loss: 0.1220 - val_mae: 0.3184\n",
      "Epoch 30/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1455 - val_loss: 0.1204 - val_mae: 0.3160\n",
      "Epoch 31/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1455 - val_loss: 0.1204 - val_mae: 0.3160\n",
      "Epoch 31/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0370 - mae: 0.1535 - val_loss: 0.1217 - val_mae: 0.3175\n",
      "Epoch 32/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0370 - mae: 0.1535 - val_loss: 0.1217 - val_mae: 0.3175\n",
      "Epoch 32/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1443 - val_loss: 0.1232 - val_mae: 0.3202\n",
      "Epoch 33/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1443 - val_loss: 0.1232 - val_mae: 0.3202\n",
      "Epoch 33/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0312 - mae: 0.1410 - val_loss: 0.1215 - val_mae: 0.3178\n",
      "Epoch 34/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0312 - mae: 0.1410 - val_loss: 0.1215 - val_mae: 0.3178\n",
      "Epoch 34/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0330 - mae: 0.1437 - val_loss: 0.1216 - val_mae: 0.3181\n",
      "Epoch 35/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0330 - mae: 0.1437 - val_loss: 0.1216 - val_mae: 0.3181\n",
      "Epoch 35/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0350 - mae: 0.1478 - val_loss: 0.1210 - val_mae: 0.3168\n",
      "Epoch 36/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0350 - mae: 0.1478 - val_loss: 0.1210 - val_mae: 0.3168\n",
      "Epoch 36/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0351 - mae: 0.1486 - val_loss: 0.1221 - val_mae: 0.3184\n",
      "Epoch 37/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0351 - mae: 0.1486 - val_loss: 0.1221 - val_mae: 0.3184\n",
      "Epoch 37/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.1452 - val_loss: 0.1208 - val_mae: 0.3160\n",
      "Epoch 38/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.1452 - val_loss: 0.1208 - val_mae: 0.3160\n",
      "Epoch 38/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1464 - val_loss: 0.1209 - val_mae: 0.3163\n",
      "Epoch 39/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1464 - val_loss: 0.1209 - val_mae: 0.3163\n",
      "Epoch 39/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0313 - mae: 0.1402 - val_loss: 0.1194 - val_mae: 0.3146\n",
      "Epoch 40/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0313 - mae: 0.1402 - val_loss: 0.1194 - val_mae: 0.3146\n",
      "Epoch 40/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.1450 - val_loss: 0.1200 - val_mae: 0.3155\n",
      "Epoch 41/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.1450 - val_loss: 0.1200 - val_mae: 0.3155\n",
      "Epoch 41/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0334 - mae: 0.1447 - val_loss: 0.1212 - val_mae: 0.3175\n",
      "Epoch 42/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0334 - mae: 0.1447 - val_loss: 0.1212 - val_mae: 0.3175\n",
      "Epoch 42/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.1428 - val_loss: 0.1207 - val_mae: 0.3169\n",
      "Epoch 43/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.1428 - val_loss: 0.1207 - val_mae: 0.3169\n",
      "Epoch 43/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0360 - mae: 0.1512 - val_loss: 0.1203 - val_mae: 0.3164\n",
      "Epoch 44/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0360 - mae: 0.1512 - val_loss: 0.1203 - val_mae: 0.3164\n",
      "Epoch 44/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.1422 - val_loss: 0.1186 - val_mae: 0.3136\n",
      "Epoch 45/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.1422 - val_loss: 0.1186 - val_mae: 0.3136\n",
      "Epoch 45/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0327 - mae: 0.1420 - val_loss: 0.1205 - val_mae: 0.3167\n",
      "Epoch 46/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0327 - mae: 0.1420 - val_loss: 0.1205 - val_mae: 0.3167\n",
      "Epoch 46/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1463 - val_loss: 0.1209 - val_mae: 0.3170\n",
      "Epoch 47/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1463 - val_loss: 0.1209 - val_mae: 0.3170\n",
      "Epoch 47/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0333 - mae: 0.1420 - val_loss: 0.1209 - val_mae: 0.3173\n",
      "Epoch 48/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0333 - mae: 0.1420 - val_loss: 0.1209 - val_mae: 0.3173\n",
      "Epoch 48/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0324 - mae: 0.1420 - val_loss: 0.1199 - val_mae: 0.3154\n",
      "Epoch 49/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0324 - mae: 0.1420 - val_loss: 0.1199 - val_mae: 0.3154\n",
      "Epoch 49/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0341 - mae: 0.1423 - val_loss: 0.1191 - val_mae: 0.3141\n",
      "Epoch 50/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0341 - mae: 0.1423 - val_loss: 0.1191 - val_mae: 0.3141\n",
      "Epoch 50/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0305 - mae: 0.1379 - val_loss: 0.1186 - val_mae: 0.3135\n",
      "Epoch 51/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0305 - mae: 0.1379 - val_loss: 0.1186 - val_mae: 0.3135\n",
      "Epoch 51/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1378 - val_loss: 0.1178 - val_mae: 0.3128\n",
      "Epoch 52/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1378 - val_loss: 0.1178 - val_mae: 0.3128\n",
      "Epoch 52/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.1442 - val_loss: 0.1197 - val_mae: 0.3153\n",
      "Epoch 53/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.1442 - val_loss: 0.1197 - val_mae: 0.3153\n",
      "Epoch 53/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1405 - val_loss: 0.1191 - val_mae: 0.3145\n",
      "Epoch 54/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1405 - val_loss: 0.1191 - val_mae: 0.3145\n",
      "Epoch 54/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0311 - mae: 0.1394 - val_loss: 0.1173 - val_mae: 0.3116\n",
      "Epoch 55/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0311 - mae: 0.1394 - val_loss: 0.1173 - val_mae: 0.3116\n",
      "Epoch 55/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0331 - mae: 0.1431 - val_loss: 0.1177 - val_mae: 0.3123\n",
      "Epoch 56/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0331 - mae: 0.1431 - val_loss: 0.1177 - val_mae: 0.3123\n",
      "Epoch 56/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1397 - val_loss: 0.1171 - val_mae: 0.3114\n",
      "Epoch 57/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1397 - val_loss: 0.1171 - val_mae: 0.3114\n",
      "Epoch 57/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0316 - mae: 0.1394 - val_loss: 0.1163 - val_mae: 0.3097\n",
      "Epoch 58/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0316 - mae: 0.1394 - val_loss: 0.1163 - val_mae: 0.3097\n",
      "Epoch 58/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1422 - val_loss: 0.1166 - val_mae: 0.3103\n",
      "Epoch 59/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1422 - val_loss: 0.1166 - val_mae: 0.3103\n",
      "Epoch 59/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0335 - mae: 0.1461 - val_loss: 0.1181 - val_mae: 0.3128\n",
      "Epoch 60/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0335 - mae: 0.1461 - val_loss: 0.1181 - val_mae: 0.3128\n",
      "Epoch 60/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0325 - mae: 0.1425 - val_loss: 0.1157 - val_mae: 0.3089\n",
      "Epoch 61/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0325 - mae: 0.1425 - val_loss: 0.1157 - val_mae: 0.3089\n",
      "Epoch 61/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1399 - val_loss: 0.1188 - val_mae: 0.3135\n",
      "Epoch 62/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1399 - val_loss: 0.1188 - val_mae: 0.3135\n",
      "Epoch 62/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1401 - val_loss: 0.1160 - val_mae: 0.3089\n",
      "Epoch 63/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0321 - mae: 0.1401 - val_loss: 0.1160 - val_mae: 0.3089\n",
      "Epoch 63/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0294 - mae: 0.1338 - val_loss: 0.1161 - val_mae: 0.3089\n",
      "Epoch 64/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0294 - mae: 0.1338 - val_loss: 0.1161 - val_mae: 0.3089\n",
      "Epoch 64/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1366 - val_loss: 0.1181 - val_mae: 0.3126\n",
      "Epoch 65/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1366 - val_loss: 0.1181 - val_mae: 0.3126\n",
      "Epoch 65/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0322 - mae: 0.1418 - val_loss: 0.1135 - val_mae: 0.3051\n",
      "Epoch 66/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0322 - mae: 0.1418 - val_loss: 0.1135 - val_mae: 0.3051\n",
      "Epoch 66/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0290 - mae: 0.1348 - val_loss: 0.1144 - val_mae: 0.3064\n",
      "Epoch 67/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0290 - mae: 0.1348 - val_loss: 0.1144 - val_mae: 0.3064\n",
      "Epoch 67/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0314 - mae: 0.1406 - val_loss: 0.1163 - val_mae: 0.3090\n",
      "Epoch 68/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0314 - mae: 0.1406 - val_loss: 0.1163 - val_mae: 0.3090\n",
      "Epoch 68/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0311 - mae: 0.1386 - val_loss: 0.1139 - val_mae: 0.3053\n",
      "Epoch 69/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0311 - mae: 0.1386 - val_loss: 0.1139 - val_mae: 0.3053\n",
      "Epoch 69/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0312 - mae: 0.1388 - val_loss: 0.1154 - val_mae: 0.3076\n",
      "Epoch 70/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0312 - mae: 0.1388 - val_loss: 0.1154 - val_mae: 0.3076\n",
      "Epoch 70/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0290 - mae: 0.1349 - val_loss: 0.1126 - val_mae: 0.3032\n",
      "Epoch 71/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0290 - mae: 0.1349 - val_loss: 0.1126 - val_mae: 0.3032\n",
      "Epoch 71/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0298 - mae: 0.1368 - val_loss: 0.1119 - val_mae: 0.3023\n",
      "Epoch 72/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0298 - mae: 0.1368 - val_loss: 0.1119 - val_mae: 0.3023\n",
      "Epoch 72/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0330 - mae: 0.1435 - val_loss: 0.1130 - val_mae: 0.3040\n",
      "Epoch 73/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0330 - mae: 0.1435 - val_loss: 0.1130 - val_mae: 0.3040\n",
      "Epoch 73/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0284 - mae: 0.1321 - val_loss: 0.1114 - val_mae: 0.3010\n",
      "Epoch 74/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0284 - mae: 0.1321 - val_loss: 0.1114 - val_mae: 0.3010\n",
      "Epoch 74/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0309 - mae: 0.1383 - val_loss: 0.1118 - val_mae: 0.3016\n",
      "Epoch 75/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0309 - mae: 0.1383 - val_loss: 0.1118 - val_mae: 0.3016\n",
      "Epoch 75/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0293 - mae: 0.1348 - val_loss: 0.1107 - val_mae: 0.2999\n",
      "Epoch 76/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0293 - mae: 0.1348 - val_loss: 0.1107 - val_mae: 0.2999\n",
      "Epoch 76/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0294 - mae: 0.1357 - val_loss: 0.1108 - val_mae: 0.3002\n",
      "Epoch 77/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0294 - mae: 0.1357 - val_loss: 0.1108 - val_mae: 0.3002\n",
      "Epoch 77/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0302 - mae: 0.1360 - val_loss: 0.1101 - val_mae: 0.2992\n",
      "Epoch 78/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0302 - mae: 0.1360 - val_loss: 0.1101 - val_mae: 0.2992\n",
      "Epoch 78/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0289 - mae: 0.1350 - val_loss: 0.1089 - val_mae: 0.2973\n",
      "Epoch 79/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0289 - mae: 0.1350 - val_loss: 0.1089 - val_mae: 0.2973\n",
      "Epoch 79/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0304 - mae: 0.1363 - val_loss: 0.1081 - val_mae: 0.2958\n",
      "Epoch 80/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0304 - mae: 0.1363 - val_loss: 0.1081 - val_mae: 0.2958\n",
      "Epoch 80/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0274 - mae: 0.1305 - val_loss: 0.1091 - val_mae: 0.2974\n",
      "Epoch 81/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0274 - mae: 0.1305 - val_loss: 0.1091 - val_mae: 0.2974\n",
      "Epoch 81/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.1084 - val_mae: 0.2962\n",
      "Epoch 82/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282 - mae: 0.1345 - val_loss: 0.1084 - val_mae: 0.2962\n",
      "Epoch 82/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0305 - mae: 0.1369 - val_loss: 0.1085 - val_mae: 0.2957\n",
      "Epoch 83/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0305 - mae: 0.1369 - val_loss: 0.1085 - val_mae: 0.2957\n",
      "Epoch 83/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282 - mae: 0.1329 - val_loss: 0.1069 - val_mae: 0.2930\n",
      "Epoch 84/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282 - mae: 0.1329 - val_loss: 0.1069 - val_mae: 0.2930\n",
      "Epoch 84/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0278 - mae: 0.1322 - val_loss: 0.1068 - val_mae: 0.2928\n",
      "Epoch 85/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0278 - mae: 0.1322 - val_loss: 0.1068 - val_mae: 0.2928\n",
      "Epoch 85/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0286 - mae: 0.1342 - val_loss: 0.1061 - val_mae: 0.2919\n",
      "Epoch 86/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0286 - mae: 0.1342 - val_loss: 0.1061 - val_mae: 0.2919\n",
      "Epoch 86/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.1063 - val_mae: 0.2924\n",
      "Epoch 87/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1319 - val_loss: 0.1063 - val_mae: 0.2924\n",
      "Epoch 87/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0262 - mae: 0.1278 - val_loss: 0.1049 - val_mae: 0.2900\n",
      "Epoch 88/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0262 - mae: 0.1278 - val_loss: 0.1049 - val_mae: 0.2900\n",
      "Epoch 88/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0290 - mae: 0.1350 - val_loss: 0.1055 - val_mae: 0.2909\n",
      "Epoch 89/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0290 - mae: 0.1350 - val_loss: 0.1055 - val_mae: 0.2909\n",
      "Epoch 89/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0296 - mae: 0.1358 - val_loss: 0.1045 - val_mae: 0.2895\n",
      "Epoch 90/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0296 - mae: 0.1358 - val_loss: 0.1045 - val_mae: 0.2895\n",
      "Epoch 90/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0264 - mae: 0.1288 - val_loss: 0.1031 - val_mae: 0.2866\n",
      "Epoch 91/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0264 - mae: 0.1288 - val_loss: 0.1031 - val_mae: 0.2866\n",
      "Epoch 91/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0274 - mae: 0.1315 - val_loss: 0.1034 - val_mae: 0.2873\n",
      "Epoch 92/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0274 - mae: 0.1315 - val_loss: 0.1034 - val_mae: 0.2873\n",
      "Epoch 92/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0278 - mae: 0.1307 - val_loss: 0.1035 - val_mae: 0.2875\n",
      "Epoch 93/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0278 - mae: 0.1307 - val_loss: 0.1035 - val_mae: 0.2875\n",
      "Epoch 93/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0275 - mae: 0.1296 - val_loss: 0.1031 - val_mae: 0.2864\n",
      "Epoch 94/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0275 - mae: 0.1296 - val_loss: 0.1031 - val_mae: 0.2864\n",
      "Epoch 94/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0287 - mae: 0.1340 - val_loss: 0.1026 - val_mae: 0.2854\n",
      "Epoch 95/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0287 - mae: 0.1340 - val_loss: 0.1026 - val_mae: 0.2854\n",
      "Epoch 95/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0273 - mae: 0.1298 - val_loss: 0.1014 - val_mae: 0.2833\n",
      "Epoch 96/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0273 - mae: 0.1298 - val_loss: 0.1014 - val_mae: 0.2833\n",
      "Epoch 96/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0276 - mae: 0.1312 - val_loss: 0.1027 - val_mae: 0.2851\n",
      "Epoch 97/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0276 - mae: 0.1312 - val_loss: 0.1027 - val_mae: 0.2851\n",
      "Epoch 97/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1300 - val_loss: 0.1025 - val_mae: 0.2846\n",
      "Epoch 98/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1300 - val_loss: 0.1025 - val_mae: 0.2846\n",
      "Epoch 98/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0253 - mae: 0.1265 - val_loss: 0.1026 - val_mae: 0.2847\n",
      "Epoch 99/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0253 - mae: 0.1265 - val_loss: 0.1026 - val_mae: 0.2847\n",
      "Epoch 99/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - mae: 0.1294 - val_loss: 0.1002 - val_mae: 0.2804\n",
      "Epoch 100/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - mae: 0.1294 - val_loss: 0.1002 - val_mae: 0.2804\n",
      "Epoch 100/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1304 - val_loss: 0.1001 - val_mae: 0.2805\n",
      "Epoch 101/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0270 - mae: 0.1304 - val_loss: 0.1001 - val_mae: 0.2805\n",
      "Epoch 101/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0270 - mae: 0.1308 - val_loss: 0.1006 - val_mae: 0.2813\n",
      "Epoch 102/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0270 - mae: 0.1308 - val_loss: 0.1006 - val_mae: 0.2813\n",
      "Epoch 102/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0263 - mae: 0.1274 - val_loss: 0.1005 - val_mae: 0.2812\n",
      "Epoch 103/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0263 - mae: 0.1274 - val_loss: 0.1005 - val_mae: 0.2812\n",
      "Epoch 103/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0271 - mae: 0.1334 - val_loss: 0.0991 - val_mae: 0.2786\n",
      "Epoch 104/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0271 - mae: 0.1334 - val_loss: 0.0991 - val_mae: 0.2786\n",
      "Epoch 104/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0281 - mae: 0.1361 - val_loss: 0.0984 - val_mae: 0.2772\n",
      "Epoch 105/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0281 - mae: 0.1361 - val_loss: 0.0984 - val_mae: 0.2772\n",
      "Epoch 105/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0247 - mae: 0.1241 - val_loss: 0.0991 - val_mae: 0.2778\n",
      "Epoch 106/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0247 - mae: 0.1241 - val_loss: 0.0991 - val_mae: 0.2778\n",
      "Epoch 106/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1235 - val_loss: 0.1003 - val_mae: 0.2797\n",
      "Epoch 107/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1235 - val_loss: 0.1003 - val_mae: 0.2797\n",
      "Epoch 107/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0265 - mae: 0.1291 - val_loss: 0.0994 - val_mae: 0.2790\n",
      "Epoch 108/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0265 - mae: 0.1291 - val_loss: 0.0994 - val_mae: 0.2790\n",
      "Epoch 108/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0255 - mae: 0.1262 - val_loss: 0.0987 - val_mae: 0.2777\n",
      "Epoch 109/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0255 - mae: 0.1262 - val_loss: 0.0987 - val_mae: 0.2777\n",
      "Epoch 109/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0266 - mae: 0.1294 - val_loss: 0.0986 - val_mae: 0.2771\n",
      "Epoch 110/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0266 - mae: 0.1294 - val_loss: 0.0986 - val_mae: 0.2771\n",
      "Epoch 110/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0252 - mae: 0.1283 - val_loss: 0.0984 - val_mae: 0.2767\n",
      "Epoch 111/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0252 - mae: 0.1283 - val_loss: 0.0984 - val_mae: 0.2767\n",
      "Epoch 111/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0243 - mae: 0.1227 - val_loss: 0.0987 - val_mae: 0.2774\n",
      "Epoch 112/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0243 - mae: 0.1227 - val_loss: 0.0987 - val_mae: 0.2774\n",
      "Epoch 112/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0256 - mae: 0.1251 - val_loss: 0.0976 - val_mae: 0.2754\n",
      "Epoch 113/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0256 - mae: 0.1251 - val_loss: 0.0976 - val_mae: 0.2754\n",
      "Epoch 113/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0249 - mae: 0.1256 - val_loss: 0.0982 - val_mae: 0.2767\n",
      "Epoch 114/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0249 - mae: 0.1256 - val_loss: 0.0982 - val_mae: 0.2767\n",
      "Epoch 114/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0258 - mae: 0.1273 - val_loss: 0.0969 - val_mae: 0.2746\n",
      "Epoch 115/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0258 - mae: 0.1273 - val_loss: 0.0969 - val_mae: 0.2746\n",
      "Epoch 115/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0260 - mae: 0.1283 - val_loss: 0.0975 - val_mae: 0.2755\n",
      "Epoch 116/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0260 - mae: 0.1283 - val_loss: 0.0975 - val_mae: 0.2755\n",
      "Epoch 116/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0253 - mae: 0.1265 - val_loss: 0.0986 - val_mae: 0.2775\n",
      "Epoch 117/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0253 - mae: 0.1265 - val_loss: 0.0986 - val_mae: 0.2775\n",
      "Epoch 117/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0249 - mae: 0.1242 - val_loss: 0.0961 - val_mae: 0.2733\n",
      "Epoch 118/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0249 - mae: 0.1242 - val_loss: 0.0961 - val_mae: 0.2733\n",
      "Epoch 118/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1242 - val_loss: 0.0978 - val_mae: 0.2763\n",
      "Epoch 119/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1242 - val_loss: 0.0978 - val_mae: 0.2763\n",
      "Epoch 119/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0245 - mae: 0.1250 - val_loss: 0.0958 - val_mae: 0.2720\n",
      "Epoch 120/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0245 - mae: 0.1250 - val_loss: 0.0958 - val_mae: 0.2720\n",
      "Epoch 120/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1241 - val_loss: 0.0959 - val_mae: 0.2722\n",
      "Epoch 121/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1241 - val_loss: 0.0959 - val_mae: 0.2722\n",
      "Epoch 121/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0217 - mae: 0.1177 - val_loss: 0.0971 - val_mae: 0.2748\n",
      "Epoch 122/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0217 - mae: 0.1177 - val_loss: 0.0971 - val_mae: 0.2748\n",
      "Epoch 122/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0240 - mae: 0.1230 - val_loss: 0.0957 - val_mae: 0.2723\n",
      "Epoch 123/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0240 - mae: 0.1230 - val_loss: 0.0957 - val_mae: 0.2723\n",
      "Epoch 123/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0242 - mae: 0.1229 - val_loss: 0.0955 - val_mae: 0.2713\n",
      "Epoch 124/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0242 - mae: 0.1229 - val_loss: 0.0955 - val_mae: 0.2713\n",
      "Epoch 124/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0243 - mae: 0.1227 - val_loss: 0.0957 - val_mae: 0.2711\n",
      "Epoch 125/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0243 - mae: 0.1227 - val_loss: 0.0957 - val_mae: 0.2711\n",
      "Epoch 125/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0254 - mae: 0.1254 - val_loss: 0.0964 - val_mae: 0.2732\n",
      "Epoch 126/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0254 - mae: 0.1254 - val_loss: 0.0964 - val_mae: 0.2732\n",
      "Epoch 126/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0229 - mae: 0.1208 - val_loss: 0.0949 - val_mae: 0.2701\n",
      "Epoch 127/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0229 - mae: 0.1208 - val_loss: 0.0949 - val_mae: 0.2701\n",
      "Epoch 127/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1248 - val_loss: 0.0958 - val_mae: 0.2717\n",
      "Epoch 128/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - mae: 0.1248 - val_loss: 0.0958 - val_mae: 0.2717\n",
      "Epoch 128/128\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0251 - mae: 0.1256 - val_loss: 0.0946 - val_mae: 0.2694\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0251 - mae: 0.1256 - val_loss: 0.0946 - val_mae: 0.2694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x241bfd78190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir i compilar el model\n",
    "model = build_and_compile_model_2(pretrained_weights=pretrained_weights, learning_rate=1e-3)\n",
    "# Entrenar el model\n",
    "model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:30:21.779796Z",
     "start_time": "2025-05-23T21:30:21.750444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequence_similarity_attention_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequence_similarity_attention_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_1             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â input_2             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â embedding_pretrainâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,937,800</span> â input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_12        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_13        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â sentence_attention  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       â      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,208</span> â embedding_pretraâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleAttention</span>)   â                   â            â not_equal_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "â                     â                   â            â embedding_pretraâ¦ â\n",
       "â                     â                   â            â not_equal_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â projection_layer    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> â sentence_attentiâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â                   â            â sentence_attentiâ¦ â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â projection_dropout  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â projection_layerâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â                   â            â projection_layerâ¦ â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â normalize_1         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â projection_dropoâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â normalize_2         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â projection_dropoâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â cosine_similarity   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â normalize_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â                   â            â normalize_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â output_scaling      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â cosine_similaritâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_1             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â input_2             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â embedding_pretrainâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m300\u001b[0m)   â  \u001b[38;5;34m3,937,800\u001b[0m â input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â\n",
       "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_12        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mNotEqual\u001b[0m)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_13        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mNotEqual\u001b[0m)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â sentence_attention  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       â      \u001b[38;5;34m1,208\u001b[0m â embedding_pretraâ¦ â\n",
       "â (\u001b[38;5;33mSimpleAttention\u001b[0m)   â                   â            â not_equal_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ¦\u001b[0m â\n",
       "â                     â                   â            â embedding_pretraâ¦ â\n",
       "â                     â                   â            â not_equal_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ¦\u001b[0m â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â projection_layer    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       â     \u001b[38;5;34m90,300\u001b[0m â sentence_attentiâ¦ â\n",
       "â (\u001b[38;5;33mDense\u001b[0m)             â                   â            â sentence_attentiâ¦ â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â projection_dropout  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â projection_layerâ¦ â\n",
       "â (\u001b[38;5;33mDropout\u001b[0m)           â                   â            â projection_layerâ¦ â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â normalize_1         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â projection_dropoâ¦ â\n",
       "â (\u001b[38;5;33mLambda\u001b[0m)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â normalize_2         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â projection_dropoâ¦ â\n",
       "â (\u001b[38;5;33mLambda\u001b[0m)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â cosine_similarity   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â normalize_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ¦ â\n",
       "â (\u001b[38;5;33mLambda\u001b[0m)            â                   â            â normalize_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â output_scaling      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â cosine_similaritâ¦ â\n",
       "â (\u001b[38;5;33mLambda\u001b[0m)            â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,212,326</span> (16.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,212,326\u001b[0m (16.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,508</span> (357.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,508\u001b[0m (357.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,937,800</span> (15.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,937,800\u001b[0m (15.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,018</span> (714.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m183,018\u001b[0m (714.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:30:22.150879Z",
     "start_time": "2025-05-23T21:30:21.807767Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "CorrelaciÃ³n de Pearson: 0.4770294564982235\n",
      "CorrelaciÃ³n de Pearson: 0.4770294564982235\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "y_pred = model.predict(x_val)\n",
    "# Calcular la correlaciÃ³n de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlaciÃ³n de Pearson\n",
    "print(f\"CorrelaciÃ³n de Pearson: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:30:22.357279Z",
     "start_time": "2025-05-23T21:30:22.160006Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m65/65\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "CorrelaciÃ³n de Pearson: 0.7141764493478945\n",
      "CorrelaciÃ³n de Pearson: 0.7141764493478945\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este exemple vamos a utilizar el corpus de training.\n",
    "y_pred = model.predict(x_train)\n",
    "# Calcular la correlaciÃ³n de Pearson entre las predicciones i els dades de prova\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_train.flatten())\n",
    "# Imprimir el coeficiente de correlaciÃ³n de Pearson\n",
    "print(f\"CorrelaciÃ³n de Pearson: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:31:00.171648Z",
     "start_time": "2025-05-23T21:31:00.165491Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7   0.25  0.734 0.45  0.4   0.55  0.534 0.5   0.5   0.6  ]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Jaccard scores: 2073, Length of y_train: 2073\n",
      "Train Jaccard Correlation de Pearson: 0.5417092707292863\n",
      "Validation Jaccard Correlation de Pearson: 0.5002332577241272\n"
     ]
    }
   ],
   "source": [
    "# Calculate Jaccard similarity for the train dataset\n",
    "train_jaccard_scores = one_hot_evaluation(train_s1, train_s2)\n",
    "\n",
    "# Convert to numpy array for proper comparison\n",
    "train_jaccard_scores = np.array(train_jaccard_scores)\n",
    "\n",
    "print(f\"Length of Jaccard scores: {len(train_jaccard_scores)}, Length of y_train: {len(y_train)}\")\n",
    "\n",
    "# Now both arrays should have the same length\n",
    "correlation, p_value = pearsonr(train_jaccard_scores, y_train.flatten())\n",
    "print(f\"Train Jaccard Correlation de Pearson: {correlation}\")\n",
    "\n",
    "# Also calculate for validation\n",
    "val_jaccard_scores = one_hot_evaluation(val_s1, val_s2)\n",
    "val_jaccard_scores = np.array(val_jaccard_scores)\n",
    "val_correlation, val_p_value = pearsonr(val_jaccard_scores, y_val.flatten())\n",
    "print(f\"Validation Jaccard Correlation de Pearson: {val_correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Cosine scores: 2073, Length of y_train: 2073\n",
      "Train Cosine Correlation de Pearson: 0.5519919131699983\n",
      "Validation Cosine Correlation de Pearson: 0.5074905114012317\n",
      "\n",
      "Train Cosine Correlation de Pearson: 0.5519919131699983\n",
      "Validation Cosine Correlation de Pearson: 0.5074905114012317\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for the train dataset\n",
    "train_cosine_scores = one_hot_cosine_similarity(train_s1, train_s2)\n",
    "\n",
    "# Convert to numpy array for proper comparison\n",
    "train_cosine_scores = np.array(train_cosine_scores)\n",
    "\n",
    "print(f\"Length of Cosine scores: {len(train_cosine_scores)}, Length of y_train: {len(y_train)}\")\n",
    "\n",
    "# Now both arrays should have the same length\n",
    "correlation, p_value = pearsonr(train_cosine_scores, y_train.flatten())\n",
    "print(f\"Train Cosine Correlation de Pearson: {correlation}\")\n",
    "\n",
    "# Also calculate for validation with the same method (cosine similarity)\n",
    "val_cosine_scores = one_hot_cosine_similarity(val_s1, val_s2)\n",
    "val_cosine_scores = np.array(val_cosine_scores)\n",
    "val_correlation, val_p_value = pearsonr(val_cosine_scores, y_val.flatten())\n",
    "print(f\"Validation Cosine Correlation de Pearson: {val_correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "- Model difÃ­cil de millorar\n",
    "- Truncar les mesures dels embeddings extreient les paraules que pertanyen al corpus (cuidado amb overfitting al train).\n",
    "- AgregaciÃ³ amb altres TF-IDF. (Modificant la capa AtenciÃ³)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExperimentaciÃ³ amb diferents dimensions de embeddings\n",
    "\n",
    "Per estudiar com varia la capacitat del model segons la mida dels word embeddings, crearem versions reduÃ¯des dels embeddings amb diferents dimensions (50, 100, 150) i compararem el seu rendiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando versiones reducidas de los embeddings (2000000 palabras)...\n",
      "Creando modelo de 50 dimensiones...\n",
      "Modelo de 50d creado. Ejemplo: 'casa' tiene forma (50,)\n",
      "Creando modelo de 100 dimensiones...\n",
      "Modelo de 50d creado. Ejemplo: 'casa' tiene forma (50,)\n",
      "Creando modelo de 100 dimensiones...\n",
      "Modelo de 100d creado. Ejemplo: 'casa' tiene forma (100,)\n",
      "Creando modelo de 150 dimensiones...\n",
      "Modelo de 100d creado. Ejemplo: 'casa' tiene forma (100,)\n",
      "Creando modelo de 150 dimensiones...\n",
      "Modelo de 150d creado. Ejemplo: 'casa' tiene forma (150,)\n",
      "Tiempo total para crear modelos reducidos: 125.02 segundos\n",
      "\n",
      "DimensiÃ³n 50:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (50,))\n",
      "\n",
      "DimensiÃ³n 100:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (100,))\n",
      "\n",
      "DimensiÃ³n 150:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (150,))\n",
      "Modelo de 150d creado. Ejemplo: 'casa' tiene forma (150,)\n",
      "Tiempo total para crear modelos reducidos: 125.02 segundos\n",
      "\n",
      "DimensiÃ³n 50:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (50,))\n",
      "\n",
      "DimensiÃ³n 100:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (100,))\n",
      "\n",
      "DimensiÃ³n 150:\n",
      "Palabra 'casa' - Vector: [-0.0359 -0.0161 -0.0268  0.0022 -0.0873]... (forma: (150,))\n"
     ]
    }
   ],
   "source": [
    "# Crear versions reduÃ¯des de los word embeddings\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# FunciÃ³n para crear embeddings de dimensiÃ³n reducida\n",
    "def create_reduced_embeddings(original_model, dimensions=[50, 100, 150]):\n",
    "    \"\"\"\n",
    "    Crea versiones reducidas de los word embeddings originales.\n",
    "    \n",
    "    Args:\n",
    "        original_model: Modelo de word embeddings original\n",
    "        dimensions: Lista de dimensiones a las que reducir los embeddings\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con los modelos reducidos (key: dimensiÃ³n, value: modelo)\n",
    "    \"\"\"\n",
    "    reduced_models = {}\n",
    "    \n",
    "    print(f\"Creando versiones reducidas de los embeddings ({len(original_model.index_to_key)} palabras)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"Creando modelo de {dim} dimensiones...\")\n",
    "        # Utilizamos defaultdict para evitar KeyError cuando busquemos palabras\n",
    "        reduced_model = defaultdict(lambda: np.zeros(dim))\n",
    "        \n",
    "        # Solo procesamos las primer\n",
    "        for word in original_model.index_to_key:\n",
    "            reduced_model[word] = original_model[word][:dim]\n",
    "        \n",
    "        reduced_models[dim] = reduced_model\n",
    "        print(f\"Modelo de {dim}d creado. Ejemplo: 'casa' tiene forma {reduced_model['casa'].shape}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Tiempo total para crear modelos reducidos: {elapsed_time:.2f} segundos\")\n",
    "    \n",
    "    return reduced_models\n",
    "\n",
    "# Crear modelos con dimensiones reducidas\n",
    "reduced_models = create_reduced_embeddings(wv_model)\n",
    "\n",
    "# Verificar algunos vectores para confirmar que la reducciÃ³n funciona\n",
    "for dim in reduced_models:\n",
    "    print(f\"\\nDimensiÃ³n {dim}:\")\n",
    "    test_word = \"casa\" if \"casa\" in wv_model else wv_model.index_to_key[0]\n",
    "    print(f\"Palabra '{test_word}' - Vector: {reduced_models[dim][test_word][:5]}... (forma: {reduced_models[dim][test_word].shape})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

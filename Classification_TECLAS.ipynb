{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277ddaed",
   "metadata": {},
   "source": [
    "# Clasificación de Texto con el Dataset TECLA\n",
    "\n",
    "Este notebook demuestra cómo cargar y utilizar el dataset TECLA de Hugging Face para tareas de clasificación de texto en catalán.\n",
    "\n",
    "TECLA (TEChniques for LAnguage processing) es un dataset diseñado para tareas de clasificación de texto en catalán."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f385c05",
   "metadata": {},
   "source": [
    "## Instalación de Dependencias\n",
    "\n",
    "Antes de comenzar, instale las bibliotecas requeridas ejecutando el siguiente comando en su terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8849c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecuta uno de los comandos anteriores para instalar las dependencias.\n",
      "Descomenta la línea correspondiente a tu sistema y necesidades.\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta este comando para instalar todas las dependencias necesarias\n",
    "# Puedes ejecutarlo directamente en una celda del notebook con el prefijo !\n",
    "\n",
    "#!pip install -U transformers datasets torch numpy pandas matplotlib seaborn scikit-learn accelerate\n",
    "\n",
    "# Si prefieres ejecutarlo en tu terminal (sin el prefijo !), usa:\n",
    "# pip install -U transformers datasets torch numpy pandas matplotlib seaborn scikit-learn accelerate\n",
    "\n",
    "# Si estás utilizando una GPU y quieres instalar PyTorch con soporte para CUDA:\n",
    "# Para CUDA 11.8 (ajusta segons la teva versió de CUDA):\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Per a un entorn conda, pots fer servir:\n",
    "# conda install -c huggingface -c conda-forge transformers datasets pytorch numpy pandas matplotlib seaborn scikit-learn accelerate\n",
    "\n",
    "print(\"Ejecuta uno de los comandos anteriores para instalar las dependencias.\")\n",
    "print(\"Descomenta la línea correspondiente a tu sistema y necesidades.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02577f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves del dataset: dict_keys(['train', 'validation', 'test'])\n",
      "Tamaño del conjunto de entrenamiento: 90700\n",
      "Tamaño del conjunto de validación: 5669\n",
      "Tamaño del conjunto de prueba: 17007\n",
      "\n",
      "Columnas disponibles: ['sentence', 'label1', 'label2']\n",
      "\n",
      "Ejemplo de los datos:\n",
      "{'sentence': \"L'ACA reactiva el retorn del cànon de l'aigua que s'envia a Tarragona i millorarà l'eficiència del canal de l'esquerra. L'obra corregirà pèrdues d'aigua a la sèquia del Cementiri de Deltebre amb una inversió de 900.000 euros. Després d'alguns exercici de paràlisi, la Comunitat de Regants de l'Esquerra de l'Ebre i l'ACA han signat, aquest dilluns, un nou conveni per reactivar obres de millora de l'eficiència d'infraestructures de reg i evitar la pèrdua d'aigua. Les actuacions començaran al febrer de l'any que ve en un tram de 4,9 quilòmetres de la sèquia del Cementiri, al terme municipal de Deltebre (Baix Ebre).Es col·locaran plaques i llits de graves, làmines de geotèxtil, i es revestiran més de 3 quilòmetres de la sèquia. Els 900.000 euros provenen del 20% del cànon de derivació de l'aigua que paga Tarragona i que s'estipula que s'ha de revertir al territori.\", 'label1': 'Economia', 'label2': 'Agroalimentació'}\n",
      "\n",
      "Número de clases en label1: 4\n",
      "Clases disponibles en label1: {'Societat', 'Cultura', 'Economia', 'Política'}\n",
      "\n",
      "Número de clases en label2: 53\n",
      "Clases disponibles en label2: {'Parlament', 'Religió', 'Trànsit', 'Equipaments i patrimoni', 'Urbanisme', 'Moviments socials', 'Judicial', 'Finances', 'Medi ambient', 'Universitats', 'Successos', 'Salut', 'Indústria', 'Política municipal', 'Habitatge', 'Cinema', 'Teatre', 'Hisenda', 'Govern espanyol', 'Govern', 'Educació', 'Immigració', 'Gastronomia', 'Esports', 'Innovació', 'Mobilitat', 'Agroalimentació', 'Infraestructures', 'Partits', 'Entitats', 'Lletres', 'Memòria històrica', 'Moda', 'Energia', 'Exteriors', 'Policial', 'Turisme', 'Festa i cultura popular', 'Treball', 'Música', 'Unió Europea', 'Serveis Socials', 'Recerca', 'Castells', 'Noves tecnologies', 'Logística', 'Comptes públics', 'Empresa', 'Cooperació', 'Arts', 'Comerç', 'Llengua', 'Meteorologia'}\n",
      "\n",
      "Distribución de label1:\n",
      "Societat: 36906 (40.69%)\n",
      "Política: 25568 (28.19%)\n",
      "Economia: 16305 (17.98%)\n",
      "Cultura: 11921 (13.14%)\n",
      "\n",
      "Distribución de label2:\n",
      "Partits: 10055 (11.09%)\n",
      "Successos: 7874 (8.68%)\n",
      "Govern: 6506 (7.17%)\n",
      "Judicial: 5789 (6.38%)\n",
      "Policial: 5557 (6.13%)\n",
      "Salut: 5430 (5.99%)\n",
      "Parlament: 4177 (4.61%)\n",
      "Agroalimentació: 3236 (3.57%)\n",
      "Medi ambient: 3028 (3.34%)\n",
      "Música: 2872 (3.17%)\n",
      "Educació: 2757 (3.04%)\n",
      "Empresa: 2699 (2.98%)\n",
      "Política municipal: 2094 (2.31%)\n",
      "Arts: 1989 (2.19%)\n",
      "Infraestructures: 1741 (1.92%)\n",
      "Serveis Socials: 1683 (1.86%)\n",
      "Treball: 1657 (1.83%)\n",
      "Mobilitat: 1625 (1.79%)\n",
      "Cinema: 1560 (1.72%)\n",
      "Teatre: 1493 (1.65%)\n",
      "Turisme: 1232 (1.36%)\n",
      "Equipaments i patrimoni: 1230 (1.36%)\n",
      "Unió Europea: 1186 (1.31%)\n",
      "Lletres: 1181 (1.30%)\n",
      "Meteorologia: 1080 (1.19%)\n",
      "Govern espanyol: 985 (1.09%)\n",
      "Comerç: 984 (1.08%)\n",
      "Festa i cultura popular: 890 (0.98%)\n",
      "Trànsit: 865 (0.95%)\n",
      "Finances: 774 (0.85%)\n",
      "Universitats: 749 (0.83%)\n",
      "Habitatge: 722 (0.80%)\n",
      "Esports: 498 (0.55%)\n",
      "Recerca: 470 (0.52%)\n",
      "Entitats: 432 (0.48%)\n",
      "Noves tecnologies: 428 (0.47%)\n",
      "Energia: 416 (0.46%)\n",
      "Religió: 314 (0.35%)\n",
      "Llengua: 286 (0.32%)\n",
      "Moviments socials: 282 (0.31%)\n",
      "Cooperació: 250 (0.28%)\n",
      "Indústria: 233 (0.26%)\n",
      "Castells: 231 (0.25%)\n",
      "Comptes públics: 206 (0.23%)\n",
      "Immigració: 189 (0.21%)\n",
      "Gastronomia: 189 (0.21%)\n",
      "Exteriors: 133 (0.15%)\n",
      "Innovació: 114 (0.13%)\n",
      "Memòria històrica: 91 (0.10%)\n",
      "Urbanisme: 86 (0.09%)\n",
      "Logística: 80 (0.09%)\n",
      "Moda: 53 (0.06%)\n",
      "Hisenda: 19 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de projecte-aina/tecla desde Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset TECLA\n",
    "tecla_dataset = load_dataset(\"projecte-aina/tecla\")\n",
    "\n",
    "# Mostrar información sobre el dataset\n",
    "print(f\"Claves del dataset: {tecla_dataset.keys()}\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(tecla_dataset['train'])}\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(tecla_dataset['validation'])}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(tecla_dataset['test'])}\")\n",
    "\n",
    "# Mostrar las columnas disponibles en el dataset\n",
    "print(f\"\\nColumnas disponibles: {tecla_dataset['train'].column_names}\")\n",
    "\n",
    "# Mostrar un ejemplo de los datos\n",
    "print(\"\\nEjemplo de los datos:\")\n",
    "print(tecla_dataset['train'][0])\n",
    "\n",
    "# Explorar las clases/etiquetas disponibles para label1 y label2\n",
    "label1_values = set(tecla_dataset['train']['label1'])\n",
    "label2_values = set(tecla_dataset['train']['label2'])\n",
    "\n",
    "print(f\"\\nNúmero de clases en label1: {len(label1_values)}\")\n",
    "print(f\"Clases disponibles en label1: {label1_values}\")\n",
    "\n",
    "print(f\"\\nNúmero de clases en label2: {len(label2_values)}\")\n",
    "print(f\"Clases disponibles en label2: {label2_values}\")\n",
    "\n",
    "# Ver la distribución de las etiquetas\n",
    "print(\"\\nDistribución de label1:\")\n",
    "label1_counts = {}\n",
    "for label in tecla_dataset['train']['label1']:\n",
    "    label1_counts[label] = label1_counts.get(label, 0) + 1\n",
    "for label, count in sorted(label1_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{label}: {count} ({count/len(tecla_dataset['train'])*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nDistribución de label2:\")\n",
    "label2_counts = {}\n",
    "for label in tecla_dataset['train']['label2']:\n",
    "    label2_counts[label] = label2_counts.get(label, 0) + 1\n",
    "for label, count in sorted(label2_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{label}: {count} ({count/len(tecla_dataset['train'])*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db16e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using model: projecte-aina/roberta-base-ca-v2-cased-sts\n",
      "Classification target: label1\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas esenciales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Verificar si CUDA está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Definir el modelo preentrenado para catalán\n",
    "model_name = \"projecte-aina/roberta-base-ca-v2-cased-sts\"\n",
    "print(f\"Using model: {model_name}\")\n",
    "\n",
    "# Nos centraremos en label1 para esta tarea de clasificación\n",
    "# Puedes cambiar a label2 si lo necesitas\n",
    "target_label = \"label1\"\n",
    "print(f\"Classification target: {target_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c176b3",
   "metadata": {},
   "source": [
    "## Enfoque Simplificado con Pipeline\n",
    "\n",
    "En lugar de realizar un proceso completo de entrenamiento manual, utilizamos directamente la pipeline de Hugging Face para clasificación de texto, lo que simplifica considerablemente el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para clasificar en 4 categorías de label1:\n",
      "  0: Cultura\n",
      "  1: Economia\n",
      "  2: Política\n",
      "  3: Societat\n",
      "Cargando el modelo base y ajustando para clasificación...\n",
      "Cargando el modelo base y ajustando para clasificación...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2-cased-sts and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([1, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_16744\\24078910.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_16744\\24078910.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo se ha cargado con 4 etiquetas de salida\n",
      "Tipo de problema configurado: single_label_classification\n",
      "Configurando parámetros de entrenamiento...\n",
      "Creando el entrenador...\n",
      "Iniciando entrenamiento del modelo...\n",
      "Iniciando entrenamiento del modelo...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='11338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   13/11338 02:37 < 45:05:45, 0.07 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enfoque para clasificación de texto usando las categorías específicas de TECLA\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Desactivar TensorFlow para evitar errores\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "\n",
    "try:\n",
    "    # Preparar el dataset para entrenamiento\n",
    "    # Vamos a entrenar un modelo específico para label1\n",
    "    label_column = target_label  # Podemos usar 'label1' o 'label2'\n",
    "    \n",
    "    # Obtener etiquetas únicas del dataset\n",
    "    labels = sorted(list(set(tecla_dataset['train'][label_column])))\n",
    "    label2id = {label: i for i, label in enumerate(labels)}\n",
    "    id2label = {i: label for i, label in enumerate(labels)}\n",
    "    num_labels = len(labels)\n",
    "    \n",
    "    print(f\"Entrenando modelo para clasificar en {num_labels} categorías de {label_column}:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"  {i}: {label}\")\n",
    "    \n",
    "    # Función para tokenizar y preparar el dataset\n",
    "    def tokenize_and_prepare(examples):\n",
    "        # Tokenizar los textos\n",
    "        tokenized = tokenizer(\n",
    "            examples[\"sentence\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        # Añadir las etiquetas numéricas\n",
    "        tokenized[\"labels\"] = [label2id[label] for label in examples[label_column]]\n",
    "        return tokenized\n",
    "    \n",
    "    # Cargar y preparar los datos\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Aplicar la tokenización a los datasets\n",
    "    tokenized_train = tecla_dataset[\"train\"].map(tokenize_and_prepare, batched=True)\n",
    "    tokenized_val = tecla_dataset[\"validation\"].map(tokenize_and_prepare, batched=True)\n",
    "    \n",
    "    # Función para calcular métricas\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        correct = predictions == labels\n",
    "        accuracy = correct.mean()\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # Cargar modelo pre-entrenado y configurarlo para nuestra tarea\n",
    "    print(\"Cargando el modelo base y ajustando para clasificación...\")\n",
    "    \n",
    "    # SOLUCIÓN: Configurar explícitamente para clasificación\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        problem_type=\"single_label_classification\"  # Especificar que es clasificación\n",
    "    )\n",
    "    \n",
    "    # Forzar el tipo de problema para asegurar que use CrossEntropyLoss\n",
    "    model.config.problem_type = \"single_label_classification\"\n",
    "    \n",
    "    print(f\"El modelo se ha cargado con {num_labels} etiquetas de salida\")\n",
    "    print(f\"Tipo de problema configurado: {model.config.problem_type}\")\n",
    "    \n",
    "    # Configuración de entrenamiento optimizada\n",
    "    print(\"Configurando parámetros de entrenamiento...\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=2,  # Reducido para pruebas más rápidas\n",
    "        per_device_train_batch_size=16,  # Aumentado para mayor eficiencia\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_steps=200,  # Reducido\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=100,\n",
    "        save_steps=1000,\n",
    "        eval_steps=500,  # Añadido para evaluación durante entrenamiento\n",
    "        eval_strategy=\"steps\",  # CORREGIDO: eval_strategy en lugar de evaluation_strategy\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "        greater_is_better=True,\n",
    "        do_eval=True,\n",
    "        do_train=True,\n",
    "        report_to=None,  # Deshabilitar wandb/tensorboard para simplificar\n",
    "    )\n",
    "    \n",
    "    # Crear el Trainer\n",
    "    print(\"Creando el entrenador...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,  # Añadir tokenizer\n",
    "    )\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    print(\"Iniciando entrenamiento del modelo...\")\n",
    "    trainer.train()\n",
    "    print(\"Entrenamiento completado!\")\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    print(\"Evaluando el modelo...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Resultados de evaluación: {eval_results}\")\n",
    "    \n",
    "    # Guardar el modelo entrenado\n",
    "    model_save_path = f\"./tecla_{label_column}_classifier\"\n",
    "    trainer.save_model(model_save_path)  # Usar trainer.save_model en lugar de model.save_pretrained\n",
    "    print(f\"Modelo guardado en {model_save_path}\")\n",
    "    \n",
    "    # Ejemplos para probar la clasificación\n",
    "    examples = [\n",
    "        \"El govern ha aprovat avui un nou decret llei per regular els preus del lloguer a les grans ciutats.\",\n",
    "        \"La nova exposició al MNAC presenta més de 100 obres inèdites del modernisme català.\",\n",
    "        \"L'empresa tecnològica ha anunciat la creació de 200 nous llocs de treball a Barcelona.\",\n",
    "        \"Els estudiants han sortit al carrer per protestar contra les retallades en educació.\"\n",
    "    ]\n",
    "    \n",
    "    # Clasificar los ejemplos usando el modelo directamente\n",
    "    print(f\"\\nClasificació d'exemples en categories de {label_column}:\")\n",
    "    model.eval()  # Poner el modelo en modo evaluación\n",
    "    \n",
    "    for text in examples:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            label_id = torch.argmax(predictions, dim=-1).item()\n",
    "        \n",
    "        predicted_label = id2label[label_id]\n",
    "        confidence = predictions[0, label_id].item()\n",
    "        print(f\"\\nTexto: {text[:100]}...\")\n",
    "        print(f\"Categoría predicha: {predicted_label}, Confianza: {confidence:.4f}\")\n",
    "    \n",
    "    # Clasificar algunos ejemplos del conjunto de prueba\n",
    "    print(f\"\\nClasificación de ejemplos del conjunto de prueba en categorías de {label_column}:\")\n",
    "    for i in range(5):  # Mostrar 5 ejemplos\n",
    "        text = tecla_dataset[\"test\"][i][\"sentence\"]\n",
    "        true_label = tecla_dataset[\"test\"][i][label_column]\n",
    "        \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            label_id = torch.argmax(predictions, dim=-1).item()\n",
    "        \n",
    "        predicted_label = id2label[label_id]\n",
    "        confidence = predictions[0, label_id].item()\n",
    "        \n",
    "        print(f\"\\nEjemplo {i+1}:\")\n",
    "        print(f\"Texto: {text[:100]}...\")\n",
    "        print(f\"Categoría real: {true_label}\")\n",
    "        print(f\"Categoría predicha: {predicted_label}, Confianza: {confidence:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante el entrenamiento o clasificación: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82054ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUACIÓN COMPLETA DEL CONJUNTO DE VALIDACIÓN\n",
      "================================================================================\n",
      "Procesando 5669 ejemplos del conjunto de validación en lotes de 32...\n",
      "Procesado hasta el ejemplo 32/5669\n",
      "Procesado hasta el ejemplo 32/5669\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Realizar las predicciones\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     32\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     33\u001b[0m     batch_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1202\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03mtoken_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m    Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1214\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:869\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    867\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 869\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    882\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:618\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    608\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    609\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    615\u001b[0m         output_attentions,\n\u001b[0;32m    616\u001b[0m     )\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:507\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    497\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:434\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    426\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    433\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 434\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    444\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:325\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    323\u001b[0m     key_layer, value_layer \u001b[38;5;241m=\u001b[39m past_key_value\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    326\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(current_states))\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- EVALUACIÓN COMPLETA DEL CONJUNTO DE VALIDACIÓN ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACIÓN COMPLETA DEL CONJUNTO DE VALIDACIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Predecir para todo el conjunto de validación\n",
    "    val_texts = tecla_dataset[\"validation\"][\"sentence\"]\n",
    "    val_true_labels = tecla_dataset[\"validation\"][label_column]\n",
    "    \n",
    "    # Convertir las etiquetas reales a IDs numéricos\n",
    "    val_true_label_ids = [label2id[label] for label in val_true_labels]\n",
    "    \n",
    "    # Inicializar listas para almacenar predicciones\n",
    "    val_predictions = []\n",
    "    \n",
    "    # Procesar el conjunto de validación en lotes para mayor eficiencia\n",
    "    batch_size = 32\n",
    "    print(f\"Procesando {len(val_texts)} ejemplos del conjunto de validación en lotes de {batch_size}...\")\n",
    "    \n",
    "    for i in range(0, len(val_texts), batch_size):\n",
    "        batch_texts = val_texts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenizar los textos\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        # Mover a la GPU si está disponible\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Realizar las predicciones\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        # Añadir las predicciones a la lista\n",
    "        val_predictions.extend(batch_predictions)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        if (i // batch_size) % 10 == 0:\n",
    "            print(f\"Procesado hasta el ejemplo {i+len(batch_texts)}/{len(val_texts)}\")\n",
    "    \n",
    "    # Calcular métricas\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "    \n",
    "    accuracy = accuracy_score(val_true_label_ids, val_predictions)\n",
    "    print(f\"\\nExactitud (Accuracy) en el conjunto de validación: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generar informe de clasificación\n",
    "    print(\"\\nInforme de clasificación:\")\n",
    "    print(classification_report(val_true_label_ids, val_predictions, target_names=labels))\n",
    "    \n",
    "    # Crear y mostrar matriz de confusión\n",
    "    conf_matrix = confusion_matrix(val_true_label_ids, val_predictions)\n",
    "    \n",
    "    # Visualizar la matriz de confusión\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.title(f'Matriz de Confusión - Conjunto de Validación ({label_column})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analizar errores\n",
    "    print(\"\\nAnálisis de ejemplos mal clasificados:\")\n",
    "    \n",
    "    # Encontrar ejemplos mal clasificados\n",
    "    misclassified_indices = [i for i, (true, pred) in enumerate(zip(val_true_label_ids, val_predictions)) if true != pred]\n",
    "    \n",
    "    # Mostrar algunos ejemplos mal clasificados\n",
    "    num_examples = min(5, len(misclassified_indices))\n",
    "    \n",
    "    if num_examples > 0:\n",
    "        for i in range(num_examples):\n",
    "            idx = misclassified_indices[i]\n",
    "            text = val_texts[idx]\n",
    "            true_label = val_true_labels[idx]\n",
    "            pred_label = id2label[val_predictions[idx]]\n",
    "            \n",
    "            print(f\"\\nEjemplo mal clasificado {i+1}:\")\n",
    "            print(f\"Texto: {text[:150]}...\")\n",
    "            print(f\"Etiqueta real: {true_label}\")\n",
    "            print(f\"Etiqueta predicha: {pred_label}\")\n",
    "            print(\"-\"*50)\n",
    "    else:\n",
    "        print(\"¡No se encontraron ejemplos mal clasificados!\")\n",
    "    \n",
    "    # Guardar métricas y resultados\n",
    "    results = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": conf_matrix.tolist(),\n",
    "        \"num_examples\": len(val_texts),\n",
    "        \"num_misclassified\": len(misclassified_indices)\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(f\"validation_metrics_{label_column}.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)    \n",
    "    print(f\"\\nLos resultados se han guardado en 'validation_metrics_{label_column}.json'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error durante la evaluación: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375922d",
   "metadata": {},
   "source": [
    "## Resultados de Evaluación\n",
    "\n",
    "Se ha evaluado el modelo entrenado en el conjunto de validación completo. Los resultados principales incluyen:\n",
    "\n",
    "1. **Exactitud (Accuracy)**: Porcentaje de ejemplos correctamente clasificados\n",
    "2. **Informe de clasificación**: Métricas de precisión, recall y F1-score para cada categoría\n",
    "3. **Matriz de confusión**: Visualización de predicciones correctas vs incorrectas\n",
    "4. **Análisis de errores**: Ejemplos de textos mal clasificados para identificar limitaciones del modelo\n",
    "\n",
    "Estas métricas permiten evaluar la calidad y fiabilidad del modelo para la tarea de clasificación en catalán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización adicional de resultados\n",
    "\n",
    "# Cargar los resultados si existen\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "result_file = f\"validation_metrics_{target_label}.json\"\n",
    "\n",
    "if os.path.exists(result_file):\n",
    "    with open(result_file, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Mostrar un resumen visual de los resultados\n",
    "    print(f\"Resumen de evaluación para clasificación de {target_label}:\")\n",
    "    print(f\"Exactitud (Accuracy): {results['accuracy']:.4f}\")\n",
    "    print(f\"Total de ejemplos evaluados: {results['num_examples']}\")\n",
    "    print(f\"Ejemplos mal clasificados: {results['num_misclassified']}\")\n",
    "    \n",
    "    # Crear un gráfico de barras para la exactitud por clase\n",
    "    # Esto requeriría datos adicionales, pero podemos hacer una visualización simple\n",
    "    if 'confusion_matrix' in results:\n",
    "        conf_matrix = np.array(results['confusion_matrix'])\n",
    "        class_accuracy = np.diag(conf_matrix) / conf_matrix.sum(axis=1)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(labels, class_accuracy, color='skyblue')\n",
    "        plt.axhline(y=results['accuracy'], color='r', linestyle='-', label=f'Exactitud global: {results[\"accuracy\"]:.4f}')\n",
    "        plt.xlabel('Categoría')\n",
    "        plt.ylabel('Exactitud')\n",
    "        plt.title(f'Exactitud por Categoría - {target_label}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1.0)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"No se encontró el archivo de resultados: {result_file}\")\n",
    "    print(\"Ejecuta primero la celda de evaluación del conjunto de validación.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

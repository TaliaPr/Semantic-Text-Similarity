{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Semantic Text Similarity\n",
    "Este modelo utiliza gensim para convertir pares de vectores + puntuaciones en vectores (word embeddings).\n",
    "Dado un dataset, infiere la puntuación de similitud entre ambas frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:07.143009Z",
     "start_time": "2025-05-23T14:55:05.828592Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requisitos\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:08.481500Z",
     "start_time": "2025-05-23T14:55:08.479325Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tipado\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:10.982179Z",
     "start_time": "2025-05-23T14:55:10.979566Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cargar stopwords en Catalan\n",
    "# STOPWORDS_CA = {\"a\", \"abans\", \"ací\", \"ah\", \"així\", \"això\", \"al\", \"aleshores\", \"algun\", \"alguna\", \"algunes\", \"alguns\", \"alhora\", \"allà\", \"allí\", \"allò\", \"als\", \"altra\", \"altre\", \"altres\", \"amb\", \"ambdues\", \"ambdós\", \"anar\", \"ans\", \"apa\", \"aquell\", \"aquella\", \"aquelles\", \"aquells\", \"aquest\", \"aquesta\", \"aquestes\", \"aquests\", \"aquí\", \"baix\", \"bastant\", \"bé\", \"cada\", \"cadascuna\", \"cadascunes\", \"cadascuns\", \"cadascú\", \"com\", \"consegueixo\", \"conseguim\", \"conseguir\", \"consigueix\", \"consigueixen\", \"consigueixes\", \"contra\", \"d'un\", \"d'una\", \"d'unes\", \"d'uns\", \"dalt\", \"de\", \"del\", \"dels\", \"des\", \"des de\", \"després\", \"dins\", \"dintre\", \"donat\", \"doncs\", \"durant\", \"e\", \"eh\", \"el\", \"elles\", \"ells\", \"els\", \"em\", \"en\", \"encara\", \"ens\", \"entre\", \"era\", \"erem\", \"eren\", \"eres\", \"es\", \"esta\", \"estan\", \"estat\", \"estava\", \"estaven\", \"estem\", \"esteu\", \"estic\", \"està\", \"estàvem\", \"estàveu\", \"et\", \"etc\", \"ets\", \"fa\", \"faig\", \"fan\", \"fas\", \"fem\", \"fer\", \"feu\", \"fi\", \"fins\", \"fora\", \"gairebé\", \"ha\", \"han\", \"has\", \"haver\", \"havia\", \"he\", \"hem\", \"heu\", \"hi\", \"ho\", \"i\", \"igual\", \"iguals\", \"inclòs\", \"ja\", \"jo\", \"l'hi\", \"la\", \"les\", \"li\", \"li'n\", \"llarg\", \"llavors\", \"m'he\", \"ma\", \"mal\", \"malgrat\", \"mateix\", \"mateixa\", \"mateixes\", \"mateixos\", \"me\", \"mentre\", \"meu\", \"meus\", \"meva\", \"meves\", \"mode\", \"molt\", \"molta\", \"moltes\", \"molts\", \"mon\", \"mons\", \"més\", \"n'he\", \"n'hi\", \"ne\", \"ni\", \"no\", \"nogensmenys\", \"només\", \"nosaltres\", \"nostra\", \"nostre\", \"nostres\", \"o\", \"oh\", \"oi\", \"on\", \"pas\", \"pel\", \"pels\", \"per\", \"per que\", \"perquè\", \"però\", \"poc\", \"poca\", \"pocs\", \"podem\", \"poden\", \"poder\", \"podeu\", \"poques\", \"potser\", \"primer\", \"propi\", \"puc\", \"qual\", \"quals\", \"quan\", \"quant\", \"que\", \"quelcom\", \"qui\", \"quin\", \"quina\", \"quines\", \"quins\", \"què\", \"s'ha\", \"s'han\", \"sa\", \"sabem\", \"saben\", \"saber\", \"sabeu\", \"sap\", \"saps\", \"semblant\", \"semblants\", \"sense\", \"ser\", \"ses\", \"seu\", \"seus\", \"seva\", \"seves\", \"si\", \"sobre\", \"sobretot\", \"soc\", \"solament\", \"sols\", \"som\", \"son\", \"sons\", \"sota\", \"sou\", \"sóc\", \"són\", \"t'ha\", \"t'han\", \"t'he\", \"ta\", \"tal\", \"també\", \"tampoc\", \"tan\", \"tant\", \"tanta\", \"tantes\", \"te\", \"tene\", \"tenim\", \"tenir\", \"teniu\", \"teu\", \"teus\", \"teva\", \"teves\", \"tinc\", \"ton\", \"tons\", \"tot\", \"tota\", \"totes\", \"tots\", \"un\", \"una\", \"unes\", \"uns\", \"us\", \"va\", \"vaig\", \"vam\", \"van\", \"vas\", \"veu\", \"vosaltres\", \"vostra\", \"vostre\", \"vostres\", \"érem\", \"éreu\", \"és\", \"éssent\", \"últim\", \"ús\"}\n",
    "STOPWORDS_CA = {\"a\", \"al\", \"el\", \"la\", \"els\", \"les\", \"de\", \"un\", \"una\", \"algun\", \"alguna\", }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:39.846622Z",
     "start_time": "2025-05-23T14:55:39.839815Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir función de pre-procesado\n",
    "def preprocess(sentence: str) -> List[str]:\n",
    "    preprocessed = simple_preprocess(sentence) # Tokenización y normalización, lematización, minúsculas\n",
    "    # Eliminar stopwords\n",
    "    preprocessed = [token for token in preprocessed if token not in STOPWORDS_CA]\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:04.254349Z",
     "start_time": "2025-05-23T14:55:40.303605Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Modelos pre-entrenados\\n# WV_MODEL_PATH = \"/Users/salva/Downloads/cc.ca.300.bin.gz\"\\nWV_MODEL_PATH = \\'/Users/salva/Downloads/cc.ca.300.vec.gz\\'\\nimport gensim\\nwv_model =  gensim.models.KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\\nwv_model\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Modelos pre-entrenados\n",
    "# WV_MODEL_PATH = \"/Users/salva/Downloads/cc.ca.300.bin.gz\"\n",
    "WV_MODEL_PATH = '/Users/salva/Downloads/cc.ca.300.vec.gz'\n",
    "import gensim\n",
    "wv_model =  gensim.models.KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\n",
    "wv_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastTextKeyedVectors\n",
    "#cargar como map:\n",
    "wv_model = FastTextKeyedVectors.load('/home/taya/Desktop/cc.ca.gensim.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:16.013377Z",
     "start_time": "2025-05-23T14:58:16.007686Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Ejemplo de 10 pares de oraciones con puntuación de similitud asociada\\n#No se usa nunca en el codigo\\ninput_pairs = [\\n    ('M'agrada el futbol', 'Disfruto veient partits de futbol', 4),\\n    ('El cel està despejat', 'Fa un dia bonic', 4.5),\\n    ('M'encanta viatjar', 'Explorar nous llocs és una passió', 3.5),\\n    ('Prefereixo l'estiu', 'No m'agrada el fred de l'hivern', 2.5),\\n    ('Tinc gana', 'Què hi ha per sopar?', 2),\\n    ('La música em relaxa', 'Escoltar música és una teràpia', 3),\\n    ('El llibre és emocionant', 'No puc deixar de llegir-lo', 4),\\n    ('M'agrada la pizza', 'És el meu menjar preferit', 4.5),\\n    ('Estic cansat', 'Necessito fer una migdiada', 1.5),\\n    ('Avui fa molta calor', 'És un dia sofocant', 3.5)\\n    ]\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Ejemplo de 10 pares de oraciones con puntuación de similitud asociada\n",
    "#No se usa nunca en el codigo\n",
    "input_pairs = [\n",
    "    ('M\\'agrada el futbol', 'Disfruto veient partits de futbol', 4),\n",
    "    ('El cel està despejat', 'Fa un dia bonic', 4.5),\n",
    "    ('M\\'encanta viatjar', 'Explorar nous llocs és una passió', 3.5),\n",
    "    ('Prefereixo l\\'estiu', 'No m\\'agrada el fred de l\\'hivern', 2.5),\n",
    "    ('Tinc gana', 'Què hi ha per sopar?', 2),\n",
    "    ('La música em relaxa', 'Escoltar música és una teràpia', 3),\n",
    "    ('El llibre és emocionant', 'No puc deixar de llegir-lo', 4),\n",
    "    ('M\\'agrada la pizza', 'És el meu menjar preferit', 4.5),\n",
    "    ('Estic cansat', 'Necessito fer una migdiada', 1.5),\n",
    "    ('Avui fa molta calor', 'És un dia sofocant', 3.5)\n",
    "    ]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:24.542260Z",
     "start_time": "2025-05-23T14:58:16.595919Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentence_1', 'sentence_2', 'label'],\n",
       "    num_rows: 3073\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Text Similarity (STS) dataset (principal per la Pràctica 4)\n",
    "train = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test = load_dataset(\"projecte-aina/sts-ca\", split=\"test\")\n",
    "val = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "all_data = load_dataset(\"projecte-aina/sts-ca\", split=\"all\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento y construccion del diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:25.881487Z",
     "start_time": "2025-05-23T14:58:25.584735Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7dd2186c7ec0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento de las oraciones y creación del diccionario\n",
    "sentences_1_preproc = [simple_preprocess(d[\"sentence_1\"]) for d in all_data] #lista de listas que son oraciones lematizadas\n",
    "sentences_2_preproc = [simple_preprocess(d[\"sentence_2\"]) for d in all_data]\n",
    "scores = [d[\"label\"] for d in all_data]\n",
    "sentence_pairs = list(zip(sentences_1_preproc, sentences_2_preproc, scores))#lista de tuplas que son ([palabras or1], [pal or 2], score)\n",
    "# Versión aplanada para poder entrenar el modelo\n",
    "sentences_pairs_flattened = sentences_1_preproc + sentences_2_preproc #todas las oraciones juntas\n",
    "diccionario = Dictionary(sentences_pairs_flattened) # diccionario donde cada palabra tiene un indice unico\n",
    "diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:26.908268Z",
     "start_time": "2025-05-23T14:58:26.906394Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['atorga', 'per', 'primer', 'cop', 'les', 'mencions', 'encarna', 'sanahuja', 'la', 'inclusió', 'de', 'la', 'perspectiva', 'de', 'gènere', 'en', 'docència', 'universitària'], ['creen', 'la', 'menció', 'encarna', 'sanahuja', 'la', 'inclusió', 'de', 'la', 'perspectiva', 'de', 'gènere', 'en', 'docència', 'universitària'], 3.5)\n"
     ]
    }
   ],
   "source": [
    "print(sentence_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construccion de la metriz TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:28.003478Z",
     "start_time": "2025-05-23T14:58:27.934262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cálculo de los pesos TF-IDF para las oraciones pre-procesadas\n",
    "corpus = [diccionario.doc2bow(sent) for sent in sentences_pairs_flattened]\n",
    "\"\"\"\n",
    "Por ejemplo, si sent es ['hola', 'mundo', 'hola'], el resultado de diccionario.doc2bow(sent) podría ser [(0, 2), (1, 1)], donde 0 es el índice de \"hola\" y 1 es el índice de \"mundo\", indicando que \"hola\" aparece 2 veces y \"mundo\" aparece 1 vez.\n",
    "corpus = El resultado es una lista de representaciones de bolsa de palabras, donde cada elemento corresponde a una oración en el conjunto de datos.\n",
    "\"\"\"\n",
    "modelo_tfidf = TfidfModel(corpus) #transformar el corpus en una representación que refleja la importancia de las palabras en cada documento en relación con el corpus completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de dimensión reducida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_50d = {\n",
    "    word: wv_model[word][:50]\n",
    "    for word in wv_model.index_to_key\n",
    "}\n",
    "\n",
    "wv_model_100d = {\n",
    "    word: wv_model[word][:100]\n",
    "    for word in wv_model.index_to_key\n",
    "}\n",
    "wv_model_150d = {\n",
    "    word: wv_model[word][:150]\n",
    "    for word in wv_model.index_to_key\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aregación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:25.966982Z",
     "start_time": "2025-05-23T14:59:25.958556Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_tf_idf(sentence_preproc: List[str], dictionary: Dictionary, tf_idf_model: TfidfModel, model = wv_model) -> Tuple[List[np.ndarray], List[float]]:\n",
    "    \"\"\"\n",
    "    lo que hace es que coge una oracion preprocesada, para cada palabra saca sus pesos TF-IDF y su vector en el embeding\n",
    "    \"\"\"\n",
    "    bow = dictionary.doc2bow(sentence_preproc)#cuenta la frecuencia de cada palabra en la oracion\n",
    "    tf_idf = tf_idf_model[bow] \n",
    "    vectors, weights = [], []\n",
    "    for word_index, weight in tf_idf:\n",
    "        word = dictionary.get(word_index)\n",
    "        if word in model:\n",
    "            vectors.append(model[word])\n",
    "            weights.append(weight)\n",
    "    return vectors, weights\n",
    "\n",
    "def map_pairs(wv_model2, sentence_pairs: List[Tuple[str, str, float]],dictionary: Dictionary = None, tf_idf_model: TfidfModel = None,) -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    \"\"\"\n",
    "    Mapea los tripletes de oraciones a listas de (x, y), (pares de vectores, score)\n",
    "    :param sentence_pairs: lista de tuplas que son ([palabras or1], [palabras or2], score)\n",
    "    :param dictionary: diccionario donde cada palabra tiene un indice unico\n",
    "    :param tf_idf_model: objeto TfidfModel que da los pesos de las palabras (se puede indexar con un bag of words)\n",
    "    :return: lista de ((vector1, vector2), similitud), donde vector1 y vector2 cambian en funcion de:\n",
    "        si tf_idf_model is not None:\n",
    "                para cada elemento de sentence_pairs devuelve el vector embeding promediado de manera ponderada por los pesos de la matriz TF-IDF de las palabras de las oraciones 1 y 2.\n",
    "        si tf_idf_model is not None\n",
    "            el promedio de los vectores de embeding de las palabras que componen cada una de las oraciones\n",
    "    \"\"\"\n",
    "    # Mapeo de los pares de oraciones a pares de vectores\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        sentence_1_preproc = preprocess(sentence_1) if isinstance(sentence_1, str) else sentence_1 # se procesa el texto antes de aplicar map_pairs entonces sentence_1 es una lista de tokens y ya nose vuelve a preprocesar\n",
    "        sentence_2_preproc = preprocess(sentence_2) if isinstance(sentence_2, str) else sentence_2\n",
    "        # Si usamos TF-IDF\n",
    "        if tf_idf_model is not None:\n",
    "            # Cálculo del promedio ponderado por TF-IDF de los word embeddings\n",
    "            vectors1, weights1 = map_tf_idf(sentence_1_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model,model =  wv_model2, )\n",
    "            vectors2, weights2 = map_tf_idf(sentence_2_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, model = wv_model2 )\n",
    "            vector1 = np.average(vectors1, weights=weights1, axis=0, ) #Esta función calcula el promedio de un conjunto de valores. Si se proporciona un argumento weights, el promedio se calcula de manera ponderada, lo que significa que cada valor contribuye al promedio de acuerdo con su peso correspondiente.\n",
    "            vector2 = np.average(vectors2, weights=weights2, axis=0, )\n",
    "        else:\n",
    "            # Cálculo del promedio de los word embeddings\n",
    "            vectors1 = [wv_model2[word] for word in sentence_1_preproc if word in wv_model2]\n",
    "            vectors2 = [wv_model2[word] for word in sentence_2_preproc if word in wv_model2]\n",
    "            vector1 = np.mean(vectors1, axis=0)\n",
    "            vector2 = np.mean(vectors2, axis=0)\n",
    "        # Añadir a la lista\n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-7.22131877e-03, -4.88683421e-03,  2.71017708e-02,  2.32332627e-02,\n",
       "         -9.60097482e-03, -3.16095435e-03,  2.90225599e-02, -1.75413820e-02,\n",
       "          2.93095319e-02, -1.60574403e-02, -6.04936805e-03,  1.49908545e-02,\n",
       "          1.00934507e-02,  1.84449753e-02,  2.16156266e-02,  2.13238810e-02,\n",
       "          8.69774586e-03,  6.13958934e-02,  2.18719114e-02,  1.01426407e-02,\n",
       "          1.16837708e-02,  3.24588305e-03, -1.32856906e-02,  5.77104877e-02,\n",
       "          1.54627187e-02,  2.13443526e-02, -3.82471218e-02,  6.23983637e-03,\n",
       "          7.31161386e-04,  8.99225741e-03, -4.87626204e-03,  1.08773269e-02,\n",
       "          1.30313145e-02, -3.86450925e-03,  7.23370200e-03, -1.75266524e-02,\n",
       "         -9.09778208e-03,  4.43412138e-02, -4.31998409e-04,  6.25044253e-04,\n",
       "         -1.13920750e-02, -1.82465011e-02, -8.11444328e-03, -8.18518457e-03,\n",
       "         -3.54176235e-03, -1.60820262e-01,  7.74505797e-03,  9.80261699e-03,\n",
       "          8.53058034e-03, -1.23878019e-02,  1.24134202e-02, -2.39070017e-03,\n",
       "         -3.17817092e-02, -6.78023514e-03, -1.43296539e-02,  2.57246362e-02,\n",
       "          2.62315431e-02,  1.36448970e-02, -9.16338087e-03,  1.39765626e-02,\n",
       "          4.86506819e-02, -3.05702791e-02, -1.73943639e-02, -2.01844855e-02,\n",
       "          3.91634927e-02,  1.06170025e-03, -2.25761531e-02, -2.53614495e-02,\n",
       "          1.06654209e-02,  3.99356146e-02,  1.90717986e-02,  5.49600371e-03,\n",
       "          2.08872278e-02,  1.34323488e-02,  1.14136353e-02, -2.26947543e-02,\n",
       "         -2.89445889e-02,  3.63149983e-03, -3.17429208e-02, -1.86948783e-02,\n",
       "          7.58524843e-03, -2.51519190e-02,  1.59076956e-02, -1.57653595e-02,\n",
       "         -1.32853988e-02,  1.84268937e-02,  1.35733292e-02, -1.35745752e-02,\n",
       "         -2.62841402e-02, -1.71081547e-03, -6.57123376e-02,  1.80123245e-02,\n",
       "          2.18237573e-02,  4.92439771e-03, -4.24249468e-03,  1.44695216e-02,\n",
       "          1.61562532e-02, -5.86160831e-03,  1.07315954e-02,  2.03850600e-02,\n",
       "         -9.68246967e-03, -9.98037382e-03,  6.31454679e-07, -2.24527261e-02,\n",
       "          5.15347347e-03, -1.18663279e-02, -4.56879624e-03,  4.84564375e-02,\n",
       "          5.10890407e-03, -1.10297034e-03, -5.12788351e-03, -1.27865401e-02,\n",
       "          1.69212758e-02, -2.37873653e-04,  7.97397964e-03, -1.12930849e-02,\n",
       "         -4.02350222e-04, -1.98382137e-02,  2.10519730e-03, -1.94884122e-03,\n",
       "         -1.41923877e-02,  1.53408167e-02, -3.14154498e-02,  5.16255789e-03,\n",
       "          6.93068941e-03,  1.27301166e-02,  2.95631792e-03, -1.99976450e-02,\n",
       "         -1.29251593e-02,  2.83612074e-02, -1.00102755e-02, -3.59831313e-03,\n",
       "          9.12615437e-03,  3.19957247e-02, -2.39536587e-03, -1.88541424e-03,\n",
       "          1.71505670e-02,  6.10816907e-02, -2.02739033e-02,  3.70995447e-04,\n",
       "         -1.79623004e-02, -9.18574379e-04,  2.46088662e-02, -5.23656944e-03,\n",
       "         -3.28713545e-02, -1.66103211e-02, -2.97392304e-02,  1.05556641e-02,\n",
       "          1.15840674e-02,  5.76075530e-02,  5.02314960e-02,  2.17064867e-02,\n",
       "          8.58374305e-03, -6.60827014e-02, -4.82426792e-03, -1.56691531e-02,\n",
       "          2.12149921e-02, -2.74767225e-02, -1.23504192e-02,  1.28560904e-02,\n",
       "          2.30588782e-02, -1.09581482e-02,  6.07751199e-03,  1.72556543e-02,\n",
       "         -1.97553865e-03,  1.22152828e-02,  1.04813740e-02,  1.40103719e-02,\n",
       "          5.37980764e-03, -5.76685295e-02,  1.36694746e-02, -2.36321303e-02,\n",
       "         -8.50384182e-03,  3.60939922e-02, -2.06882135e-03,  1.76951758e-02,\n",
       "          1.57728072e-02,  2.88058438e-02, -8.86882738e-03,  6.88743752e-02,\n",
       "          6.25128593e-03,  3.75693638e-03,  3.87385404e-05, -1.95502007e-02,\n",
       "         -5.08330865e-03, -6.56666336e-03, -4.60735302e-03, -1.69378997e-02,\n",
       "          2.03075495e-02, -4.75446082e-02, -2.89494102e-02, -7.66059492e-03,\n",
       "         -2.24331713e-03,  8.62236897e-02, -2.80728569e-02, -4.31060661e-03,\n",
       "          1.31037543e-02,  6.93664039e-03,  8.79472834e-03,  5.53005787e-02,\n",
       "         -3.09062304e-03, -1.42629341e-02, -2.72252156e-02,  1.37947659e-02,\n",
       "         -3.86245701e-03, -1.68961022e-03,  1.90346599e-02, -1.98370433e-02,\n",
       "          2.21129468e-04,  8.48248098e-03,  1.53173742e-02, -4.47935110e-02,\n",
       "          5.90692373e-02,  4.12743244e-03,  2.69058790e-02, -7.84230922e-03,\n",
       "         -1.00485311e-02,  3.48163964e-03, -7.07877696e-03, -8.69120567e-03,\n",
       "         -1.09471734e-02, -5.26084500e-03, -8.29154383e-03,  1.45321145e-02,\n",
       "          1.17931868e-02,  1.51625271e-03,  5.06379921e-05,  3.64201031e-02,\n",
       "         -5.98440757e-03,  4.41127321e-03, -2.08663335e-02, -1.70784310e-02,\n",
       "         -2.18255851e-02,  6.00788341e-03,  5.07507834e-03, -1.38918141e-02,\n",
       "         -6.91033048e-03,  1.14552128e-02,  6.34593222e-02, -1.32782786e-02,\n",
       "         -1.52115628e-02,  4.98272376e-02,  1.72577717e-02, -1.29923328e-02,\n",
       "         -1.60627377e-02,  4.10427215e-02, -2.45433983e-03,  5.57846760e-03,\n",
       "         -2.11911409e-02, -2.09040772e-03,  4.27414873e-02,  2.59594736e-02,\n",
       "         -2.21033701e-02, -9.22074085e-03,  6.56417001e-03, -6.15493147e-03,\n",
       "         -6.36646366e-03, -2.16802575e-02,  2.19316476e-02, -1.32581929e-03,\n",
       "         -8.58274602e-03,  1.45549130e-03, -1.33940025e-02, -4.33783476e-03,\n",
       "          9.55339827e-03, -2.29094632e-02, -3.11402989e-03, -1.97023859e-02,\n",
       "          2.13536615e-03, -1.45499117e-02,  2.32157588e-02, -2.51983588e-02,\n",
       "         -2.26461076e-02,  9.16354896e-03,  2.66498964e-02, -1.95218307e-02,\n",
       "         -5.17713434e-02, -2.78031737e-02, -2.49143180e-02,  5.64633386e-03,\n",
       "         -1.70476468e-02,  1.34696997e-02, -5.37980768e-03, -2.86228522e-02,\n",
       "          1.15971552e-02,  1.62302861e-02, -1.50279653e-02, -3.47484244e-02,\n",
       "         -2.68725549e-02, -6.37603429e-03,  1.05356869e-04, -1.25608841e-02,\n",
       "         -4.91036526e-03, -5.21338575e-04,  4.98603459e-02, -1.67891928e-03,\n",
       "         -2.89849270e-03, -2.52519604e-02,  1.43659082e-02, -1.06123175e-02]),\n",
       "  array([-6.83419957e-03, -1.18342274e-02,  2.81851265e-02,  1.56639266e-02,\n",
       "         -8.56577435e-04, -8.51332926e-04,  1.97378555e-02, -1.29571395e-02,\n",
       "          4.93545554e-02, -2.41754346e-02, -6.15790577e-03,  2.05138671e-02,\n",
       "          1.93670358e-02,  2.11652259e-02,  2.54499821e-02,  1.63368237e-02,\n",
       "          4.16049481e-03,  3.83112881e-02,  2.22273047e-02,  4.62837957e-03,\n",
       "          8.80235256e-03, -2.01674838e-03, -1.16806213e-02,  4.86109168e-02,\n",
       "          1.98380204e-02, -1.89877654e-03, -4.72341870e-02, -4.54726101e-03,\n",
       "         -7.67185251e-03, -5.59219061e-05, -9.20897783e-03,  7.59127691e-03,\n",
       "          7.42895688e-04, -6.14518295e-03,  1.84238488e-02, -2.73708592e-02,\n",
       "          3.67920039e-03,  5.15129104e-02,  4.80286734e-03, -9.51228594e-03,\n",
       "         -1.11621336e-02, -9.42123322e-03, -4.36669167e-03, -1.52258050e-02,\n",
       "          9.90805424e-04, -1.54695765e-01,  1.73456723e-02,  4.71676183e-03,\n",
       "          4.02265375e-03, -2.22887292e-02, -4.60747433e-03,  3.95980001e-03,\n",
       "         -4.49414413e-02, -1.66012033e-02, -1.11012129e-02,  2.86654471e-02,\n",
       "          2.77660979e-02,  2.29358544e-02, -9.27368574e-03,  1.76946555e-02,\n",
       "          3.86702123e-02, -2.49444389e-02,  8.16866338e-04, -1.31154861e-02,\n",
       "          4.54887142e-02,  1.82431527e-03, -9.26950632e-03, -1.15554111e-02,\n",
       "          2.80840740e-02,  1.72604205e-02,  5.92232558e-03,  1.80038366e-02,\n",
       "          4.91635839e-02,  2.28532993e-02,  6.92838741e-03, -3.29340996e-02,\n",
       "         -2.60844809e-02, -3.53558118e-03, -2.37629223e-02, -1.33396815e-02,\n",
       "          3.39014677e-02, -2.58249188e-02,  1.58621179e-02, -1.38280199e-02,\n",
       "         -1.94001082e-02,  3.23780085e-02,  8.73536972e-03, -1.06491400e-02,\n",
       "         -2.06113311e-02, -1.00204539e-02, -5.92414899e-02,  2.21567742e-02,\n",
       "          1.96703621e-02,  4.83981773e-03,  4.64754394e-03,  1.72329994e-02,\n",
       "          3.77878697e-03, -7.31476285e-03,  2.15761497e-02,  2.36946578e-02,\n",
       "         -3.94739185e-04, -3.15822189e-03,  6.27627253e-03, -1.63456528e-02,\n",
       "         -2.86408123e-03, -1.34084593e-02, -2.05908982e-02,  3.79488378e-02,\n",
       "         -2.59135821e-03, -5.99367373e-03, -5.48361672e-03, -2.25192984e-02,\n",
       "          1.53839963e-02, -1.96333146e-03,  1.04385230e-02, -9.95364947e-03,\n",
       "         -9.15884628e-04, -5.44193423e-03, -2.63560402e-03, -1.20995468e-02,\n",
       "         -1.94892631e-02,  5.10339449e-03, -3.99716956e-02,  6.63766081e-03,\n",
       "          2.83341507e-02,  1.61479897e-02, -6.24960469e-03, -2.01853115e-02,\n",
       "         -2.30493463e-02,  2.41974686e-02, -1.18435264e-02,  3.91196668e-03,\n",
       "          1.57427261e-02,  3.39905907e-02,  1.78401215e-02, -5.43773888e-03,\n",
       "          1.96007225e-02,  8.70553736e-02, -2.09045670e-02,  5.44575620e-03,\n",
       "         -1.74754817e-02, -6.31366838e-03,  4.67595758e-03,  1.15769349e-03,\n",
       "         -2.48051513e-02, -1.49467794e-02,  8.50755240e-03,  3.35060067e-02,\n",
       "          3.74447485e-03,  4.09239615e-02,  3.32012232e-02,  3.43022553e-02,\n",
       "          1.95873175e-03, -4.23116064e-02, -1.78572984e-03, -2.38531207e-02,\n",
       "          2.10662950e-03, -2.19738587e-02, -1.20522812e-02, -3.03089888e-03,\n",
       "          2.11344370e-02, -8.71930295e-03,  7.29551984e-03,  1.66129700e-02,\n",
       "         -1.27604342e-02,  9.56745217e-03,  6.98299118e-03,  2.53704170e-02,\n",
       "         -4.42790063e-03, -3.90480910e-02,  8.54313270e-03, -2.50870639e-02,\n",
       "         -3.21222553e-05,  1.70423389e-02,  1.84731972e-02,  2.96567194e-03,\n",
       "          2.61907966e-02,  1.49996948e-02, -2.33189960e-02,  6.46570743e-02,\n",
       "          3.11559877e-03,  2.37721322e-02,  1.93601322e-02, -2.57546712e-02,\n",
       "         -1.83501803e-02, -1.41467092e-02, -3.99285842e-03, -1.79875420e-02,\n",
       "          1.90183532e-02, -2.44178147e-02, -1.57051930e-02, -2.09854681e-02,\n",
       "          1.37791918e-03,  7.44763341e-02, -1.74727091e-02,  3.67230073e-03,\n",
       "          1.56129086e-02,  6.37680905e-04,  1.01134477e-02,  2.87668182e-02,\n",
       "          2.03147982e-02, -1.17364094e-02, -1.45116558e-02,  6.01164431e-03,\n",
       "         -7.51482784e-03, -1.18620916e-02,  1.71493723e-02, -1.25271817e-02,\n",
       "         -1.03429024e-02, -4.95697306e-03,  3.03381939e-02, -3.41038112e-02,\n",
       "          4.47540520e-02,  1.99627772e-02,  1.54856961e-02, -1.28739820e-02,\n",
       "         -1.37375703e-02,  7.22146110e-03, -1.12781470e-02, -3.54985917e-03,\n",
       "         -1.46177715e-02,  1.68767010e-02, -1.02305389e-03,  4.97828967e-03,\n",
       "         -4.69090611e-03, -7.10695948e-03,  5.32717242e-03,  2.88679476e-02,\n",
       "         -2.48944984e-03, -3.63596450e-04, -1.58664227e-02, -2.27195900e-02,\n",
       "         -1.06893757e-02, -1.09062554e-03,  1.24194070e-02,  1.34343369e-02,\n",
       "          2.25927407e-03,  5.54371125e-03,  6.09565856e-02, -9.14932218e-03,\n",
       "         -1.07793950e-02,  4.92963797e-02,  1.36362660e-02, -1.14051405e-02,\n",
       "         -1.74310632e-02,  5.70965599e-02, -1.19615038e-02,  1.05203062e-02,\n",
       "         -4.02353531e-03,  5.68556388e-03,  5.59104681e-02,  1.28396213e-02,\n",
       "         -1.06977573e-02, -1.08159224e-02, -1.46696972e-02, -9.03286637e-03,\n",
       "         -3.02932333e-04, -5.26778925e-04,  2.86689934e-02,  2.36106037e-03,\n",
       "         -4.98861461e-03,  6.93722282e-03, -7.73450376e-03, -8.31161353e-03,\n",
       "          7.77818995e-03, -6.43278433e-03, -1.27221542e-02,  1.05815064e-02,\n",
       "          2.84699066e-03, -2.10621337e-02, -3.27117528e-03, -2.31504872e-02,\n",
       "         -4.80825505e-03, -1.02471190e-02,  6.89615496e-03, -2.43042988e-02,\n",
       "         -1.73822640e-02, -2.59426005e-02, -2.67280864e-02,  1.26821842e-02,\n",
       "          1.60994342e-03,  3.71996485e-03, -5.48653625e-03, -1.88920388e-02,\n",
       "          1.97826725e-02,  4.47507107e-03, -1.87621528e-02, -2.91604958e-02,\n",
       "         -1.39914642e-02, -1.30793378e-02, -9.50955897e-04, -3.02010468e-02,\n",
       "          4.11583971e-03, -7.42575856e-03,  3.74844929e-02, -1.16436960e-02,\n",
       "         -1.95666894e-02, -1.67785357e-02,  2.49638147e-02, -8.38376810e-03])),\n",
       " 3.5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir los pares de vectores y la puntuación de similitud asociada\n",
    "mapped_no_tfidf = map_pairs(wv_model, sentence_pairs, tf_idf_model=None, dictionary=diccionario, )\n",
    "mapped = map_pairs(wv_model,sentence_pairs, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dimensión reducida: <sb>\n",
    "\n",
    "sí usando pesos TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_50 = map_pairs(wv_model_50d,sentence_pairs, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_100 = map_pairs(wv_model_100d,sentence_pairs, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_150 = map_pairs(wv_model_150d,sentence_pairs, tf_idf_model=modelo_tfidf, dictionary=diccionario, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(50,)\n",
      "(100,)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(mapped_no_tfidf[0][0][0].shape)\n",
    "print(mapped[0][0][0].shape)\n",
    "print(mapped_50[0][0][0].shape)\n",
    "print(mapped_100[0][0][0].shape)\n",
    "print(mapped_150[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentes modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:33.852866Z",
     "start_time": "2025-05-23T14:59:29.286142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir el Modelo\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_and_compile_model(hidden_size: int = 128, embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Esto crea una red neuronal de manera que al entrenarla las distancias coseno cuadren con la etiqueta real\n",
    "    hidden_size: Tamaño de capas ocultas (no se usa en este código)\n",
    "    embedding_size: Dimensión de los vectores de entrada (300)\n",
    "    learning_rate: Tasa de aprendizaje para el optimizador\n",
    "    \"\"\"\n",
    "    # Capa de entrada para los pares de vectores\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,)) #los pares de vectores a comparar\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,))\n",
    "\n",
    "    # Capa oculta, con funcion de activacion lineal, tiene como objetivo proyectar los vectores de entrada en un nuevo espacio.\n",
    "    \"\"\"\n",
    "    La capa oculta (en este caso, la capa densa) tiene pesos que se ajustan durante el entrenamiento.\n",
    "    Estos pesos son los que transforman los vectores de entrada en los vectores proyectados\n",
    "    \"\"\"\n",
    "    first_projection = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        # activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),# inicializa los pesos de la capa como una matriz identidad\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "    )\n",
    "    #aplica la capa de proyeccion a los dos vectores de entrada\n",
    "    projected_1 = first_projection(input_1)\n",
    "    projected_2 = first_projection(input_2)\n",
    "    \"\"\"\n",
    "    # Compute the cosine distance\n",
    "    projected_1 = tf.linalg.l2_normalize(projected_1, axis=1, ) #Normaliza ambos vectores para que tengan magnitud 1, necesario para el cálculo de similitud coseno\n",
    "    projected_2 = tf.linalg.l2_normalize(projected_2, axis=1, )\n",
    "    output = 2.5 * (1.0 + tf.reduce_sum(projected_1 * projected_2, axis=1, ))\n",
    "    \"\"\" \n",
    "    #lo comentado es del profe y no va. Esto es del Chat############################################################################################\n",
    "    normalize = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))\n",
    "    projected_1 = normalize(projected_1)\n",
    "    projected_2 = normalize(projected_2)\n",
    "    output = tf.keras.layers.Lambda(lambda tensors: 2.5 * (1.0 + tf.reduce_sum(tensors[0] * tensors[1], axis=1)))([projected_1, projected_2])\n",
    "    ############################################################################################################################################\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output) #Durante el entrenamiento, Keras ajusta los pesos de la capa oculta para minimizar la función de pérdida definida (en este caso, el error absoluto medio).\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n",
    "\n",
    "```\n",
    "x = Input(...)\n",
    "...\n",
    "tf_fn(x)  # Invalid.\n",
    "```\n",
    "\n",
    "What you should do instead is wrap `tf_fn` in a layer:\n",
    "\n",
    "```\n",
    "class MyLayer(Layer):\n",
    "    def call(self, x):\n",
    "        return tf_fn(x)\n",
    "\n",
    "x = MyLayer()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las transparencias para el modelo 1 pone este codigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_aggregated(embedding_dim: int, hidden_size: int = 128, dropout_rate: float = 0.3) -> tf.keras.Model:\n",
    "    input_1 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_2\")\n",
    "    concatenated = tf.keras.layers.Concatenate(axis=-1)([input_1, input_2])\n",
    "    x = tf.keras.layers.BatchNormalization()(concatenated)\n",
    "    x = tf.keras.layers.Dense(hidden_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x) # Activació lineal per a regressió\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "#model_agg.fit([X1_train, X2_train], Y_train, epochs=..., batch_size=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧠 Modelo build_model_aggregated: Concatenación + Red Neuronal Densa\n",
    "🏗️ Arquitectura:\n",
    "\n",
    "    Toma dos vectores de entrada (input_vector_1, input_vector_2).\n",
    "\n",
    "    Los concatena (Concatenate), por lo que la dimensión del vector combinado es el doble del embedding_dim.\n",
    "\n",
    "    Aplica:\n",
    "\n",
    "        BatchNormalization\n",
    "\n",
    "        Dense con ReLU\n",
    "\n",
    "        Otro BatchNormalization\n",
    "\n",
    "        Dropout\n",
    "\n",
    "        Una capa de salida densa sin activación (regresión lineal).\n",
    "\n",
    "    Se entrena con MSE (Mean Squared Error).\n",
    "\n",
    "🧾 Objetivo implícito:\n",
    "\n",
    "    Aprender una función no lineal entre los vectores concatenados y la puntuación objetivo (p. ej., similitud STS, afinidad, etc.).\n",
    "\n",
    "    Aprende una transformación compleja basada en composición conjunta de los dos vectores.\n",
    "\n",
    "📌 Ventajas:\n",
    "\n",
    "    Flexibilidad para aprender patrones complejos.\n",
    "\n",
    "    Permite capturar interacciones no lineales entre los dos vectores.\n",
    "\n",
    "❗ Consideraciones:\n",
    "\n",
    "    Puede sobreajustarse si el dataset es pequeño.\n",
    "\n",
    "    Requiere más parámetros, por lo tanto más datos para entrenar bien.\n",
    "\n",
    "🧠 build_and_compile_model: Proyección + Similitud Coseno\n",
    "🏗️ Arquitectura:\n",
    "\n",
    "    Aplica una capa densa compartida (misma proyección) a cada vector por separado. Inicialmente es una matriz identidad.\n",
    "\n",
    "    Los normaliza a magnitud 1.\n",
    "\n",
    "    Calcula la similitud coseno como cos(θ) = dot(product).\n",
    "\n",
    "    La salida es 2.5 * (1 + similitud_coseno), lo cual transforma el rango [-1, 1] a [0, 5].\n",
    "\n",
    "    Se entrena con MAE (Mean Absolute Error).\n",
    "\n",
    "🧾 Objetivo implícito:\n",
    "\n",
    "    Aprender una proyección donde la similitud coseno refleje la puntuación deseada (por ejemplo, cuán similares son dos textos o frases).\n",
    "\n",
    "    Optimiza directamente sobre una función interpretable (similitud coseno), útil para tareas tipo semantic textual similarity (STS).\n",
    "\n",
    "📌 Ventajas:\n",
    "\n",
    "    Muy interpretativo.\n",
    "\n",
    "    Más simple y menos propenso a sobreajuste.\n",
    "\n",
    "    Funciona bien cuando la relación entre embeddings y similitud es principalmente angular (coseno).\n",
    "\n",
    "❗ Consideraciones:\n",
    "\n",
    "    Menor capacidad expresiva que el Modelo 1.\n",
    "\n",
    "    Asume que la similitud se puede modelar bien con una proyección lineal + coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_and_compile_model2(embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    # Input layer\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_2\")\n",
    "\n",
    "    # hidden layer\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.3, name=\"projection_dropout\")\n",
    "    projected_1_dense = dropout(first_projection_layer(input_1))\n",
    "    projected_2_dense = dropout(first_projection_layer(input_2))\n",
    "\n",
    "    # Normalize the projected vectors using Lambda layers\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1_dense)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2_dense)\n",
    "\n",
    "    # Compute the custom similarity score using a Lambda layer\n",
    "    similarity_sum = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"similarity_sum\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    output = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\" #cambiar 0.5 por 2.5 para que este entre 0 y 5 \n",
    "    )(similarity_sum)\n",
    "\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output, name=\"similarity_model\")\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Característica             | Modelo 1: Cosine (`build_and_compile_model2`) | Modelo 2: MLP (`build_model_aggregated`) |\n",
    "| -------------------------- | -------------------------------------------- | ---------------------------------------- |\n",
    "| Tipo de entrada            | 2 vectores                                   | 2 vectores concatenados                  |\n",
    "| Proyección                 | Capa densa compartida                        | Dense normal (no compartida)             |\n",
    "| Normalización L2           | ✅ sí                                         | ❌ no                                     |\n",
    "| Métrica implícita          | Cosine similarity                            | No definida; aprende desde los datos     |\n",
    "| Salida                     | Escalado de coseno (rango 0-1 o 0-5)         | Escalar libre (regresión lineal)         |\n",
    "| Capacidad expresiva        | Limitada (coseno + proyección)               | Alta (MLP)                               |\n",
    "| Interpretabilidad          | Alta                                         | Media                                    |\n",
    "| Velocidad de entrenamiento | Más rápido                                   | Más lento                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Aspecto                         | build_and_compile_model                  | `build_and_compile_model2`                              |\n",
    "| ------------------------------- | ----------------------------------------- | ------------------------------------------------------ |\n",
    "| **Activación en la proyección** | Ninguna (lineal)                          | `tanh` (no lineal)                                     |\n",
    "| **Regularización**              | No hay                                    | Sí, con `Dropout`                                      |\n",
    "| **Normalización**               | Directamente con `tf.linalg.l2_normalize` | Igual, pero encapsulada en `Lambda` layers con nombres |\n",
    "| **Similitud coseno**            | `2.5 * (1.0 + coseno)`                    | `0.5 * (1.0 + coseno)`                                 |\n",
    "| **Escalado de salida**          | Rango `[0, 5]`                            | Rango `[0, 1]`                                         |\n",
    "| **Perdida**                     | `mean_absolute_error`                     | `mean_squared_error`                                   |\n",
    "| **Estilo**                      | Más directo, menos modular                | Más claro, modular, con nombres de capas               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training y evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def evaluate_model(model, X1_test, X2_test, Y_test, name=\"\"):\n",
    "    y_pred = model.predict([X1_test, X2_test]).squeeze()\n",
    "    y_true = Y_test.squeeze()\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    spearman, _ = spearmanr(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n🔎 Resultados para el modelo '{name}':\")\n",
    "    print(f\"MSE:      {mse:.4f}\")\n",
    "    print(f\"RMSE:     {rmse:.4f}\")\n",
    "    print(f\"MAE:      {mae:.4f}\")\n",
    "    print(f\"Pearson:  {pearson:.4f}\")\n",
    "    print(f\"Spearman: {spearman:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"pearson\": pearson,\n",
    "        \"spearman\": spearman\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir constantes de entrenamiento\n",
    "batch_size: int = 64\n",
    "num_epochs: int = 64\n",
    "train_val_split: float = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener x_train e y_train\n",
    "train_slice: int = int(len(mapped) * train_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_list_to_x_y(pair_list: List[Tuple[Tuple[np.ndarray, np.ndarray], int]]) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Otiene las matrices X_1 (N x d) , X_2 (N x d), e Y (n) a partir de listas de parejas de vectores de oraciones - Listas de (d, d, 1)\n",
    "    :param pair_list: lista que devuelve map_pairs(), lista de ((vector1, vector2), similitud), sonde vector1 y 2 son vectores agregados\n",
    "    :return:\n",
    "    transforma una lista de pares de vectores y puntuaciones (como los que se usan en tareas de similaridad semántica tipo STS) en el formato adecuado para alimentar a un modelo de aprendizaje automático.\n",
    "    \"\"\"\n",
    "    _x, _y = zip(*pair_list) #_x: lista de tuplas (embedding_1, embedding_2), _y: lista de etiquetas\n",
    "    _x_1, _x_2 = zip(*_x)#_x_1: todos los embedding_1,  _x_2: todos los embedding_2\n",
    "    return (np.array(_x_1), np.array(_x_2)), np.array(_y, dtype=np.float32, ) / 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las listas de train y test USANDO TF-IDF\n",
    "x_train, y_train = pair_list_to_x_y(mapped[:train_slice])\n",
    "x_val, y_val = pair_list_to_x_y(mapped[train_slice:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las listas de train y test SIN USAR TF-IDF\n",
    "x_train_normal, y_train_normal = pair_list_to_x_y(mapped[:train_slice])\n",
    "x_val_normal, y_val_normal = pair_list_to_x_y(mapped[train_slice:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_50, y_train_50 = pair_list_to_x_y(mapped_50[:train_slice])\n",
    "x_val_50, y_val_50 = pair_list_to_x_y(mapped_50[train_slice:])\n",
    "\n",
    "x_train_100, y_train_100 = pair_list_to_x_y(mapped_100[:train_slice])\n",
    "x_val_100, y_val_100 = pair_list_to_x_y(mapped_100[train_slice:])\n",
    "\n",
    "x_train_150, y_train_150 = pair_list_to_x_y(mapped_150[:train_slice])\n",
    "x_val_150, y_val_150 = pair_list_to_x_y(mapped_150[train_slice:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 17:07:34.108625: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Preparar los conjuntos de datos de entrenamiento y validación\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los conjuntos de datos de entrenamiento y validación\n",
    "train_dataset_normal = tf.data.Dataset.from_tensor_slices((x_train_normal, y_train_normal))\n",
    "train_dataset_normal = train_dataset_normal.shuffle(buffer_size=len(x_train_normal)).batch(batch_size)\n",
    "\n",
    "val_dataset_normal = tf.data.Dataset.from_tensor_slices((x_val_normal, y_val_normal))\n",
    "val_dataset_normal = val_dataset_normal.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distancia COS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos evaluar el modelo si sólo utilizamos COS similarity. (Depende completamente de los Word Embeddings)\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_normal = mapped_no_tfidf[train_slice:]\n",
    "val = mapped[train_slice:]\n",
    "val_50 = mapped_50[train_slice:]\n",
    "val_100 = mapped_100[train_slice:]\n",
    "val_150 = mapped_150[train_slice:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando media clásica la correlación de Pearson es: 0.43930761675943547\n",
      "Usando media ponderada con TF-IDF la correlación de Pearson es: 0.3689169387565914\n",
      "Usando media ponderada con TF-IDF y dimensión 50, la correlación de Pearson es: 0.41854519762908476\n",
      "Usando media ponderada con TF-IDF y dimensión 100, la correlación de Pearson es: 0.4308664019477864\n",
      "Usando media ponderada con TF-IDF y dimensión 150, la correlación de Pearson es: 0.4422013561274339\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = []\n",
    "y_pred_normal = []\n",
    "y_pred_50 = []\n",
    "y_pred_100 = []\n",
    "y_pred_150 = []\n",
    "for j in range(len(val)):\n",
    "    i = val[j]\n",
    "    v1, v2 = i[0] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_baseline.append(d)\n",
    "\n",
    "    k = val_normal[j]\n",
    "    v1, v2 = k[0] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_normal.append(d)\n",
    "\n",
    "    m = val_50[j]\n",
    "    v1, v2 = m[0] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_50.append(d)\n",
    "\n",
    "    l = val_100[j]\n",
    "    v1, v2 = l[0] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_100.append(d)\n",
    "\n",
    "    e = val_150[j]\n",
    "    v1, v2 = e[0] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_150.append(d)\n",
    "\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(np.array(y_pred_baseline), y_val.flatten())\n",
    "correlation_normal, _ = pearsonr(np.array(y_pred_normal), y_val_normal.flatten())\n",
    "correlation_50, _ = pearsonr(np.array(y_pred_50), y_val_50.flatten())\n",
    "correlation_100, _ = pearsonr(np.array(y_pred_100), y_val_100.flatten())\n",
    "correlation_150, _ = pearsonr(np.array(y_pred_150), y_val_150.flatten())\n",
    "\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Usando media clásica la correlación de Pearson es: {correlation}\")\n",
    "print(f\"Usando media ponderada con TF-IDF la correlación de Pearson es: {correlation_normal}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensión 50, la correlación de Pearson es: {correlation_50}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensión 100, la correlación de Pearson es: {correlation_100}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensión 150, la correlación de Pearson es: {correlation_150}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.120397Z",
     "start_time": "2025-05-23T21:27:56.109750Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#la del profe: (la de arriba es la misma pero la he modificado para ver las dos correlaciones a la vez)\\nval = mapped[train_slice:]\\ny_pred_baseline = []\\ny_pred_normal = []\\nfor (v1, v2), dist in val:\\n    d = 1.0 - spatial.distance.cosine(v1, v2)\\n    y_pred_baseline.append(d)\\n# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\\ncorrelation, _ = pearsonr(np.array(y_pred_baseline), y_val.flatten())\\n# Imprimir el coeficiente de correlación de Pearson\\nprint(f\"Correlación de Pearson: {correlation}\")\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#la del profe: (la de arriba es la misma pero la he modificado para ver las dos correlaciones a la vez)\n",
    "val = mapped[train_slice:]\n",
    "y_pred_baseline = []\n",
    "y_pred_normal = []\n",
    "for (v1, v2), dist in val:\n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_baseline.append(d)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(np.array(y_pred_baseline), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba del embeding aprendido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_vector_1', 'input_vector_2']\n",
      "Received: inputs=(('Tensor(shape=(None, 300))', 'Tensor(shape=(None, 300))'),)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.3664 - mae: 1.1879 - root_mean_squared_error: 1.5340\n",
      "Epoch 2/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9782 - mae: 0.7739 - root_mean_squared_error: 0.9889\n",
      "Epoch 3/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7932 - mae: 0.6947 - root_mean_squared_error: 0.8904\n",
      "Epoch 4/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5493 - mae: 0.5778 - root_mean_squared_error: 0.7409\n",
      "Epoch 5/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4561 - mae: 0.5207 - root_mean_squared_error: 0.6745\n",
      "Epoch 6/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3417 - mae: 0.4474 - root_mean_squared_error: 0.5845\n",
      "Epoch 7/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3004 - mae: 0.4108 - root_mean_squared_error: 0.5479\n",
      "Epoch 8/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2426 - mae: 0.3695 - root_mean_squared_error: 0.4917\n",
      "Epoch 9/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1774 - mae: 0.3216 - root_mean_squared_error: 0.4211\n",
      "Epoch 10/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1438 - mae: 0.2856 - root_mean_squared_error: 0.3791\n",
      "Epoch 11/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1229 - mae: 0.2702 - root_mean_squared_error: 0.3505\n",
      "Epoch 12/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0983 - mae: 0.2376 - root_mean_squared_error: 0.3135\n",
      "Epoch 13/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0905 - mae: 0.2269 - root_mean_squared_error: 0.3006\n",
      "Epoch 14/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0795 - mae: 0.2082 - root_mean_squared_error: 0.2814\n",
      "Epoch 15/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0615 - mae: 0.1881 - root_mean_squared_error: 0.2479\n",
      "Epoch 16/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0541 - mae: 0.1772 - root_mean_squared_error: 0.2325\n",
      "Epoch 17/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0496 - mae: 0.1684 - root_mean_squared_error: 0.2226\n",
      "Epoch 18/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0456 - mae: 0.1633 - root_mean_squared_error: 0.2134\n",
      "Epoch 19/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0383 - mae: 0.1520 - root_mean_squared_error: 0.1955\n",
      "Epoch 20/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0376 - mae: 0.1480 - root_mean_squared_error: 0.1937\n",
      "Epoch 21/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0364 - mae: 0.1498 - root_mean_squared_error: 0.1907\n",
      "Epoch 22/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0290 - mae: 0.1332 - root_mean_squared_error: 0.1703\n",
      "Epoch 23/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0296 - mae: 0.1358 - root_mean_squared_error: 0.1720\n",
      "Epoch 24/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0257 - mae: 0.1231 - root_mean_squared_error: 0.1603\n",
      "Epoch 25/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0281 - mae: 0.1291 - root_mean_squared_error: 0.1677\n",
      "Epoch 26/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0255 - mae: 0.1224 - root_mean_squared_error: 0.1597\n",
      "Epoch 27/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.1184 - root_mean_squared_error: 0.1523\n",
      "Epoch 28/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0245 - mae: 0.1192 - root_mean_squared_error: 0.1566\n",
      "Epoch 29/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0230 - mae: 0.1184 - root_mean_squared_error: 0.1515\n",
      "Epoch 30/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0232 - mae: 0.1186 - root_mean_squared_error: 0.1521\n",
      "Epoch 31/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0223 - mae: 0.1135 - root_mean_squared_error: 0.1492\n",
      "Epoch 32/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0214 - mae: 0.1137 - root_mean_squared_error: 0.1460\n",
      "Epoch 33/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.1120 - root_mean_squared_error: 0.1434\n",
      "Epoch 34/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0197 - mae: 0.1093 - root_mean_squared_error: 0.1402\n",
      "Epoch 35/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0190 - mae: 0.1059 - root_mean_squared_error: 0.1378\n",
      "Epoch 36/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0187 - mae: 0.1070 - root_mean_squared_error: 0.1369\n",
      "Epoch 37/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0186 - mae: 0.1065 - root_mean_squared_error: 0.1362\n",
      "Epoch 38/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171 - mae: 0.1031 - root_mean_squared_error: 0.1308\n",
      "Epoch 39/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184 - mae: 0.1054 - root_mean_squared_error: 0.1357\n",
      "Epoch 40/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0170 - mae: 0.1026 - root_mean_squared_error: 0.1304\n",
      "Epoch 41/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.1020 - root_mean_squared_error: 0.1323\n",
      "Epoch 42/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - mae: 0.1015 - root_mean_squared_error: 0.1293\n",
      "Epoch 43/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - mae: 0.0983 - root_mean_squared_error: 0.1273\n",
      "Epoch 44/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0977 - root_mean_squared_error: 0.1266\n",
      "Epoch 45/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0977 - root_mean_squared_error: 0.1255\n",
      "Epoch 46/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0152 - mae: 0.0944 - root_mean_squared_error: 0.1231\n",
      "Epoch 47/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0978 - root_mean_squared_error: 0.1254\n",
      "Epoch 48/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - mae: 0.0907 - root_mean_squared_error: 0.1166\n",
      "Epoch 49/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0137 - mae: 0.0909 - root_mean_squared_error: 0.1170\n",
      "Epoch 50/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - mae: 0.0904 - root_mean_squared_error: 0.1147\n",
      "Epoch 51/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - mae: 0.0943 - root_mean_squared_error: 0.1213\n",
      "Epoch 52/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0149 - mae: 0.0949 - root_mean_squared_error: 0.1221\n",
      "Epoch 53/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0139 - mae: 0.0916 - root_mean_squared_error: 0.1178\n",
      "Epoch 54/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.0902 - root_mean_squared_error: 0.1151\n",
      "Epoch 55/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.0904 - root_mean_squared_error: 0.1149\n",
      "Epoch 56/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0128 - mae: 0.0869 - root_mean_squared_error: 0.1133\n",
      "Epoch 57/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0114 - mae: 0.0848 - root_mean_squared_error: 0.1068\n",
      "Epoch 58/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - mae: 0.0852 - root_mean_squared_error: 0.1091\n",
      "Epoch 59/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0852 - root_mean_squared_error: 0.1083\n",
      "Epoch 60/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0121 - mae: 0.0867 - root_mean_squared_error: 0.1098\n",
      "Epoch 61/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0118 - mae: 0.0838 - root_mean_squared_error: 0.1087\n",
      "Epoch 62/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0121 - mae: 0.0857 - root_mean_squared_error: 0.1098\n",
      "Epoch 63/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0114 - mae: 0.0843 - root_mean_squared_error: 0.1069\n",
      "Epoch 64/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0112 - mae: 0.0817 - root_mean_squared_error: 0.1059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7dd103c96cf0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_cos = build_model_aggregated(embedding_dim=300)\n",
    "model_no_cos.fit([x_train], y_train, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "🔎 Resultados para el modelo 'Linealmodel no cos()':\n",
      "MSE:      0.0279\n",
      "RMSE:     0.1672\n",
      "MAE:      0.1280\n",
      "Pearson:  0.3419\n",
      "Spearman: 0.3337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Linealmodel no cos()',\n",
       " 'mse': 0.027944477,\n",
       " 'rmse': 0.16716602,\n",
       " 'mae': 0.12803978,\n",
       " 'pearson': 0.3418520310011242,\n",
       " 'spearman': 0.33370564078195586}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, X2 = x_val\n",
    "evaluate_model(model_no_cos, X1, X2, y_val, name=\"Linealmodel no cos()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model_no_cos, show_shapes=True, show_layer_activations=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_vector_1', 'input_vector_2']\n",
      "Received: inputs=(('Tensor(shape=(None, None))', 'Tensor(shape=(None, None))'),)\n",
      "  warnings.warn(msg)\n",
      "2025-05-25 17:33:02.090854: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [64,100] vs. [600]\n",
      "\t [[{{function_node __inference_one_step_on_data_55655}}{{node gradient_tape/functional_1/batch_normalization_1/batchnorm/mul_1/BroadcastGradientArgs}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/functional_1/batch_normalization_1/batchnorm/mul_1/BroadcastGradientArgs defined at (most recent call last):\n  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_26870/2176028764.py\", line 2, in <module>\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [64,100] vs. [600]\n\t [[{{node gradient_tape/functional_1/batch_normalization_1/batchnorm/mul_1/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_55735]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_no_cos_50 \u001b[38;5;241m=\u001b[39m build_model_aggregated(embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_no_cos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train_50\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/myenv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/functional_1/batch_normalization_1/batchnorm/mul_1/BroadcastGradientArgs defined at (most recent call last):\n  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_26870/2176028764.py\", line 2, in <module>\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n\nIncompatible shapes: [64,100] vs. [600]\n\t [[{{node gradient_tape/functional_1/batch_normalization_1/batchnorm/mul_1/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_55735]"
     ]
    }
   ],
   "source": [
    "#model_no_cos_50 = build_model_aggregated(embedding_dim=50)\n",
    "#model_no_cos.fit([x_train_50], y_train_50, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9752 - val_loss: 3.7108\n",
      "Epoch 2/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6279 - val_loss: 3.6226\n",
      "Epoch 3/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5095 - val_loss: 3.5766\n",
      "Epoch 4/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.4266 - val_loss: 3.5462\n",
      "Epoch 5/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.3611 - val_loss: 3.5241\n",
      "Epoch 6/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3055 - val_loss: 3.5071\n",
      "Epoch 7/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2580 - val_loss: 3.4937\n",
      "Epoch 8/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2178 - val_loss: 3.4825\n",
      "Epoch 9/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1824 - val_loss: 3.4730\n",
      "Epoch 10/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1502 - val_loss: 3.4649\n",
      "Epoch 11/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1230 - val_loss: 3.4580\n",
      "Epoch 12/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0975 - val_loss: 3.4527\n",
      "Epoch 13/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0756 - val_loss: 3.4471\n",
      "Epoch 14/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0526 - val_loss: 3.4422\n",
      "Epoch 15/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0324 - val_loss: 3.4383\n",
      "Epoch 16/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0152 - val_loss: 3.4357\n",
      "Epoch 17/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9999 - val_loss: 3.4318\n",
      "Epoch 18/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9813 - val_loss: 3.4288\n",
      "Epoch 19/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9653 - val_loss: 3.4270\n",
      "Epoch 20/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9531 - val_loss: 3.4237\n",
      "Epoch 21/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9360 - val_loss: 3.4216\n",
      "Epoch 22/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9251 - val_loss: 3.4194\n",
      "Epoch 23/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9120 - val_loss: 3.4183\n",
      "Epoch 24/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9028 - val_loss: 3.4157\n",
      "Epoch 25/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8857 - val_loss: 3.4134\n",
      "Epoch 26/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8746 - val_loss: 3.4117\n",
      "Epoch 27/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8677 - val_loss: 3.4091\n",
      "Epoch 28/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8564 - val_loss: 3.4069\n",
      "Epoch 29/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8430 - val_loss: 3.4052\n",
      "Epoch 30/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8368 - val_loss: 3.4019\n",
      "Epoch 31/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8264 - val_loss: 3.3998\n",
      "Epoch 32/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8166 - val_loss: 3.3994\n",
      "Epoch 33/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.8069 - val_loss: 3.3999\n",
      "Epoch 34/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8007 - val_loss: 3.3930\n",
      "Epoch 35/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7896 - val_loss: 3.3937\n",
      "Epoch 36/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7826 - val_loss: 3.3898\n",
      "Epoch 37/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.7690 - val_loss: 3.3867\n",
      "Epoch 38/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7636 - val_loss: 3.3887\n",
      "Epoch 39/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7606 - val_loss: 3.3840\n",
      "Epoch 40/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7473 - val_loss: 3.3846\n",
      "Epoch 41/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7436 - val_loss: 3.3851\n",
      "Epoch 42/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7390 - val_loss: 3.3772\n",
      "Epoch 43/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7286 - val_loss: 3.3753\n",
      "Epoch 44/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7243 - val_loss: 3.3736\n",
      "Epoch 45/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7184 - val_loss: 3.3677\n",
      "Epoch 46/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7081 - val_loss: 3.3672\n",
      "Epoch 47/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7028 - val_loss: 3.3649\n",
      "Epoch 48/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6940 - val_loss: 3.3631\n",
      "Epoch 49/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6880 - val_loss: 3.3598\n",
      "Epoch 50/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6797 - val_loss: 3.3559\n",
      "Epoch 51/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6723 - val_loss: 3.3573\n",
      "Epoch 52/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6706 - val_loss: 3.3539\n",
      "Epoch 53/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6589 - val_loss: 3.3491\n",
      "Epoch 54/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6504 - val_loss: 3.3470\n",
      "Epoch 55/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6426 - val_loss: 3.3469\n",
      "Epoch 56/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6408 - val_loss: 3.3421\n",
      "Epoch 57/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6307 - val_loss: 3.3410\n",
      "Epoch 58/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6239 - val_loss: 3.3379\n",
      "Epoch 59/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6150 - val_loss: 3.3391\n",
      "Epoch 60/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6122 - val_loss: 3.3361\n",
      "Epoch 61/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6086 - val_loss: 3.3350\n",
      "Epoch 62/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5975 - val_loss: 3.3330\n",
      "Epoch 63/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.5956 - val_loss: 3.3314\n",
      "Epoch 64/64\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5901 - val_loss: 3.3332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7dd0fa174e00>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lin = build_and_compile_model()\n",
    "model_lin.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "🔎 Resultados para el modelo '':\n",
      "MSE:      12.2433\n",
      "RMSE:     3.4990\n",
      "MAE:      3.3332\n",
      "Pearson:  0.3417\n",
      "Spearman: 0.3970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': '',\n",
       " 'mse': 12.243323,\n",
       " 'rmse': 3.499046,\n",
       " 'mae': 3.3331766,\n",
       " 'pearson': 0.341672256901909,\n",
       " 'spearman': 0.397042571697594}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model_lin, X1, X2, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Correlación de Pearson: 0.341672256901909\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "y_pred: tf.RaggedTensor = model_lin.predict(x_val)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_no_lin = build_and_compile_model2()\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_activations=True, )\n",
    "#print(model.summary())\n",
    "# Entrenar el modelo\n",
    "model_no_lin.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.239203Z",
     "start_time": "2025-05-23T21:27:56.137048Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Correlación de Pearson: 0.5301249838419955\n"
     ]
    }
   ],
   "source": [
    "#from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "y_pred: tf.RaggedTensor = model_no_lin.predict(x_val)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lo mismo pero para el train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.369002Z",
     "start_time": "2025-05-23T21:27:56.250260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#from scipy.stats import pearsonr\\n# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\\ny_pred: tf.RaggedTensor = model_no_lin.predict(x_train)\\n# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\\ncorrelation, _ = pearsonr(y_pred.flatten(), y_train.flatten())\\n# Imprimir el coeficiente de correlación de Pearson\\nprint(f\"Correlación de Pearson: {correlation}\")\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "y_pred: tf.RaggedTensor = model_no_lin.predict(x_train)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_train.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

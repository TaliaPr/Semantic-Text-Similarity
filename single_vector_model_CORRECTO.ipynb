{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Semantic Text Similarity\n",
    "\n",
    "En este fichero se va a comparar el rendimiento diferentes modelos simples o de regresi贸n de cara a la tarea de clasificaci贸n de similitud sem谩ntica entre frases en catal谩n. <sb>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:07.143009Z",
     "start_time": "2025-05-23T14:55:05.828592Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requisitos\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy import spatial\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from scipy.special import logit\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tipado\n",
    "from typing import Tuple, List, Iterable, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la base de datos y preprocesar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:39.846622Z",
     "start_time": "2025-05-23T14:55:39.839815Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stopwords en Catalan\n",
    "STOPWORDS_CA = {\"a\", \"al\", \"el\", \"la\", \"els\", \"les\", \"de\", \"un\", \"una\", \"algun\", \"alguna\", }\n",
    "# Definir funci贸n de pre-procesado\n",
    "def preprocess(sentence: str) -> List[str]:\n",
    "    preprocessed = simple_preprocess(sentence) # Tokenizaci贸n y normalizaci贸n, lematizaci贸n, min煤sculas\n",
    "    # Eliminar stopwords\n",
    "    preprocessed = [token for token in preprocessed if token not in STOPWORDS_CA]\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentence_1', 'sentence_2', 'label'],\n",
       "    num_rows: 3073\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Text Similarity (STS) dataset (principal per la Prctica 4)\n",
    "train = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test = load_dataset(\"projecte-aina/sts-ca\", split=\"test\")\n",
    "val = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "all_data = load_dataset(\"projecte-aina/sts-ca\", split=\"all\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_corpus(corpus: Any) -> List[Tuple[List[str], List[str], float]]:\n",
    "    # Preprocesa las frases de cada elemento del corpus usando simple_preprocess (tokenizaci贸n y normalizaci贸n)\n",
    "    sentences_1_preproc = [simple_preprocess(d[\"sentence_1\"]) for d in corpus]  # Lista de listas: cada oraci贸n 1 preprocesada\n",
    "    sentences_2_preproc = [simple_preprocess(d[\"sentence_2\"]) for d in corpus]  # Lista de listas: cada oraci贸n 2 preprocesada\n",
    "    scores = [d[\"label\"] for d in corpus]  # Lista de puntuaciones de similitud\n",
    "    # Une las oraciones preprocesadas y su puntuaci贸n en una lista de tuplas\n",
    "    sentence_pairs = list(zip(sentences_1_preproc, sentences_2_preproc, scores))\n",
    "    return sentence_pairs\n",
    "\n",
    "# Aplica la funci贸n a los conjuntos de entrenamiento, test y validaci贸n\n",
    "train_preproc = map_corpus(train)\n",
    "test_preproc = map_corpus(test)\n",
    "val_preproc = map_corpus(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding **gensim** pre-entrenado: <sb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastTextKeyedVectors\n",
    "#cargar como map:\n",
    "wv_model = FastTextKeyedVectors.load('/home/taya/Desktop/cc.ca.gensim.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos modelos de dimensi贸n reducida, mediante el truncamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_50d = {\n",
    "    word: wv_model[word][:50]\n",
    "    for word in wv_model.index_to_key\n",
    "}\n",
    "\n",
    "wv_model_100d = {\n",
    "    word: wv_model[word][:100]\n",
    "    for word in wv_model.index_to_key\n",
    "}\n",
    "wv_model_150d = {\n",
    "    word: wv_model[word][:150]\n",
    "    for word in wv_model.index_to_key\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcci贸n del diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:25.881487Z",
     "start_time": "2025-05-23T14:58:25.584735Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento de las oraciones y creaci贸n del diccionario\n",
    "sentences_1_preproc = [simple_preprocess(d[\"sentence_1\"]) for d in all_data] #lista de listas que son oraciones lematizadas\n",
    "sentences_2_preproc = [simple_preprocess(d[\"sentence_2\"]) for d in all_data]\n",
    "scores = [d[\"label\"] for d in all_data]\n",
    "sentence_pairs = list(zip(sentences_1_preproc, sentences_2_preproc, scores))#lista de tuplas que son ([palabras or1], [pal or 2], score)\n",
    "# Versi贸n aplanada para poder entrenar el modelo\n",
    "sentences_pairs_flattened = sentences_1_preproc + sentences_2_preproc #todas las oraciones juntas\n",
    "diccionario = Dictionary(sentences_pairs_flattened) # diccionario donde cada palabra tiene un indice unico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcci贸n de la matriz TF-IDF: <sb>\n",
    "\n",
    "Sirve para dar m谩s peso a las palabras importantes y menos peso a las comunes. <sb>\n",
    "- TF (Term Frequency): Qu茅 tan frecuente es una palabra en UN documento.\n",
    "- IDF (Inverse Document Frequency): Qu茅 tan rara es esa palabra en TODA la colecci贸n.<sb>\n",
    "\n",
    "As铆, el documnto se puede caracterizar por las palabras que contiene y diferenciar de otros por las palabras no comunes que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:28.003478Z",
     "start_time": "2025-05-23T14:58:27.934262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# C谩lculo de los pesos TF-IDF para las oraciones pre-procesadas\n",
    "corpus = [diccionario.doc2bow(sent) for sent in sentences_pairs_flattened]\n",
    "\"\"\"\n",
    "Por ejemplo, si sent es ['hola', 'mundo', 'hola'], el resultado de diccionario.doc2bow(sent) podr铆a ser [(0, 2), (1, 1)], donde 0 es el 铆ndice de \"hola\" y 1 es el 铆ndice de \"mundo\", indicando que \"hola\" aparece 2 veces y \"mundo\" aparece 1 vez.\n",
    "corpus = El resultado es una lista de representaciones de bolsa de palabras, donde cada elemento corresponde a una oraci贸n en el conjunto de datos.\n",
    "\"\"\"\n",
    "modelo_tfidf = TfidfModel(corpus) #transformar el corpus en una representaci贸n que refleja la importancia de las palabras en cada documento en relaci贸n con el corpus completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aregaci贸n: <sb>\n",
    "\n",
    "En esta parte, para poder obtener el embeding de una frase entera se van a promediar los embedings de cada palabra por la que est谩 compuesta la frase, ponderando o no con los pesos TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:25.966982Z",
     "start_time": "2025-05-23T14:59:25.958556Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_tf_idf(sentence_preproc: List[str], dictionary: Dictionary, tf_idf_model: TfidfModel, model = wv_model) -> Tuple[List[np.ndarray], List[float]]:\n",
    "    \"\"\"\n",
    "    dada una oracion preprocesada, para cada palabra saca sus pesos TF-IDF y su vector en el embeding\n",
    "    \"\"\"\n",
    "    bow = dictionary.doc2bow(sentence_preproc)#cuenta la frecuencia de cada palabra en la oracion\n",
    "    tf_idf = tf_idf_model[bow] \n",
    "    vectors, weights = [], []\n",
    "    for word_index, weight in tf_idf:\n",
    "        word = dictionary.get(word_index)\n",
    "        if word in model:\n",
    "            vectors.append(model[word])\n",
    "            weights.append(weight)\n",
    "    return vectors, weights\n",
    "\n",
    "def map_pairs(wv_model2, sentence_pairs: List[Tuple[str, str, float]],dictionary: Dictionary = None, tf_idf_model: TfidfModel = None,) -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    \"\"\"\n",
    "    Mapea los tripletes de oraciones a listas de (x, y), (pares de vectores, score)\n",
    "    :param sentence_pairs: lista de tuplas que son ([palabras or1], [palabras or2], score)\n",
    "    :param dictionary: diccionario donde cada palabra tiene un indice unico\n",
    "    :param tf_idf_model: objeto TfidfModel que da los pesos de las palabras (se puede indexar con un bag of words)\n",
    "    :return: lista de ((vector1, vector2), similitud), donde vector1 y vector2 cambian en funcion de:\n",
    "        si tf_idf_model is not None:\n",
    "                para cada elemento de sentence_pairs devuelve el vector embeding promediado de manera ponderada por los pesos de la matriz TF-IDF de las palabras de las oraciones 1 y 2.\n",
    "        si tf_idf_model is not None\n",
    "            el promedio de los vectores de embeding de las palabras que componen cada una de las oraciones\n",
    "    \"\"\"\n",
    "    # Mapeo de los pares de oraciones a pares de vectores\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        sentence_1_preproc = preprocess(sentence_1) if isinstance(sentence_1, str) else sentence_1 # se procesa el texto antes de aplicar map_pairs entonces sentence_1 es una lista de tokens y ya nose vuelve a preprocesar\n",
    "        sentence_2_preproc = preprocess(sentence_2) if isinstance(sentence_2, str) else sentence_2\n",
    "        # Si usamos TF-IDF\n",
    "        if tf_idf_model is not None:\n",
    "            # C谩lculo del promedio ponderado por TF-IDF de los word embeddings\n",
    "            vectors1, weights1 = map_tf_idf(sentence_1_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model,model =  wv_model2, )\n",
    "            vectors2, weights2 = map_tf_idf(sentence_2_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, model = wv_model2 )\n",
    "            vector1 = np.average(vectors1, weights=weights1, axis=0, ) #Esta funci贸n calcula el promedio de un conjunto de valores. Si se proporciona un argumento weights, el promedio se calcula de manera ponderada, lo que significa que cada valor contribuye al promedio de acuerdo con su peso correspondiente.\n",
    "            vector2 = np.average(vectors2, weights=weights2, axis=0, )\n",
    "        else:\n",
    "            # C谩lculo del promedio de los word embeddings\n",
    "            vectors1 = [wv_model2[word] for word in sentence_1_preproc if word in wv_model2]\n",
    "            vectors2 = [wv_model2[word] for word in sentence_2_preproc if word in wv_model2]\n",
    "            vector1 = np.mean(vectors1, axis=0)\n",
    "            vector2 = np.mean(vectors2, axis=0)\n",
    "        # A帽adir a la lista\n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-7.22131877e-03, -4.88683421e-03,  2.71017708e-02,  2.32332627e-02,\n",
       "         -9.60097482e-03, -3.16095435e-03,  2.90225599e-02, -1.75413820e-02,\n",
       "          2.93095319e-02, -1.60574403e-02, -6.04936805e-03,  1.49908545e-02,\n",
       "          1.00934507e-02,  1.84449753e-02,  2.16156266e-02,  2.13238810e-02,\n",
       "          8.69774586e-03,  6.13958934e-02,  2.18719114e-02,  1.01426407e-02,\n",
       "          1.16837708e-02,  3.24588305e-03, -1.32856906e-02,  5.77104877e-02,\n",
       "          1.54627187e-02,  2.13443526e-02, -3.82471218e-02,  6.23983637e-03,\n",
       "          7.31161386e-04,  8.99225741e-03, -4.87626204e-03,  1.08773269e-02,\n",
       "          1.30313145e-02, -3.86450925e-03,  7.23370200e-03, -1.75266524e-02,\n",
       "         -9.09778208e-03,  4.43412138e-02, -4.31998409e-04,  6.25044253e-04,\n",
       "         -1.13920750e-02, -1.82465011e-02, -8.11444328e-03, -8.18518457e-03,\n",
       "         -3.54176235e-03, -1.60820262e-01,  7.74505797e-03,  9.80261699e-03,\n",
       "          8.53058034e-03, -1.23878019e-02,  1.24134202e-02, -2.39070017e-03,\n",
       "         -3.17817092e-02, -6.78023514e-03, -1.43296539e-02,  2.57246362e-02,\n",
       "          2.62315431e-02,  1.36448970e-02, -9.16338087e-03,  1.39765626e-02,\n",
       "          4.86506819e-02, -3.05702791e-02, -1.73943639e-02, -2.01844855e-02,\n",
       "          3.91634927e-02,  1.06170025e-03, -2.25761531e-02, -2.53614495e-02,\n",
       "          1.06654209e-02,  3.99356146e-02,  1.90717986e-02,  5.49600371e-03,\n",
       "          2.08872278e-02,  1.34323488e-02,  1.14136353e-02, -2.26947543e-02,\n",
       "         -2.89445889e-02,  3.63149983e-03, -3.17429208e-02, -1.86948783e-02,\n",
       "          7.58524843e-03, -2.51519190e-02,  1.59076956e-02, -1.57653595e-02,\n",
       "         -1.32853988e-02,  1.84268937e-02,  1.35733292e-02, -1.35745752e-02,\n",
       "         -2.62841402e-02, -1.71081547e-03, -6.57123376e-02,  1.80123245e-02,\n",
       "          2.18237573e-02,  4.92439771e-03, -4.24249468e-03,  1.44695216e-02,\n",
       "          1.61562532e-02, -5.86160831e-03,  1.07315954e-02,  2.03850600e-02,\n",
       "         -9.68246967e-03, -9.98037382e-03,  6.31454679e-07, -2.24527261e-02,\n",
       "          5.15347347e-03, -1.18663279e-02, -4.56879624e-03,  4.84564375e-02,\n",
       "          5.10890407e-03, -1.10297034e-03, -5.12788351e-03, -1.27865401e-02,\n",
       "          1.69212758e-02, -2.37873653e-04,  7.97397964e-03, -1.12930849e-02,\n",
       "         -4.02350222e-04, -1.98382137e-02,  2.10519730e-03, -1.94884122e-03,\n",
       "         -1.41923877e-02,  1.53408167e-02, -3.14154498e-02,  5.16255789e-03,\n",
       "          6.93068941e-03,  1.27301166e-02,  2.95631792e-03, -1.99976450e-02,\n",
       "         -1.29251593e-02,  2.83612074e-02, -1.00102755e-02, -3.59831313e-03,\n",
       "          9.12615437e-03,  3.19957247e-02, -2.39536587e-03, -1.88541424e-03,\n",
       "          1.71505670e-02,  6.10816907e-02, -2.02739033e-02,  3.70995447e-04,\n",
       "         -1.79623004e-02, -9.18574379e-04,  2.46088662e-02, -5.23656944e-03,\n",
       "         -3.28713545e-02, -1.66103211e-02, -2.97392304e-02,  1.05556641e-02,\n",
       "          1.15840674e-02,  5.76075530e-02,  5.02314960e-02,  2.17064867e-02,\n",
       "          8.58374305e-03, -6.60827014e-02, -4.82426792e-03, -1.56691531e-02,\n",
       "          2.12149921e-02, -2.74767225e-02, -1.23504192e-02,  1.28560904e-02,\n",
       "          2.30588782e-02, -1.09581482e-02,  6.07751199e-03,  1.72556543e-02,\n",
       "         -1.97553865e-03,  1.22152828e-02,  1.04813740e-02,  1.40103719e-02,\n",
       "          5.37980764e-03, -5.76685295e-02,  1.36694746e-02, -2.36321303e-02,\n",
       "         -8.50384182e-03,  3.60939922e-02, -2.06882135e-03,  1.76951758e-02,\n",
       "          1.57728072e-02,  2.88058438e-02, -8.86882738e-03,  6.88743752e-02,\n",
       "          6.25128593e-03,  3.75693638e-03,  3.87385404e-05, -1.95502007e-02,\n",
       "         -5.08330865e-03, -6.56666336e-03, -4.60735302e-03, -1.69378997e-02,\n",
       "          2.03075495e-02, -4.75446082e-02, -2.89494102e-02, -7.66059492e-03,\n",
       "         -2.24331713e-03,  8.62236897e-02, -2.80728569e-02, -4.31060661e-03,\n",
       "          1.31037543e-02,  6.93664039e-03,  8.79472834e-03,  5.53005787e-02,\n",
       "         -3.09062304e-03, -1.42629341e-02, -2.72252156e-02,  1.37947659e-02,\n",
       "         -3.86245701e-03, -1.68961022e-03,  1.90346599e-02, -1.98370433e-02,\n",
       "          2.21129468e-04,  8.48248098e-03,  1.53173742e-02, -4.47935110e-02,\n",
       "          5.90692373e-02,  4.12743244e-03,  2.69058790e-02, -7.84230922e-03,\n",
       "         -1.00485311e-02,  3.48163964e-03, -7.07877696e-03, -8.69120567e-03,\n",
       "         -1.09471734e-02, -5.26084500e-03, -8.29154383e-03,  1.45321145e-02,\n",
       "          1.17931868e-02,  1.51625271e-03,  5.06379921e-05,  3.64201031e-02,\n",
       "         -5.98440757e-03,  4.41127321e-03, -2.08663335e-02, -1.70784310e-02,\n",
       "         -2.18255851e-02,  6.00788341e-03,  5.07507834e-03, -1.38918141e-02,\n",
       "         -6.91033048e-03,  1.14552128e-02,  6.34593222e-02, -1.32782786e-02,\n",
       "         -1.52115628e-02,  4.98272376e-02,  1.72577717e-02, -1.29923328e-02,\n",
       "         -1.60627377e-02,  4.10427215e-02, -2.45433983e-03,  5.57846760e-03,\n",
       "         -2.11911409e-02, -2.09040772e-03,  4.27414873e-02,  2.59594736e-02,\n",
       "         -2.21033701e-02, -9.22074085e-03,  6.56417001e-03, -6.15493147e-03,\n",
       "         -6.36646366e-03, -2.16802575e-02,  2.19316476e-02, -1.32581929e-03,\n",
       "         -8.58274602e-03,  1.45549130e-03, -1.33940025e-02, -4.33783476e-03,\n",
       "          9.55339827e-03, -2.29094632e-02, -3.11402989e-03, -1.97023859e-02,\n",
       "          2.13536615e-03, -1.45499117e-02,  2.32157588e-02, -2.51983588e-02,\n",
       "         -2.26461076e-02,  9.16354896e-03,  2.66498964e-02, -1.95218307e-02,\n",
       "         -5.17713434e-02, -2.78031737e-02, -2.49143180e-02,  5.64633386e-03,\n",
       "         -1.70476468e-02,  1.34696997e-02, -5.37980768e-03, -2.86228522e-02,\n",
       "          1.15971552e-02,  1.62302861e-02, -1.50279653e-02, -3.47484244e-02,\n",
       "         -2.68725549e-02, -6.37603429e-03,  1.05356869e-04, -1.25608841e-02,\n",
       "         -4.91036526e-03, -5.21338575e-04,  4.98603459e-02, -1.67891928e-03,\n",
       "         -2.89849270e-03, -2.52519604e-02,  1.43659082e-02, -1.06123175e-02]),\n",
       "  array([-6.83419957e-03, -1.18342274e-02,  2.81851265e-02,  1.56639266e-02,\n",
       "         -8.56577435e-04, -8.51332926e-04,  1.97378555e-02, -1.29571395e-02,\n",
       "          4.93545554e-02, -2.41754346e-02, -6.15790577e-03,  2.05138671e-02,\n",
       "          1.93670358e-02,  2.11652259e-02,  2.54499821e-02,  1.63368237e-02,\n",
       "          4.16049481e-03,  3.83112881e-02,  2.22273047e-02,  4.62837957e-03,\n",
       "          8.80235256e-03, -2.01674838e-03, -1.16806213e-02,  4.86109168e-02,\n",
       "          1.98380204e-02, -1.89877654e-03, -4.72341870e-02, -4.54726101e-03,\n",
       "         -7.67185251e-03, -5.59219061e-05, -9.20897783e-03,  7.59127691e-03,\n",
       "          7.42895688e-04, -6.14518295e-03,  1.84238488e-02, -2.73708592e-02,\n",
       "          3.67920039e-03,  5.15129104e-02,  4.80286734e-03, -9.51228594e-03,\n",
       "         -1.11621336e-02, -9.42123322e-03, -4.36669167e-03, -1.52258050e-02,\n",
       "          9.90805424e-04, -1.54695765e-01,  1.73456723e-02,  4.71676183e-03,\n",
       "          4.02265375e-03, -2.22887292e-02, -4.60747433e-03,  3.95980001e-03,\n",
       "         -4.49414413e-02, -1.66012033e-02, -1.11012129e-02,  2.86654471e-02,\n",
       "          2.77660979e-02,  2.29358544e-02, -9.27368574e-03,  1.76946555e-02,\n",
       "          3.86702123e-02, -2.49444389e-02,  8.16866338e-04, -1.31154861e-02,\n",
       "          4.54887142e-02,  1.82431527e-03, -9.26950632e-03, -1.15554111e-02,\n",
       "          2.80840740e-02,  1.72604205e-02,  5.92232558e-03,  1.80038366e-02,\n",
       "          4.91635839e-02,  2.28532993e-02,  6.92838741e-03, -3.29340996e-02,\n",
       "         -2.60844809e-02, -3.53558118e-03, -2.37629223e-02, -1.33396815e-02,\n",
       "          3.39014677e-02, -2.58249188e-02,  1.58621179e-02, -1.38280199e-02,\n",
       "         -1.94001082e-02,  3.23780085e-02,  8.73536972e-03, -1.06491400e-02,\n",
       "         -2.06113311e-02, -1.00204539e-02, -5.92414899e-02,  2.21567742e-02,\n",
       "          1.96703621e-02,  4.83981773e-03,  4.64754394e-03,  1.72329994e-02,\n",
       "          3.77878697e-03, -7.31476285e-03,  2.15761497e-02,  2.36946578e-02,\n",
       "         -3.94739185e-04, -3.15822189e-03,  6.27627253e-03, -1.63456528e-02,\n",
       "         -2.86408123e-03, -1.34084593e-02, -2.05908982e-02,  3.79488378e-02,\n",
       "         -2.59135821e-03, -5.99367373e-03, -5.48361672e-03, -2.25192984e-02,\n",
       "          1.53839963e-02, -1.96333146e-03,  1.04385230e-02, -9.95364947e-03,\n",
       "         -9.15884628e-04, -5.44193423e-03, -2.63560402e-03, -1.20995468e-02,\n",
       "         -1.94892631e-02,  5.10339449e-03, -3.99716956e-02,  6.63766081e-03,\n",
       "          2.83341507e-02,  1.61479897e-02, -6.24960469e-03, -2.01853115e-02,\n",
       "         -2.30493463e-02,  2.41974686e-02, -1.18435264e-02,  3.91196668e-03,\n",
       "          1.57427261e-02,  3.39905907e-02,  1.78401215e-02, -5.43773888e-03,\n",
       "          1.96007225e-02,  8.70553736e-02, -2.09045670e-02,  5.44575620e-03,\n",
       "         -1.74754817e-02, -6.31366838e-03,  4.67595758e-03,  1.15769349e-03,\n",
       "         -2.48051513e-02, -1.49467794e-02,  8.50755240e-03,  3.35060067e-02,\n",
       "          3.74447485e-03,  4.09239615e-02,  3.32012232e-02,  3.43022553e-02,\n",
       "          1.95873175e-03, -4.23116064e-02, -1.78572984e-03, -2.38531207e-02,\n",
       "          2.10662950e-03, -2.19738587e-02, -1.20522812e-02, -3.03089888e-03,\n",
       "          2.11344370e-02, -8.71930295e-03,  7.29551984e-03,  1.66129700e-02,\n",
       "         -1.27604342e-02,  9.56745217e-03,  6.98299118e-03,  2.53704170e-02,\n",
       "         -4.42790063e-03, -3.90480910e-02,  8.54313270e-03, -2.50870639e-02,\n",
       "         -3.21222553e-05,  1.70423389e-02,  1.84731972e-02,  2.96567194e-03,\n",
       "          2.61907966e-02,  1.49996948e-02, -2.33189960e-02,  6.46570743e-02,\n",
       "          3.11559877e-03,  2.37721322e-02,  1.93601322e-02, -2.57546712e-02,\n",
       "         -1.83501803e-02, -1.41467092e-02, -3.99285842e-03, -1.79875420e-02,\n",
       "          1.90183532e-02, -2.44178147e-02, -1.57051930e-02, -2.09854681e-02,\n",
       "          1.37791918e-03,  7.44763341e-02, -1.74727091e-02,  3.67230073e-03,\n",
       "          1.56129086e-02,  6.37680905e-04,  1.01134477e-02,  2.87668182e-02,\n",
       "          2.03147982e-02, -1.17364094e-02, -1.45116558e-02,  6.01164431e-03,\n",
       "         -7.51482784e-03, -1.18620916e-02,  1.71493723e-02, -1.25271817e-02,\n",
       "         -1.03429024e-02, -4.95697306e-03,  3.03381939e-02, -3.41038112e-02,\n",
       "          4.47540520e-02,  1.99627772e-02,  1.54856961e-02, -1.28739820e-02,\n",
       "         -1.37375703e-02,  7.22146110e-03, -1.12781470e-02, -3.54985917e-03,\n",
       "         -1.46177715e-02,  1.68767010e-02, -1.02305389e-03,  4.97828967e-03,\n",
       "         -4.69090611e-03, -7.10695948e-03,  5.32717242e-03,  2.88679476e-02,\n",
       "         -2.48944984e-03, -3.63596450e-04, -1.58664227e-02, -2.27195900e-02,\n",
       "         -1.06893757e-02, -1.09062554e-03,  1.24194070e-02,  1.34343369e-02,\n",
       "          2.25927407e-03,  5.54371125e-03,  6.09565856e-02, -9.14932218e-03,\n",
       "         -1.07793950e-02,  4.92963797e-02,  1.36362660e-02, -1.14051405e-02,\n",
       "         -1.74310632e-02,  5.70965599e-02, -1.19615038e-02,  1.05203062e-02,\n",
       "         -4.02353531e-03,  5.68556388e-03,  5.59104681e-02,  1.28396213e-02,\n",
       "         -1.06977573e-02, -1.08159224e-02, -1.46696972e-02, -9.03286637e-03,\n",
       "         -3.02932333e-04, -5.26778925e-04,  2.86689934e-02,  2.36106037e-03,\n",
       "         -4.98861461e-03,  6.93722282e-03, -7.73450376e-03, -8.31161353e-03,\n",
       "          7.77818995e-03, -6.43278433e-03, -1.27221542e-02,  1.05815064e-02,\n",
       "          2.84699066e-03, -2.10621337e-02, -3.27117528e-03, -2.31504872e-02,\n",
       "         -4.80825505e-03, -1.02471190e-02,  6.89615496e-03, -2.43042988e-02,\n",
       "         -1.73822640e-02, -2.59426005e-02, -2.67280864e-02,  1.26821842e-02,\n",
       "          1.60994342e-03,  3.71996485e-03, -5.48653625e-03, -1.88920388e-02,\n",
       "          1.97826725e-02,  4.47507107e-03, -1.87621528e-02, -2.91604958e-02,\n",
       "         -1.39914642e-02, -1.30793378e-02, -9.50955897e-04, -3.02010468e-02,\n",
       "          4.11583971e-03, -7.42575856e-03,  3.74844929e-02, -1.16436960e-02,\n",
       "         -1.95666894e-02, -1.67785357e-02,  2.49638147e-02, -8.38376810e-03])),\n",
       " 3.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_no_tfidf = map_pairs(wv_model, train_preproc, tf_idf_model=None, dictionary=diccionario, )\n",
    "mapped_train_tfidf = map_pairs(wv_model,train_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "\n",
    "mapped_val_no_tfidf = map_pairs(wv_model,val_preproc, tf_idf_model=None, dictionary=diccionario, )\n",
    "mapped_val_tfidf = map_pairs(wv_model,val_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "\n",
    "mapped_train_tfidf[0]# Imprimir los pares de vectores y la puntuaci贸n de similitud asociada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dimensi贸n reducida: <sb>\n",
    "\n",
    "- s铆 usando pesos TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_50 = map_pairs(wv_model_50d, train_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_100 = map_pairs(wv_model_100d, train_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_150 = map_pairs(wv_model_150d, train_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "\n",
    "\n",
    "mapped_val_50 = map_pairs(wv_model_50d, val_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_val_100 = map_pairs(wv_model_100d, val_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped_val_150 = map_pairs(wv_model_150d, val_preproc, tf_idf_model=modelo_tfidf, dictionary=diccionario, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(50,)\n",
      "(100,)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las dimensiones de los vectores resultantes\n",
    "print(mapped_no_tfidf[0][0][0].shape)\n",
    "print(mapped_train_tfidf[0][0][0].shape)\n",
    "print(mapped_50[0][0][0].shape)\n",
    "print(mapped_100[0][0][0].shape)\n",
    "print(mapped_150[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definici贸n de diferentes modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:33.852866Z",
     "start_time": "2025-05-23T14:59:29.286142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir el Modelo\n",
    "\n",
    "def build_and_compile_model(hidden_size: int = 128, embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Esto crea una red neuronal de manera que al entrenarla las distancias coseno cuadren con la etiqueta real\n",
    "    hidden_size: Tama帽o de capas ocultas (no se usa en este c贸digo)\n",
    "    embedding_size: Dimensi贸n de los vectores de entrada (300)\n",
    "    learning_rate: Tasa de aprendizaje para el optimizador\n",
    "    \"\"\"\n",
    "    # Capa de entrada para los pares de vectores\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,)) #los pares de vectores a comparar\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,))\n",
    "\n",
    "    # Capa oculta, con funcion de activacion lineal, tiene como objetivo proyectar los vectores de entrada en un nuevo espacio.\n",
    "    \"\"\"\n",
    "    La capa oculta (en este caso, la capa densa) tiene pesos que se ajustan durante el entrenamiento.\n",
    "    Estos pesos son los que transforman los vectores de entrada en los vectores proyectados\n",
    "    \"\"\"\n",
    "    first_projection = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        # activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),# inicializa los pesos de la capa como una matriz identidad\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "    )\n",
    "    #aplica la capa de proyeccion a los dos vectores de entrada\n",
    "    projected_1 = first_projection(input_1)\n",
    "    projected_2 = first_projection(input_2)\n",
    "\n",
    "    normalize = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))\n",
    "    projected_1 = normalize(projected_1)\n",
    "    projected_2 = normalize(projected_2)\n",
    "    output = tf.keras.layers.Lambda(lambda tensors: 2.5 * (1.0 + tf.reduce_sum(tensors[0] * tensors[1], axis=1)))([projected_1, projected_2])\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output) #Durante el entrenamiento, Keras ajusta los pesos de la capa oculta para minimizar la funci贸n de p茅rdida definida (en este caso, el error absoluto medio).\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**build_and_compile_model**: Proyecci贸n lineal + Similitud Coseno \n",
    "\n",
    "Arquitectura:\n",
    "\n",
    "- Aplica una capa densa compartida (misma proyecci贸n) a cada vector por separado. Inicialmente es una matriz identidad.\n",
    "- Los normaliza a magnitud 1.\n",
    "- Calcula la similitud coseno como cos(胃) = dot(product).\n",
    "- La salida es 2.5 * (1 + similitud_coseno), lo cual transforma el rango [-1, 1] a [0, 5].\n",
    "- Se entrena con MAE (Mean Absolute Error).\n",
    "\n",
    "Objetivo:\n",
    "- Aprender una proyecci贸n donde la similitud coseno refleje la puntuaci贸n deseada (por ejemplo, cu谩n similares son dos textos o frases).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_aggregated(embedding_dim: int, hidden_size: int = 128, dropout_rate: float = 0.3) -> tf.keras.Model:\n",
    "    input_1 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_dim,), name=\"input_vector_2\")\n",
    "    concatenated = tf.keras.layers.Concatenate(axis=-1)([input_1, input_2])\n",
    "    x = tf.keras.layers.BatchNormalization()(concatenated)\n",
    "    x = tf.keras.layers.Dense(hidden_size, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x) # Activaci贸 lineal per a regressi贸\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "#model_agg.fit([X1_train, X2_train], Y_train, epochs=..., batch_size=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo **build_model_aggregated**: Concatenaci贸n + Red Neuronal Densa\n",
    "Arquitectura:\n",
    "- Toma dos vectores de entrada (input_vector_1, input_vector_2).\n",
    "- Los concatena (Concatenate), por lo que la dimensi贸n del vector combinado es el doble del embedding_dim.\n",
    "- Aplica:\n",
    "    - BatchNormalization\n",
    "    - Dense con ReLU\n",
    "    - Otro BatchNormalization\n",
    "    - Dropout\n",
    "    - Una capa de salida densa sin activaci贸n (regresi贸n lineal).\n",
    "    - Se entrena con MSE (Mean Squared Error).\n",
    "\n",
    "Objetivo:\n",
    "- Aprender una funci贸n no lineal entre los vectores concatenados y la puntuaci贸n objetivo (p. ej., similitud STS, afinidad, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_and_compile_model2(embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    # Input layer\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_2\")\n",
    "\n",
    "    # hidden layer\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.3, name=\"projection_dropout\")\n",
    "    projected_1_dense = dropout(first_projection_layer(input_1))\n",
    "    projected_2_dense = dropout(first_projection_layer(input_2))\n",
    "\n",
    "    # Normalize the projected vectors using Lambda layers\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1_dense)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2_dense)\n",
    "\n",
    "    # Compute the custom similarity score using a Lambda layer\n",
    "    similarity_sum = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"similarity_sum\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    output = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\" #cambiar 0.5 por 2.5 para que este entre 0 y 5 \n",
    "    )(similarity_sum)\n",
    "\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output, name=\"similarity_model\")\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo **build_and_compile_model2**.\n",
    "\n",
    "Deferencias clave con build_and_compile_model: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Aspecto                         | build_and_compile_model                  | `build_and_compile_model2`                              |\n",
    "| ------------------------------- | ----------------------------------------- | ------------------------------------------------------ |\n",
    "| **Activaci贸n en la proyecci贸n** | Ninguna (lineal)                          | `tanh` (no lineal)                                     |\n",
    "| **Regularizaci贸n**              | No hay                                    | S铆, con `Dropout`                                      |\n",
    "| **Normalizaci贸n**               | Directamente con `tf.linalg.l2_normalize` | Igual, pero encapsulada en `Lambda` layers con nombres |\n",
    "| **Similitud coseno**            | `2.5 * (1.0 + coseno)`                    | `0.5 * (1.0 + coseno)`                                 |\n",
    "| **Escalado de salida**          | Rango `[0, 5]`                            | Rango `[0, 1]`                                         |\n",
    "| **Perdida**                     | `mean_absolute_error`                     | `mean_squared_error`                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training y evaluaci贸n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir constantes de entrenamiento\n",
    "batch_size: int = 64\n",
    "num_epochs: int = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model,\n",
    "    X1_test: np.ndarray,\n",
    "    X2_test: np.ndarray,\n",
    "    Y_test: np.ndarray,\n",
    "    name: str = \"\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Eval煤a un modelo de similitud sem谩ntica sobre un conjunto de test y muestra varias m茅tricas.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado (por ejemplo, un modelo de Keras).\n",
    "        X1_test: Array de vectores de entrada 1 (frase 1).\n",
    "        X2_test: Array de vectores de entrada 2 (frase 2).\n",
    "        Y_test: Array de etiquetas verdaderas (similitud real).\n",
    "        name: Nombre del modelo (opcional, para mostrar en los resultados).\n",
    "\n",
    "    Returns:\n",
    "        Diccionario con las m茅tricas calculadas: MSE, RMSE, MAE, Pearson y Spearman.\n",
    "    \"\"\"\n",
    "    # Realiza la predicci贸n del modelo\n",
    "    y_pred = model.predict([X1_test, X2_test]).squeeze()\n",
    "    y_true = Y_test.squeeze()\n",
    "\n",
    "    # Calcula las m茅tricas de evaluaci贸n\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    spearman, _ = spearmanr(y_true, y_pred)\n",
    "\n",
    "    # Muestra los resultados por pantalla\n",
    "    print(f\"\\n Resultados para el modelo '{name}':\")\n",
    "    print(f\"MSE:      {mse:.4f}\")\n",
    "    print(f\"RMSE:     {rmse:.4f}\")\n",
    "    print(f\"MAE:      {mae:.4f}\")\n",
    "    print(f\"Pearson:  {pearson:.4f}\")\n",
    "    print(f\"Spearman: {spearman:.4f}\")\n",
    "\n",
    "    # Devuelve las m茅tricas en un diccionario\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"pearson\": pearson,\n",
    "        \"spearman\": spearman\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener Train y Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_list_to_x_y(pair_list: List[Tuple[Tuple[np.ndarray, np.ndarray], int]]) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Obtiene las matrices X_1 (N x d) , X_2 (N x d), e Y (n) a partir de listas de parejas de vectores de oraciones - Listas de (d, d, 1)\n",
    "    :param pair_list: lista que devuelve map_pairs(), lista de ((vector1, vector2), similitud), sonde vector1 y 2 son vectores agregados\n",
    "    :return:\n",
    "    transforma una lista de pares de vectores y puntuaciones en el formato adecuado para alimentar a un modelo de aprendizaje autom谩tico.\n",
    "    \"\"\"\n",
    "    _x, _y = zip(*pair_list) #_x: lista de tuplas (embedding_1, embedding_2), _y: lista de etiquetas\n",
    "    _x_1, _x_2 = zip(*_x)#_x_1: todos los embedding_1,  _x_2: todos los embedding_2\n",
    "    return (np.array(_x_1), np.array(_x_2)), np.array(_y, dtype=np.float32, ) / 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las listas de train y test USANDO TF-IDF\n",
    "x_train, y_train = pair_list_to_x_y(mapped_train_tfidf)\n",
    "x_val, y_val = pair_list_to_x_y(mapped_val_tfidf)\n",
    "\n",
    "\n",
    "# Obtener las listas de train y test SIN USAR TF-IDF\n",
    "x_train_normal, y_train_normal = pair_list_to_x_y(mapped_no_tfidf)\n",
    "x_val_normal, y_val_normal = pair_list_to_x_y(mapped_val_no_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De dimension reducida CON TF-IDF\n",
    "x_train_50, y_train_50 = pair_list_to_x_y(mapped_50)\n",
    "x_val_50, y_val_50 = pair_list_to_x_y(mapped_val_50)\n",
    "\n",
    "x_train_100, y_train_100 = pair_list_to_x_y(mapped_100)\n",
    "x_val_100, y_val_100 = pair_list_to_x_y(mapped_val_100)\n",
    "\n",
    "x_train_150, y_train_150 = pair_list_to_x_y(mapped_150)\n",
    "x_val_150, y_val_150 = pair_list_to_x_y(mapped_val_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 21:40:54.666095: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Preparar los conjuntos en forma de tensor\n",
    "#Con TF-IDF\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "#Sin TF-IDF\n",
    "train_dataset_normal = tf.data.Dataset.from_tensor_slices((x_train_normal, y_train_normal))\n",
    "train_dataset_normal = train_dataset_normal.shuffle(buffer_size=len(x_train_normal)).batch(batch_size)\n",
    "\n",
    "val_dataset_normal = tf.data.Dataset.from_tensor_slices((x_val_normal, y_val_normal))\n",
    "val_dataset_normal = val_dataset_normal.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensi贸n 50\n",
    "train_dataset_50 = tf.data.Dataset.from_tensor_slices((x_train_50, y_train_50))\n",
    "train_dataset_50 = train_dataset_50.shuffle(buffer_size=len(x_train_50)).batch(batch_size)\n",
    "\n",
    "val_dataset_50 = tf.data.Dataset.from_tensor_slices((x_val_50, y_val_50))\n",
    "val_dataset_50 = val_dataset_50.batch(batch_size)\n",
    "\n",
    "#Dimensi贸n 100\n",
    "train_dataset_100 = tf.data.Dataset.from_tensor_slices((x_train_100, y_train_100))\n",
    "train_dataset_100 = train_dataset_100.shuffle(buffer_size=len(x_train_100)).batch(batch_size)\n",
    "\n",
    "val_dataset_100 = tf.data.Dataset.from_tensor_slices((x_val_100, y_val_100))\n",
    "val_dataset_100 = val_dataset_100.batch(batch_size)\n",
    "\n",
    "\n",
    "#Dimensi贸n 150\n",
    "train_dataset_150 = tf.data.Dataset.from_tensor_slices((x_train_150, y_train_150))\n",
    "train_dataset_150 = train_dataset_150.shuffle(buffer_size=len(x_train_150)).batch(batch_size)\n",
    "\n",
    "val_dataset_150 = tf.data.Dataset.from_tensor_slices((x_val_150, y_val_150))\n",
    "val_dataset_150 = val_dataset_150.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo COS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos no entrenar ning煤n modelo si s贸lo utilizamos COS similarity. El rendiminto depender谩 completamente del Word Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando media cl谩sica la correlaci贸n de Pearson es: 0.4023026679065351\n",
      "Usando media ponderada con TF-IDF la correlaci贸n de Pearson es: 0.24358562692308788\n",
      "Usando media ponderada con TF-IDF y dimensi贸n 50, la correlaci贸n de Pearson es: 0.3632097710213902\n",
      "Usando media ponderada con TF-IDF y dimensi贸n 100, la correlaci贸n de Pearson es: 0.38166246524470904\n",
      "Usando media ponderada con TF-IDF y dimensi贸n 150, la correlaci贸n de Pearson es: 0.39754565403044134\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = []\n",
    "y_pred_normal = []\n",
    "y_pred_50 = []\n",
    "y_pred_100 = []\n",
    "y_pred_150 = []\n",
    "for j in range(len(mapped_val_tfidf)):\n",
    "    i = mapped_val_tfidf[j]\n",
    "    v1= i[0][0] \n",
    "    v2 = i[0][1]\n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_baseline.append(d)\n",
    "\n",
    "    k = mapped_val_no_tfidf[j]\n",
    "    v1 = k[0][0]\n",
    "    v2 = k[0][1] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_normal.append(d)\n",
    "\n",
    "    m = mapped_val_50[j]\n",
    "    v1 = m[0][0] \n",
    "    v2 = m[0][1]\n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_50.append(d)\n",
    "\n",
    "    l = mapped_val_100[j]\n",
    "    v1 = l[0][0]\n",
    "    v2 = l[0][1] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_100.append(d)\n",
    "\n",
    "    e = mapped_val_150[j]\n",
    "    v1 = e[0][0]\n",
    "    v2 = e[0][1] \n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_150.append(d)\n",
    "\n",
    "# Calcular la correlaci贸n de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(np.array(y_pred_baseline), y_val.flatten())\n",
    "correlation_normal, _ = pearsonr(np.array(y_pred_normal), y_val_normal.flatten())\n",
    "correlation_50, _ = pearsonr(np.array(y_pred_50), y_val_50.flatten())\n",
    "correlation_100, _ = pearsonr(np.array(y_pred_100), y_val_100.flatten())\n",
    "correlation_150, _ = pearsonr(np.array(y_pred_150), y_val_150.flatten())\n",
    "\n",
    "# Imprimir el coeficiente de correlaci贸n de Pearson\n",
    "print(f\"Usando media cl谩sica la correlaci贸n de Pearson es: {correlation}\")\n",
    "print(f\"Usando media ponderada con TF-IDF la correlaci贸n de Pearson es: {correlation_normal}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensi贸n 50, la correlaci贸n de Pearson es: {correlation_50}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensi贸n 100, la correlaci贸n de Pearson es: {correlation_100}\")\n",
    "print(f\"Usando media ponderada con TF-IDF y dimensi贸n 150, la correlaci贸n de Pearson es: {correlation_150}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vemos que, en este caso, la ponderaci贸n con los pesos TF-IDF empeora considerablemente el rendimiento. Si dos frases tienen pocas o ninguna palabra en com煤n, el coseno ser谩 bajo, aunque el significado sea parecido.\n",
    "- La reducci贸n de la dimensi贸n tambi茅n afecta negativamente al modelo. Suponemos que es debido a la p茅rdida considerable de informaci贸n.\n",
    "- Nos gustar铆a poder modificar los pesos durante el c谩lculo de la distancia coseno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Regresi贸n 1, prueba del embeding pre-entrenado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sin distancia coseno**, modelo simple de regresi贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taya/Desktop/myenv/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_vector_1', 'input_vector_2']\n",
      "Received: inputs=(('Tensor(shape=(None, 300))', 'Tensor(shape=(None, 300))'),)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2.5055 - mae: 1.2171 - root_mean_squared_error: 1.5797\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4504 - mae: 0.9192 - root_mean_squared_error: 1.2035\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9373 - mae: 0.7495 - root_mean_squared_error: 0.9679\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7207 - mae: 0.6446 - root_mean_squared_error: 0.8488\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5769 - mae: 0.5778 - root_mean_squared_error: 0.7591\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4608 - mae: 0.5098 - root_mean_squared_error: 0.6782\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3841 - mae: 0.4838 - root_mean_squared_error: 0.6198\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3248 - mae: 0.4401 - root_mean_squared_error: 0.5695\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2571 - mae: 0.3875 - root_mean_squared_error: 0.5068\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2379 - mae: 0.3707 - root_mean_squared_error: 0.4876\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1926 - mae: 0.3262 - root_mean_squared_error: 0.4387\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1742 - mae: 0.3210 - root_mean_squared_error: 0.4172\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1473 - mae: 0.2871 - root_mean_squared_error: 0.3835\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1215 - mae: 0.2612 - root_mean_squared_error: 0.3486\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1017 - mae: 0.2432 - root_mean_squared_error: 0.3188\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0901 - mae: 0.2286 - root_mean_squared_error: 0.3000\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0751 - mae: 0.2081 - root_mean_squared_error: 0.2740\n",
      "Epoch 18/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0643 - mae: 0.1959 - root_mean_squared_error: 0.2535\n",
      "Epoch 19/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0660 - mae: 0.1967 - root_mean_squared_error: 0.2566\n",
      "Epoch 20/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0569 - mae: 0.1796 - root_mean_squared_error: 0.2385\n",
      "Epoch 21/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0473 - mae: 0.1663 - root_mean_squared_error: 0.2175\n",
      "Epoch 22/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0428 - mae: 0.1590 - root_mean_squared_error: 0.2068\n",
      "Epoch 23/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0421 - mae: 0.1558 - root_mean_squared_error: 0.2051\n",
      "Epoch 24/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1531 - root_mean_squared_error: 0.2034\n",
      "Epoch 25/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.1477 - root_mean_squared_error: 0.1879\n",
      "Epoch 26/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mae: 0.1439 - root_mean_squared_error: 0.1920\n",
      "Epoch 27/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mae: 0.1336 - root_mean_squared_error: 0.1719\n",
      "Epoch 28/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mae: 0.1322 - root_mean_squared_error: 0.1696\n",
      "Epoch 29/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0286 - mae: 0.1306 - root_mean_squared_error: 0.1691\n",
      "Epoch 30/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0264 - mae: 0.1258 - root_mean_squared_error: 0.1623\n",
      "Epoch 31/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0252 - mae: 0.1230 - root_mean_squared_error: 0.1588\n",
      "Epoch 32/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0247 - mae: 0.1211 - root_mean_squared_error: 0.1572\n",
      "Epoch 33/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0253 - mae: 0.1221 - root_mean_squared_error: 0.1589\n",
      "Epoch 34/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0242 - mae: 0.1208 - root_mean_squared_error: 0.1557\n",
      "Epoch 35/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0218 - mae: 0.1143 - root_mean_squared_error: 0.1476\n",
      "Epoch 36/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0216 - mae: 0.1126 - root_mean_squared_error: 0.1468\n",
      "Epoch 37/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0208 - mae: 0.1123 - root_mean_squared_error: 0.1440\n",
      "Epoch 38/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.1111 - root_mean_squared_error: 0.1441\n",
      "Epoch 39/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0215 - mae: 0.1147 - root_mean_squared_error: 0.1467\n",
      "Epoch 40/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.1055 - root_mean_squared_error: 0.1375\n",
      "Epoch 41/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0192 - mae: 0.1089 - root_mean_squared_error: 0.1385\n",
      "Epoch 42/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0181 - mae: 0.1029 - root_mean_squared_error: 0.1344\n",
      "Epoch 43/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0183 - mae: 0.1041 - root_mean_squared_error: 0.1352\n",
      "Epoch 44/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mae: 0.1038 - root_mean_squared_error: 0.1331\n",
      "Epoch 45/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mae: 0.1009 - root_mean_squared_error: 0.1291\n",
      "Epoch 46/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.1003 - root_mean_squared_error: 0.1285\n",
      "Epoch 47/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0163 - mae: 0.0988 - root_mean_squared_error: 0.1276\n",
      "Epoch 48/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0970 - root_mean_squared_error: 0.1236\n",
      "Epoch 49/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0974 - root_mean_squared_error: 0.1241\n",
      "Epoch 50/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0958 - root_mean_squared_error: 0.1229\n",
      "Epoch 51/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0939 - root_mean_squared_error: 0.1204\n",
      "Epoch 52/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0957 - root_mean_squared_error: 0.1250\n",
      "Epoch 53/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0952 - root_mean_squared_error: 0.1230\n",
      "Epoch 54/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0918 - root_mean_squared_error: 0.1207\n",
      "Epoch 55/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0910 - root_mean_squared_error: 0.1179\n",
      "Epoch 56/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0911 - root_mean_squared_error: 0.1178\n",
      "Epoch 57/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0906 - root_mean_squared_error: 0.1155\n",
      "Epoch 58/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0922 - root_mean_squared_error: 0.1181\n",
      "Epoch 59/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0893 - root_mean_squared_error: 0.1148\n",
      "Epoch 60/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0882 - root_mean_squared_error: 0.1146\n",
      "Epoch 61/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0845 - root_mean_squared_error: 0.1099\n",
      "Epoch 62/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0883 - root_mean_squared_error: 0.1124\n",
      "Epoch 63/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0862 - root_mean_squared_error: 0.1096\n",
      "Epoch 64/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0862 - root_mean_squared_error: 0.1105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787a1155ef60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con TF-IDF\n",
    "model_no_cos = build_model_aggregated(embedding_dim=300)\n",
    "model_no_cos.fit([x_train], y_train, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      " Resultados para el modelo 'Linealmodel no cos()':\n",
      "MSE:      0.0308\n",
      "RMSE:     0.1756\n",
      "MAE:      0.1344\n",
      "Pearson:  0.2468\n",
      "Spearman: 0.2546\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val\n",
    "D_agragated_tfidf = evaluate_model(model_no_cos, X1, X2, y_val, name=\"Linealmodel no cos()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - mae: 0.1002 - root_mean_squared_error: 0.1301\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0925 - root_mean_squared_error: 0.1185\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0947 - root_mean_squared_error: 0.1213\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0952 - root_mean_squared_error: 0.1236\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0938 - root_mean_squared_error: 0.1210\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0896 - root_mean_squared_error: 0.1165\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0892 - root_mean_squared_error: 0.1123\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0861 - root_mean_squared_error: 0.1116\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0854 - root_mean_squared_error: 0.1079\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0850 - root_mean_squared_error: 0.1083\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0843 - root_mean_squared_error: 0.1083\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0847 - root_mean_squared_error: 0.1086\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0864 - root_mean_squared_error: 0.1099\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0794 - root_mean_squared_error: 0.1004\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0815 - root_mean_squared_error: 0.1060\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0789 - root_mean_squared_error: 0.1005\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0796 - root_mean_squared_error: 0.1037\n",
      "Epoch 18/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0792 - root_mean_squared_error: 0.1035\n",
      "Epoch 19/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0804 - root_mean_squared_error: 0.1040\n",
      "Epoch 20/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0821 - root_mean_squared_error: 0.1071\n",
      "Epoch 21/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0778 - root_mean_squared_error: 0.0987\n",
      "Epoch 22/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0795 - root_mean_squared_error: 0.1026\n",
      "Epoch 23/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0766 - root_mean_squared_error: 0.0988\n",
      "Epoch 24/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0777 - root_mean_squared_error: 0.0988\n",
      "Epoch 25/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0758 - root_mean_squared_error: 0.0966\n",
      "Epoch 26/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0786 - root_mean_squared_error: 0.1001\n",
      "Epoch 27/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0759 - root_mean_squared_error: 0.0983\n",
      "Epoch 28/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0745 - root_mean_squared_error: 0.0964\n",
      "Epoch 29/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0762 - root_mean_squared_error: 0.0975\n",
      "Epoch 30/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0756 - root_mean_squared_error: 0.0973\n",
      "Epoch 31/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0737 - root_mean_squared_error: 0.0958\n",
      "Epoch 32/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - mae: 0.0745 - root_mean_squared_error: 0.0958\n",
      "Epoch 33/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - mae: 0.0744 - root_mean_squared_error: 0.0961\n",
      "Epoch 34/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0725 - root_mean_squared_error: 0.0928\n",
      "Epoch 35/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0735 - root_mean_squared_error: 0.0943\n",
      "Epoch 36/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0741 - root_mean_squared_error: 0.0962\n",
      "Epoch 37/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0708 - root_mean_squared_error: 0.0909\n",
      "Epoch 38/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0734 - root_mean_squared_error: 0.0941\n",
      "Epoch 39/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - mae: 0.0724 - root_mean_squared_error: 0.0936\n",
      "Epoch 40/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0715 - root_mean_squared_error: 0.0923\n",
      "Epoch 41/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0715 - root_mean_squared_error: 0.0922\n",
      "Epoch 42/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0694 - root_mean_squared_error: 0.0896\n",
      "Epoch 43/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0720 - root_mean_squared_error: 0.0930\n",
      "Epoch 44/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0714 - root_mean_squared_error: 0.0917\n",
      "Epoch 45/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0740 - root_mean_squared_error: 0.0945\n",
      "Epoch 46/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0700 - root_mean_squared_error: 0.0892\n",
      "Epoch 47/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0686 - root_mean_squared_error: 0.0888\n",
      "Epoch 48/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - mae: 0.0704 - root_mean_squared_error: 0.0907\n",
      "Epoch 49/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0691 - root_mean_squared_error: 0.0894\n",
      "Epoch 50/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - mae: 0.0671 - root_mean_squared_error: 0.0868\n",
      "Epoch 51/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 - mae: 0.0690 - root_mean_squared_error: 0.0883\n",
      "Epoch 52/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0697 - root_mean_squared_error: 0.0895\n",
      "Epoch 53/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0714 - root_mean_squared_error: 0.0909\n",
      "Epoch 54/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0681 - root_mean_squared_error: 0.0890\n",
      "Epoch 55/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - mae: 0.0685 - root_mean_squared_error: 0.0877\n",
      "Epoch 56/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - mae: 0.0673 - root_mean_squared_error: 0.0852\n",
      "Epoch 57/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - mae: 0.0653 - root_mean_squared_error: 0.0841\n",
      "Epoch 58/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - mae: 0.0655 - root_mean_squared_error: 0.0853\n",
      "Epoch 59/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - mae: 0.0674 - root_mean_squared_error: 0.0889\n",
      "Epoch 60/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - mae: 0.0680 - root_mean_squared_error: 0.0878\n",
      "Epoch 61/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 - mae: 0.0663 - root_mean_squared_error: 0.0854\n",
      "Epoch 62/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - mae: 0.0684 - root_mean_squared_error: 0.0888\n",
      "Epoch 63/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 - mae: 0.0680 - root_mean_squared_error: 0.0876\n",
      "Epoch 64/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mae: 0.0671 - root_mean_squared_error: 0.0865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787a11cc5d00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sin TF-IDF\n",
    "model_no_cos_no_tfidf = build_model_aggregated(embedding_dim=300)\n",
    "model_no_cos.fit([x_train_normal], y_train_normal, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      " Resultados para el modelo 'Linealmodel no cos()':\n",
      "MSE:      0.0314\n",
      "RMSE:     0.1771\n",
      "MAE:      0.1336\n",
      "Pearson:  0.2577\n",
      "Spearman: 0.2713\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_normal\n",
    "D_agragated_no_tfidf = evaluate_model(model_no_cos, X1, X2, y_val_normal, name=\"Linealmodel no cos()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Este modelo no tiene mucho sentido ya que no incorpora la distancia coseno en el etrenamiento.\n",
    "- TF-IDF no mejora el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo con coseno y activaci贸n lineal:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.9945 - val_loss: 3.7056\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6515 - val_loss: 3.6114\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5301 - val_loss: 3.5616\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4431 - val_loss: 3.5285\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3736 - val_loss: 3.5051\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3150 - val_loss: 3.4873\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2658 - val_loss: 3.4731\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2222 - val_loss: 3.4616\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1845 - val_loss: 3.4523\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1504 - val_loss: 3.4442\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1203 - val_loss: 3.4382\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0945 - val_loss: 3.4321\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0659 - val_loss: 3.4259\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0443 - val_loss: 3.4209\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0237 - val_loss: 3.4212\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0064 - val_loss: 3.4163\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9916 - val_loss: 3.4113\n",
      "Epoch 18/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9654 - val_loss: 3.4094\n",
      "Epoch 19/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9524 - val_loss: 3.4086\n",
      "Epoch 20/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9458 - val_loss: 3.4032\n",
      "Epoch 21/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9251 - val_loss: 3.4048\n",
      "Epoch 22/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9131 - val_loss: 3.4020\n",
      "Epoch 23/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9056 - val_loss: 3.3984\n",
      "Epoch 24/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8859 - val_loss: 3.4009\n",
      "Epoch 25/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8778 - val_loss: 3.3985\n",
      "Epoch 26/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8601 - val_loss: 3.3935\n",
      "Epoch 27/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8550 - val_loss: 3.3945\n",
      "Epoch 28/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8422 - val_loss: 3.3896\n",
      "Epoch 29/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8310 - val_loss: 3.3928\n",
      "Epoch 30/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8329 - val_loss: 3.3882\n",
      "Epoch 31/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8126 - val_loss: 3.3889\n",
      "Epoch 32/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8039 - val_loss: 3.3847\n",
      "Epoch 33/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8008 - val_loss: 3.3835\n",
      "Epoch 34/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7868 - val_loss: 3.3809\n",
      "Epoch 35/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7791 - val_loss: 3.3857\n",
      "Epoch 36/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7747 - val_loss: 3.3763\n",
      "Epoch 37/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7584 - val_loss: 3.3758\n",
      "Epoch 38/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7541 - val_loss: 3.3794\n",
      "Epoch 39/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7460 - val_loss: 3.3720\n",
      "Epoch 40/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7293 - val_loss: 3.3734\n",
      "Epoch 41/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7257 - val_loss: 3.3781\n",
      "Epoch 42/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7268 - val_loss: 3.3668\n",
      "Epoch 43/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7059 - val_loss: 3.3663\n",
      "Epoch 44/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6971 - val_loss: 3.3667\n",
      "Epoch 45/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6917 - val_loss: 3.3664\n",
      "Epoch 46/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6877 - val_loss: 3.3641\n",
      "Epoch 47/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6779 - val_loss: 3.3617\n",
      "Epoch 48/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6703 - val_loss: 3.3623\n",
      "Epoch 49/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6637 - val_loss: 3.3563\n",
      "Epoch 50/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6568 - val_loss: 3.3633\n",
      "Epoch 51/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6633 - val_loss: 3.3573\n",
      "Epoch 52/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6457 - val_loss: 3.3486\n",
      "Epoch 53/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6400 - val_loss: 3.3491\n",
      "Epoch 54/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6288 - val_loss: 3.3510\n",
      "Epoch 55/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6255 - val_loss: 3.3454\n",
      "Epoch 56/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6160 - val_loss: 3.3435\n",
      "Epoch 57/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6051 - val_loss: 3.3443\n",
      "Epoch 58/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6046 - val_loss: 3.3423\n",
      "Epoch 59/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5962 - val_loss: 3.3375\n",
      "Epoch 60/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5871 - val_loss: 3.3327\n",
      "Epoch 61/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5813 - val_loss: 3.3409\n",
      "Epoch 62/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5849 - val_loss: 3.3296\n",
      "Epoch 63/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5716 - val_loss: 3.3295\n",
      "Epoch 64/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5638 - val_loss: 3.3310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787a0f7ef560>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lin = build_and_compile_model()\n",
    "model_lin.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo '':\n",
      "MSE:      12.1662\n",
      "RMSE:     3.4880\n",
      "MAE:      3.3310\n",
      "Pearson:  0.2451\n",
      "Spearman: 0.2986\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val\n",
    "D_lin_tfidf = evaluate_model(model_lin, X1, X2, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.0661 - val_loss: 4.1375\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5981 - val_loss: 4.2438\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3850 - val_loss: 4.2717\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2886 - val_loss: 4.2721\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2246 - val_loss: 4.2670\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1787 - val_loss: 4.2609\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1404 - val_loss: 4.2538\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1077 - val_loss: 4.2501\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0731 - val_loss: 4.2463\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0413 - val_loss: 4.2446\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0123 - val_loss: 4.2423\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9877 - val_loss: 4.2406\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9648 - val_loss: 4.2375\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9434 - val_loss: 4.2345\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9260 - val_loss: 4.2333\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9104 - val_loss: 4.2307\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8924 - val_loss: 4.2300\n",
      "Epoch 18/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8799 - val_loss: 4.2302\n",
      "Epoch 19/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8637 - val_loss: 4.2302\n",
      "Epoch 20/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8512 - val_loss: 4.2257\n",
      "Epoch 21/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8403 - val_loss: 4.2216\n",
      "Epoch 22/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8269 - val_loss: 4.2218\n",
      "Epoch 23/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8153 - val_loss: 4.2160\n",
      "Epoch 24/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8065 - val_loss: 4.2179\n",
      "Epoch 25/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7963 - val_loss: 4.2159\n",
      "Epoch 26/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7893 - val_loss: 4.2196\n",
      "Epoch 27/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7806 - val_loss: 4.2205\n",
      "Epoch 28/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7839 - val_loss: 4.2121\n",
      "Epoch 29/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7719 - val_loss: 4.2060\n",
      "Epoch 30/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7615 - val_loss: 4.1988\n",
      "Epoch 31/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7594 - val_loss: 4.1933\n",
      "Epoch 32/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7500 - val_loss: 4.1903\n",
      "Epoch 33/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7388 - val_loss: 4.1900\n",
      "Epoch 34/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7316 - val_loss: 4.1919\n",
      "Epoch 35/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7267 - val_loss: 4.1924\n",
      "Epoch 36/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7209 - val_loss: 4.1946\n",
      "Epoch 37/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7171 - val_loss: 4.1976\n",
      "Epoch 38/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7106 - val_loss: 4.1963\n",
      "Epoch 39/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7194 - val_loss: 4.1903\n",
      "Epoch 40/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7062 - val_loss: 4.1817\n",
      "Epoch 41/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7041 - val_loss: 4.1758\n",
      "Epoch 42/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6964 - val_loss: 4.1685\n",
      "Epoch 43/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6965 - val_loss: 4.1638\n",
      "Epoch 44/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7002 - val_loss: 4.1619\n",
      "Epoch 45/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6985 - val_loss: 4.1663\n",
      "Epoch 46/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6892 - val_loss: 4.1670\n",
      "Epoch 47/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6803 - val_loss: 4.1599\n",
      "Epoch 48/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6784 - val_loss: 4.1603\n",
      "Epoch 49/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6744 - val_loss: 4.1616\n",
      "Epoch 50/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6754 - val_loss: 4.1569\n",
      "Epoch 51/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6674 - val_loss: 4.1569\n",
      "Epoch 52/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6655 - val_loss: 4.1611\n",
      "Epoch 53/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6663 - val_loss: 4.1542\n",
      "Epoch 54/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6578 - val_loss: 4.1587\n",
      "Epoch 55/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6590 - val_loss: 4.1570\n",
      "Epoch 56/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6567 - val_loss: 4.1590\n",
      "Epoch 57/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6520 - val_loss: 4.1534\n",
      "Epoch 58/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6506 - val_loss: 4.1477\n",
      "Epoch 59/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6434 - val_loss: 4.1475\n",
      "Epoch 60/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6412 - val_loss: 4.1451\n",
      "Epoch 61/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6405 - val_loss: 4.1459\n",
      "Epoch 62/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6348 - val_loss: 4.1470\n",
      "Epoch 63/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6363 - val_loss: 4.1479\n",
      "Epoch 64/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6344 - val_loss: 4.1513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787a0f7e1490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lin_no_tfidf = build_and_compile_model()\n",
    "model_lin_no_tfidf.fit(train_dataset_normal, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      " Resultados para el modelo '':\n",
      "MSE:      13.4533\n",
      "RMSE:     3.6679\n",
      "MAE:      3.3347\n",
      "Pearson:  0.1075\n",
      "Spearman: 0.1922\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_normal\n",
    "D_lin_no_itfidf = evaluate_model(model_lin_no_tfidf, X1, X2, y_val_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vemos que resultados no meoran incorporando la distancia coseno en el entrenamiento.\n",
    "- La ponderaci贸n TF-IDF, en este caso, s铆 que mejora el rendimineto del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo con coeno y activaci贸n no lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1045 - val_loss: 0.1450\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0820 - val_loss: 0.1353\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0760 - val_loss: 0.1305\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0729 - val_loss: 0.1264\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0698 - val_loss: 0.1231\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0659 - val_loss: 0.1206\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0634 - val_loss: 0.1185\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0607 - val_loss: 0.1165\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0583 - val_loss: 0.1153\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0566 - val_loss: 0.1145\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0549 - val_loss: 0.1135\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0534 - val_loss: 0.1124\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0513 - val_loss: 0.1120\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0507 - val_loss: 0.1105\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0488 - val_loss: 0.1100\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481 - val_loss: 0.1100\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0470 - val_loss: 0.1089\n",
      "Epoch 18/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0459 - val_loss: 0.1089\n",
      "Epoch 19/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0453 - val_loss: 0.1081\n",
      "Epoch 20/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0438 - val_loss: 0.1077\n",
      "Epoch 21/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0433 - val_loss: 0.1076\n",
      "Epoch 22/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0427 - val_loss: 0.1075\n",
      "Epoch 23/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0416 - val_loss: 0.1070\n",
      "Epoch 24/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.1068\n",
      "Epoch 25/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0403 - val_loss: 0.1064\n",
      "Epoch 26/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.1059\n",
      "Epoch 27/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.1056\n",
      "Epoch 28/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0382 - val_loss: 0.1056\n",
      "Epoch 29/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - val_loss: 0.1056\n",
      "Epoch 30/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.1053\n",
      "Epoch 31/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - val_loss: 0.1053\n",
      "Epoch 32/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.1054\n",
      "Epoch 33/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.1049\n",
      "Epoch 34/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.1050\n",
      "Epoch 35/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.1048\n",
      "Epoch 36/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.1043\n",
      "Epoch 37/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.1045\n",
      "Epoch 38/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.1044\n",
      "Epoch 39/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.1044\n",
      "Epoch 40/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0336 - val_loss: 0.1042\n",
      "Epoch 41/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0332 - val_loss: 0.1038\n",
      "Epoch 42/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0324 - val_loss: 0.1039\n",
      "Epoch 43/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0325 - val_loss: 0.1041\n",
      "Epoch 44/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.1042\n",
      "Epoch 45/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.1040\n",
      "Epoch 46/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.1037\n",
      "Epoch 47/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.1038\n",
      "Epoch 48/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.1034\n",
      "Epoch 49/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0308 - val_loss: 0.1037\n",
      "Epoch 50/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0304 - val_loss: 0.1040\n",
      "Epoch 51/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.1038\n",
      "Epoch 52/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.1034\n",
      "Epoch 53/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - val_loss: 0.1035\n",
      "Epoch 54/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - val_loss: 0.1035\n",
      "Epoch 55/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - val_loss: 0.1034\n",
      "Epoch 56/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289 - val_loss: 0.1034\n",
      "Epoch 57/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - val_loss: 0.1034\n",
      "Epoch 58/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - val_loss: 0.1035\n",
      "Epoch 59/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0285 - val_loss: 0.1034\n",
      "Epoch 60/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.1032\n",
      "Epoch 61/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0284 - val_loss: 0.1034\n",
      "Epoch 62/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - val_loss: 0.1033\n",
      "Epoch 63/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0280 - val_loss: 0.1035\n",
      "Epoch 64/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0279 - val_loss: 0.1032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787a0ed8cd70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_no_lin = build_and_compile_model2()\n",
    "# Entrenar el modelo\n",
    "model_no_lin.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo '':\n",
      "MSE:      0.1032\n",
      "RMSE:     0.3212\n",
      "MAE:      0.2868\n",
      "Pearson:  0.4717\n",
      "Spearman: 0.4755\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val\n",
    "D_no_lin_tfidf = evaluate_model(model_no_lin, X1, X2, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_lin_no_tfidf = build_and_compile_model2()\n",
    "model_no_lin_no_tfidf.fit(train_dataset_normal, epochs=num_epochs, validation_data=val_dataset_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo '':\n",
      "MSE:      0.1050\n",
      "RMSE:     0.3240\n",
      "MAE:      0.2848\n",
      "Pearson:  0.3791\n",
      "Spearman: 0.4134\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_normal\n",
    "D_no_lin_no_tfidf = evaluate_model(model_no_lin_no_tfidf, X1, X2, y_val_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El uso de TF-IDF mejora los resultados. <sb>\n",
    "- La activaci贸n no lineal y la incorporaci贸n de la distancia coseno dentro del enrenamiento mejora el rendimiento.\n",
    "\n",
    "### El impacto de la dimensionalidad:\n",
    "\n",
    "Para la evaluaci贸n del impacto de la dimensionalidad se va a usar el mejor modelo hasta el momento, que es `build_and_compile_model2()`. Usando la ponderaci贸n TF-IDF ya que, como hemos visto, permite mejorar el rendimineto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_lin_50 = build_and_compile_model2(embedding_size = 50)\n",
    "model_no_lin_50.fit(train_dataset_50, epochs=num_epochs, validation_data=val_dataset_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo 'De dimansi贸n 50':\n",
      "MSE:      0.1203\n",
      "RMSE:     0.3469\n",
      "MAE:      0.3119\n",
      "Pearson:  0.4211\n",
      "Spearman: 0.4397\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_50\n",
    "D_50 = evaluate_model(model_no_lin_50, X1, X2, y_val_50, \"De dimansi贸n 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_lin_100 = build_and_compile_model2(embedding_size = 100)\n",
    "model_no_lin_100.fit(train_dataset_100, epochs=num_epochs, validation_data=val_dataset_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo 'De dimansi贸n 100':\n",
      "MSE:      0.1104\n",
      "RMSE:     0.3323\n",
      "MAE:      0.2986\n",
      "Pearson:  0.4619\n",
      "Spearman: 0.4844\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_100\n",
    "D_100 = evaluate_model(model_no_lin_100, X1, X2, y_val_100, \"De dimansi贸n 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_lin_150 = build_and_compile_model2(embedding_size = 150)\n",
    "model_no_lin_150.fit(train_dataset_150, epochs=num_epochs, validation_data=val_dataset_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " Resultados para el modelo '':\n",
      "MSE:      0.1075\n",
      "RMSE:     0.3279\n",
      "MAE:      0.2941\n",
      "Pearson:  0.4702\n",
      "Spearman: 0.4877\n"
     ]
    }
   ],
   "source": [
    "X1, X2 = x_val_150\n",
    "D_150 = evaluate_model(model_no_lin_150, X1, X2, y_val_150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un tama帽o de embeding 100 da los mejores resultados. Parece que una dimensi贸n menor permite generalizar un poco mejor al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado evaluaremos la mejor arquitectura encontrada hasta ahora (build_and_compile_model2) utilizando el embeding de Spacy, que ya devuelve el vector de la oraci贸n promediado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ca_core_news_md\") #previamente hay que descargar: python -m spacy download ca_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_spacy(model, train: Iterable[dict]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Procesa los datos de entrenamiento para extraer los embeddings de las frases y las puntuaciones.\n",
    "    Args:\n",
    "        model: Un modelo de lenguaje spaCy cargado.\n",
    "        train: Iterable de diccionarios con las claves 'sentence_1', 'sentence_2' y 'label'.\n",
    "        \n",
    "    Devuelve tres arrays: vectores de sentence_1, sentence_2 y etiquetas.\n",
    "    \"\"\"\n",
    "    e1_list = []\n",
    "    e2_list = []\n",
    "    scores = []\n",
    "    for i in train:\n",
    "        s1 = model(i[\"sentence_1\"])\n",
    "        s2 = model(i[\"sentence_2\"])\n",
    "        e1_list.append(s1.vector)\n",
    "        e2_list.append(s2.vector)\n",
    "        scores.append(i[\"label\"]/ 5.0)\n",
    "    return np.array(e1_list), np.array(e2_list), np.array(scores, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train_s, x2_train_s, y_train_s = prepare_spacy(nlp, train)\n",
    "x1_val_s, x2_val_s, y_val_s = prepare_spacy(nlp, val)\n",
    "\n",
    "train_dataset_s = tf.data.Dataset.from_tensor_slices(((x1_train_s, x2_train_s), y_train_s))\n",
    "train_dataset_s = train_dataset_s.shuffle(buffer_size=len(x1_train_s)).batch(batch_size)\n",
    "\n",
    "val_dataset_s = tf.data.Dataset.from_tensor_slices(((x1_val_s, x2_val_s), y_val_s))\n",
    "val_dataset_s = val_dataset_s.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar\n",
    "model_no_lin_con_s = build_and_compile_model2(embedding_size=300)\n",
    "model_no_lin_con_s.fit(train_dataset_s, epochs=num_epochs, validation_data=val_dataset_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      " Resultados para el modelo 'Spacy Embedding':\n",
      "MSE:      0.0975\n",
      "RMSE:     0.3122\n",
      "MAE:      0.2658\n",
      "Pearson:  0.2863\n",
      "Spearman: 0.2975\n"
     ]
    }
   ],
   "source": [
    "# Evaluar\n",
    "D_s = evaluate_model(model_no_lin_con_s, x1_val_s, x2_val_s, y_val_s, \"Spacy Embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos uno de los peores resultados. Podemos inferir que el modelo de FastText es mucho m谩s potente. <sb>\n",
    "\n",
    "Adem谩s podr铆amos decir que, en general, el promediado de vectores de palabras:\n",
    "- Pierde el orden de las palabras.\n",
    "- No modela interacciones sint谩cticas ni sem谩nticas complejas.\n",
    "- Se ve afectado mucho si hay muchas palabras comunes o sin informaci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa fine-tuned por STS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo est谩 pre-entrenado para maximizar la correlacion de Pearson y Searman m茅dia. Si antes las palabras tien铆an el mismo embedding en diferentes contextos, ahora se entrena un modelo espec铆fico para captar similitudes entre oraciones del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs_ = [(item['sentence_1'], item['sentence_2']) for item in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se modifica el codigo propuesto en HuggingFase por causa de problemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_corregida_huggingface(sentence_pairs):\n",
    "    model = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    # Preparar pares usando el tokenizer correctamente\n",
    "    texts = [f\"{s1} [SEP] {s2}\" for s1, s2 in sentence_pairs]\n",
    "    predictions = pipe(texts)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "predicted_scores = version_corregida_huggingface(sentence_pairs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores = [item['score'] for item in predicted_scores]\n",
    "true_scores = [item['label'] for item in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3242\n",
      "MAE: 0.4224\n",
      "Pearson correlation: 0.7496\n",
      "Spearman correlation: 0.7304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Calcular errores\n",
    "mse = mean_squared_error(true_scores, predicted_scores)\n",
    "mae = mean_absolute_error(true_scores, predicted_scores)\n",
    "\n",
    "# Calcular correlaciones\n",
    "pearson_corr, _ = pearsonr(true_scores, predicted_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, predicted_scores)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f}\")\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fine-tunnig mejora muy significativamente el rendimiento del modelo. Este es el modelo con el mejor rendimiento que obtenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa reentrenado con coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento del modelo RoBERTa podemos a帽adir la similitud de coseno como la predicci贸n de similitud de las frases. Esto permite crear un embeding donde la direcci贸n representa el significado de la frase, y la mejor forma de medirlo es con el coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs_train = [(item['sentence_1'], item['sentence_2']) for item in train]\n",
    "true_scores_train = [item['label']/5 for item in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equilibramos el dataset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(true_scores_train, bins=20)\n",
    "plt.title(\"Distribuci贸n de etiquetas reales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a numpy\n",
    "scores = np.array(true_scores_train)\n",
    "pairs = np.array(sentence_pairs_train)\n",
    "\n",
    "# Seleccionar ejemplos por rangos\n",
    "mask_low = (scores <= 0.3)\n",
    "mask_mid = (scores > 0.3) & (scores <= 0.7)\n",
    "mask_high = (scores > 0.7)\n",
    "\n",
    "# Balancear\n",
    "n = min(mask_low.sum(), mask_mid.sum(), mask_high.sum())  # Tama帽o m铆nimo de los grupos\n",
    "\n",
    "# Tomar n ejemplos de cada grupo\n",
    "balanced_pairs = np.concatenate([\n",
    "    pairs[mask_low][:n],\n",
    "    pairs[mask_mid][:n],\n",
    "    pairs[mask_high][:n]\n",
    "])\n",
    "balanced_scores = np.concatenate([\n",
    "    scores[mask_low][:n],\n",
    "    scores[mask_mid][:n],\n",
    "    scores[mask_high][:n]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2-cased-sts and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 1. Dataset\n",
    "\n",
    "class SimilarityDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para pares de frases y sus similitudes.\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs: List[Tuple[str, str]], similarities: List[float], tokenizer: Any, max_len: int = 128):\n",
    "        self.pairs = pairs\n",
    "        self.similarities = similarities\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        sent1, sent2 = self.pairs[idx]\n",
    "        similarity = self.similarities[idx]\n",
    "\n",
    "        encoded1 = self.tokenizer(sent1, padding='max_length', truncation=True,\n",
    "                                  max_length=self.max_len, return_tensors='pt')\n",
    "        encoded2 = self.tokenizer(sent2, padding='max_length', truncation=True,\n",
    "                                  max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids1': encoded1['input_ids'].squeeze(0),\n",
    "            'attention_mask1': encoded1['attention_mask'].squeeze(0),\n",
    "            'input_ids2': encoded2['input_ids'].squeeze(0),\n",
    "            'attention_mask2': encoded2['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(similarity, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# 2. Modelo con pooling + comparaci贸n\n",
    "class SimilarityModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo de similitud basado en un encoder de Transformers.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids1: torch.Tensor, attention_mask1: torch.Tensor,\n",
    "                input_ids2: torch.Tensor, attention_mask2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        out1 = self.encoder(input_ids=input_ids1, attention_mask=attention_mask1)\n",
    "        out2 = self.encoder(input_ids=input_ids2, attention_mask=attention_mask2)\n",
    "\n",
    "        # Usamos el embedding del token [CLS]\n",
    "        emb1 = out1.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
    "        emb2 = out2.last_hidden_state[:, 0, :]\n",
    "\n",
    "        return emb1, emb2\n",
    "\n",
    "# 3. Funci贸n de p茅rdida: Cosine Similarity Loss\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Funci贸n de p茅rdida basada en la similitud coseno y MSE.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cos_sim = nn.CosineSimilarity(dim=1)\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, emb1: torch.Tensor, emb2: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        sim = self.cos_sim(emb1, emb2)  # predicci贸n\n",
    "        loss = self.mse(sim, labels)    # MSE entre predicci贸n y similitud real\n",
    "        return loss\n",
    "\n",
    "# Preparaci贸n de tokenizer, dataset, dataloader, modelo, funci贸n de p茅rdida y optimizador\n",
    "tokenizer: Any = AutoTokenizer.from_pretrained('projecte-aina/roberta-base-ca-v2-cased-sts')\n",
    "train_dataset: SimilarityDataset = SimilarityDataset(balanced_pairs, balanced_scores, tokenizer)\n",
    "dataloader: DataLoader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model: SimilarityModel = SimilarityModel('projecte-aina/roberta-base-ca-v2-cased-sts')\n",
    "loss_fn: CosineSimilarityLoss = CosineSimilarityLoss()\n",
    "optimizer: AdamW = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 3.2327\n",
      "Epoch 2 - Loss: 2.0414\n",
      "Epoch 3 - Loss: 1.4310\n",
      "Epoch 4 - Loss: 1.1652\n",
      "Epoch 5 - Loss: 0.9914\n",
      "Epoch 6 - Loss: 0.6520\n",
      "Epoch 7 - Loss: 0.5043\n",
      "Epoch 8 - Loss: 0.4765\n",
      "Epoch 9 - Loss: 0.4092\n",
      "Epoch 10 - Loss: 0.3856\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids1 = batch['input_ids1'].to(device)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device)\n",
    "        input_ids2 = batch['input_ids2'].to(device)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        emb1, emb2 = model(input_ids1, attention_mask1, input_ids2, attention_mask2)\n",
    "        loss = loss_fn(emb1, emb2, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Guardar todo el modelo entrenado\n",
    "torch.save(model.state_dict(), './modelo_entrenado3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con 10 epoch la loss sigue siendo grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores_val = [item['label']/5  for item in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-base-ca-v2-cased-sts and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtener las similitudes predichas\n",
    "model = SimilarityModel('projecte-aina/roberta-base-ca-v2-cased-sts')\n",
    "model.load_state_dict(torch.load('./modelo_entrenado3.pt', map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "predicciones = []\n",
    "for s1, s2 in sentence_pairs_:\n",
    "    encoded1 = tokenizer(s1, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "    encoded2 = tokenizer(s2, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "    for k in encoded1:\n",
    "        encoded1[k] = encoded1[k].to(device)\n",
    "        encoded2[k] = encoded2[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb1, emb2 = model(\n",
    "            input_ids1=encoded1['input_ids'],\n",
    "            attention_mask1=encoded1['attention_mask'],\n",
    "            input_ids2=encoded2['input_ids'],\n",
    "            attention_mask2=encoded2['attention_mask']\n",
    "        )\n",
    "        sim = F.cosine_similarity(emb1, emb2).item()\n",
    "        predicciones.append(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Correlaci贸n de Pearson: 0.2597\n",
      " Valor-p: 3.7768e-09\n"
     ]
    }
   ],
   "source": [
    "correlacion, p_valor = pearsonr(predicciones, true_scores_val)\n",
    "print(f\"\\n Correlaci贸n de Pearson: {correlacion:.4f}\")\n",
    "print(f\" Valor-p: {p_valor:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos encontramos con un problema de capacidad computacional. Lo mejor ser铆a entrenar m谩s el modelo, para obtener mejores resultados. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
